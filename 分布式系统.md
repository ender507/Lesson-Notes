# 分布式系统

[TOC]

## 一、 简介

### 1.1 分布式系统

分布式系统是若干独立租住计算机的集合，这些计算机对于用户来说像是单个耦合系统。物理分布，逻辑集中；个体独立，整体统一。特点：

- 自主性：计算节点硬件或者软件进程是独立的
- 耦合性：用户或者应用程序感觉分布式系统是一个系统，节点之间相互协作。

分布式系统特性：

- 构成组件被所有用户共享
- 系统资源可能不允许访问
- 软件运行在不同处理器上的多个并发进程上
- 允许多点控制
- 允许多点失效

集中式系统特性：

- 仅有单个组件构成
- 单个组件被用户一直占用
- 所有资源都是可访问的
- 软件运行在单个进程中
- 单点控制
- 单点失效

分布式系统的8个谬误：

- 网络可靠
- 延迟为0
- 带宽无限
- 网络安全
- 拓扑结构不变
- 只有一个管理员
- 不考虑传输开销

- 网络都是同构的

### 1.2 节点

自主节点集合：

- 节点独立行为
  - 每个节点都是独立的，有自己的本地时间
  - 没有全局锁
  - 存在基本的同步和协同的问题
- 节点集合行为
  - 管理集合中节点的关系（开放集合/封闭集合）
  - 确认通信的成员是否授权（信任和安全机制）

节点之间的组织形式里，覆盖网络最为常用：每个节点仅和邻居节点通信，邻居节点是动态的，甚至只能通过查询获得。

覆盖网络的类型：

- 结构性P2P网络：节点之间的连接具有特定规则的结构
- 非结构性P2P网络：节点之间的连接具有随机和任意性

一致系统：节点无论在什么地方，用户无论何时访问，节点集合对用户来讲是一个整体。用户不知道计算发生的位置和数据存储的位置，数据拷贝是完全隐藏的。核心是分布式透明性。

面临的挑战：部分失效。分布式系统的部分会不可避免地失效。部分失效与恢复很难做到对用户的透明性。

### 1.3 分布式系统的目标

#### 1.3.1 资源可访问

典型样例：

- 基于云的存储和文件系统
- 基于P2P的流媒体系统
- 共享邮件系统（外包的邮件系统）
- 共享的Web支撑系统（CDN）

#### 1.3.2 透明性

隐藏进程和资源在多台计算机上分布这一事实。

| 透明性类型 | 说明                                         |
| ---------- | -------------------------------------------- |
| 访问       | 隐藏数据表示形式的不同以及资源访问方式的不同 |
| 位置       | 隐藏资源所在的位置                           |
| 迁移       | 隐藏资源是否移动到另一个位置                 |
| 重定位     | 隐藏资源是否在使用中移动到另一个位置         |
| 复制       | 隐藏是否对资源进行复制                       |
| 并发       | 隐藏资源是否由相互竞争的用户共享             |
| 故障       | 隐藏资源的故障和恢复                         |
| 持久化     | 隐藏资源在主存和磁盘这一事实                 |

完全透明性是不可取也是难以实现的。因为：

- 可能隐含通信的性能问题
- 完全隐藏网络和节点的失效是不可能的：不能区分失效和性能变慢的节点；不能确定系统失效前的操作是什么
- 完全的透明性可能牺牲性能，暴露系统分布特征
- 保证复制节点与主节点的一致性需要时间（一致性问题）
- 为了容错需要立即将内存修改的内容同步到磁盘上

暴露系统的分布特征有一定的场景：

- 利用基于位置的服务（如：找到附近的朋友）
- 当与不同时区的用户交互时
- 当让用户理解系统发生了什么时，如一台服务器不响应，报告失效

结论：分布式透明性是一个比较好的属性，但是需要区别对待

#### 1.3.3 开放性

系统根据一系列准则来提供服务，这些准则描述了提供服务的语法和语义。即标准化。应有：

- 系统有良好定义的接口
- 系统易于实现互操作性
- 系统支持可移植性
- 系统容易实现可扩展性

重点：策略与机制分离。

策略：

- 需要为客户端的缓冲数据设置什么级别的一致性
- 运行下载的程序执行什么操作
- 网络带宽波动时如何调整QoS(服务质量)需求
- 通信安全水平的设置

机制：

- 运行动态设定缓冲策略
- 支持为移动代码设置不同的信任级别
- 为每个数据提供可调整的QoS参数
- 提供不同的加密算法

策略与机制分离的越严格则越需要设计合适的机制，从而导致很多的配置参数和很复杂的管理。硬编码某些策略可以简化管理，减少复杂性，但会导致灵活性降低。需要平衡。

#### 1.3.4 可扩展性

- 规模可扩展性：用户数量和进程数量增加
- 地理可扩展性：节点之间的最大物理位置
- 管理可扩展性：管理域的数量

大部分系统关系规模可扩展性。一般的解决方案为多个服务器独立并行运行。其他两个仍然充满挑战。

##### 1.3.4.1 规模可扩展性

集中式要解决规模可扩展性的根因：

- 计算容量受到CPU性能限制
- 存储容量局限，包括CPU与磁盘间的传输速率
- 网络局限：用户与集中服务之间的网络带宽

一个集中服务可以建模为一个简单的排队系统，假设队列长度无限，到达率为$\lambda$，服务率为$\mu$，则系统中包含`k`个请求的概率为$p_k=(1-\frac{\lambda}{\mu})(\frac{\lambda}{\mu}^k)$。令：
$$
\displaystyle U=\sum_{k>0}p_k=1-p_0=\frac{\lambda}{\mu}
$$
则有：
$$
p_k=(1-U)U^k
$$
系统中的平均请求数：
$$
\displaystyle\overline{N}=\sum_{k\geq0}k*p_k=\sum_{k\geq0}k*(1-U)U^k=(1-U)\sum_{k\geq0}k*U^k=\frac{(1-U)U}{(1-U)^2}=\frac{U}{1-U}
$$
平均吞吐量：
$$
X=U*\mu+(1-U)*0=\frac{\lambda}{\mu}*\mu=\lambda
$$
响应时间（处理一个请求的总的时间）：
$$
R = \frac{\overline{N}}{X}=\frac{S}{1-U}\rightarrow\frac{R}{S}=\frac{1}{1-U}
$$
如果U较小，相应时间趋近于1，意味着服务被立即处理；若U增加到1则系统处于挂起状态，应减少S。

##### 1.3.4.2 地理可扩展性

不能简单地从LAN扩展到WAN。很多分布式系统假设客户端和服务器之间的交互是同步的。广域环境中的延迟问题限制扩展性。

WAN中的连接常常不可靠，简单地将流视频从LAN移动到WAN会导致失效

确实多点通信导致一个简单的搜索广播不能执行。解决方案是将命名服务和目录服务分离。

##### 1.3.4.3 管理可扩展性

本质：与使用方法、管理和安全相关的策略冲突。

例子：

- 计算网络：在不同的域之间共享昂贵的计算资源
- 共享设备：如控制管理使用共享无线望远镜
- 文件共享系统（BitTorrent）、P2P电话（Skype）、基于P2P的音频数据流（Spotify）等

### 1.4 拓展技术

-  隐藏通信延迟：尽量避免等待远程服务对请求的相应。

利用异步通信技术，设计分离的相应消息处理器。但是不是所有的应用都适合这种模式。某些交互式的应用，用户发出请求后处于等待无所事事的状态。

- 分布：在多个机器上划分数据集和计算

- 复制和缓存：在多个不同机器上创建多个数据副本。

复制的使用很简单，但存在一致性问题。保证副本的一致性需要每次修改进行全局同步，产生高额代价。如果可以容忍不一致，可以减少全局的同步。

---------

## 二、 分布式系统架构

### 2.1 分布式架构类型

分布式系统案例：

- 分布式文件系统：HDFS、NFS、Ceph等
- 分布式数据库：MongoDB、Cassandra、ElasticSearch等
- 分布式处理框架：Hadoop、MPI、Spark、Storm等
- 分布式调度器：YARN、Mesos、Slurm等
- 分布式操作系统：Kubernetes、OpenStack、OpenShift等

体系结构样式包含：

- （可替换性）组件具有良好定义的接口
- 组件之间互联的方式
- 组件之间交换的数据
- 组件以及连接器是如何协同配置的

其中，连接器提供了一种机制，在组件之间传递通信、使得组件相互协调和协作。依据组件和连接器的使用可以出现不同的配置，从而划分不同的体系结构，包括：

- 分层式体系结构：主要用于客户端-服务器模型
- 基于对象的体系结构：主要用于分布式对象系统
- 以数据为中心的体系结构：如Pub/Sub结构
- 基于事件的体系结构：共享数据空间结构

### 2.2 分布式软件架构

确定软件组件和这些组件的交互以及它们的位置就是软件体系结构的一个实例，称为系统体系结构，包括：

- 集中式体系结构：整个系统包含一个控制中心，协同系统的运行
- 非集中式组织结构：系统没有一个整体的控制中心，各个节点独立自主运行
- 混合组织结构

#### 2.2.1 客户端-服务器模型

特征：

- Server进程：实现特定服务的进程
- Client进程：通过网服务器发送请求来请求服务，然后等待服务器回复的进程
- 客户端和服务器进程可以分布在不同的机器上
- 客户端在使用服务时采用请求-响应模式

主流的客户端服务器通信协议包括HTTP、HTTPS、REST API、AJAX、PRC、SOAP等

在应用分层的场景下，传统的三层视图包括：

- 用户结构层，包含系统与用户直接交互的单元，比如显示和管理
- 应用处理层，包含应用的主要函数，但是不与具体的数据绑定
- 数据层，管理应用使用的实际数据

分层结构是IT系统常见的组织结构形式，使用到了传统的数据库以及相关的应用程序。

#### 2.2.2 基于对象的体系风格结构

本质：组件由通过过程调用相互连接的对象构成，对象可以放置在不同的机器上，调用可以跨网络执行。对象封装了数据，并且提供面向数据的方法，而没有展示内部实现

RESTful架构：REST（representational safe transfer）风格，将分布式系统看做资源的集合，由组件独立管理。这些资源可以由应用程序添加、删除、检索和修改。资源可以通过命名机制标识，所有的服务提供相同的接口。从一个服务发出或者传入的消息是完全自描述的。执行完操作后，执行组件不再记录调用者的信息。

样例：Amazon's S3：对象objects放在桶buckets中，桶是不能嵌套的，桶中对象的操作需要标识符。典型的操作：所有的对象是通过HTTP协议传输的：

- 创建桶或者对象：在一个URI中执行PUT操作
- 列出对象：在桶上执行GET操作
- 读对象：通过一个完整的URI执行GET

因为接口简单，RESTful方法很好用，但是与资源相关的操作的参数空间设计会很复杂。

#### 2.2.3 协同

时态和引用耦合

|              | 时态耦合    | 时态解耦          |
| ------------ | ----------- | ----------------- |
| **引用耦合** | Direct      | Mailbox           |
| **引用解耦** | Event-based | Shared data space |

#### 2.2.4 非集中式体系结构

- 垂直分布vertical：系统逻辑分层，不同层次分布在不同的机器上
- 水平分布horizontal：客户或者服务器在物理上分成逻辑相等的几个部分，每个部分相对独立且分布在不同的机器上
- 点对点系统peer-to-peer：水平分布，构成点对点系统的进程完全相同，既是客户端又是服务器，无中心化系统
  - 结构化的P2P系统：节点按照特定的分布式数据结构组织
  - 无结构化的P2P系统：节点邻居随机选择
  - 混合P2P系统

在所有的P2P场景中，都会讨论覆盖网络：数据通过节点之间的连接传输，与应用层的广播类似

##### 结构化的点对点系统

将节点组织在一个特定结构的覆盖网络中，如环形结构，让这些节点根据自己的ID提供相应的职能。索引与语义无关、数据与唯一的键值对应。最佳实践：哈希。P2P系统用于存储键值对。

简单的例子：超立方体结构。

查找数据键值k的数据d，意味着将请求路由到节点标识符为k的节点

Chord结构：分布式哈希表DHT。节点和数据项的key值在同一个随机空间中生成（160位标识符），数据项键值与节点标识符一一对应。键值为k的数据项保存在满足ID大于k的最小节点上。环可以通过节点之间的捷径shortcuts进行拓展。

CAN（content addressable network）上下文可编址结构：将节点组织成d维空间，令每一个节点在一个特定的区域负责特定的任务。当有新节点加入时，将区域进一步划分。

#####  非结构化的点对点系统

本质：每个节点维持一个动态随机的邻接表，目标是构建一个随机图。部分视图：从当前节点集合中随机选择出来c个活节点，交换信息。

部分视图的构造：主动进程推送到对等节点c/2+1个表项，被动进程推送相同数量的表项给对方

P2P系统数据搜索方式：

- 泛洪方式：请求发出节点u会向其所有邻居节点发出数据搜索请求。如果之前已经收到了节点请求，则请求会被忽略。否则，节点会在本节点查找数据项，请求会迭代传递下去。有TTL的限制，通信代价高
- 随机游走：请求发出节点u从其邻居节点中随机选择一个节点，然后进行本地搜索。如果没有完成则继续从其邻居节点中选择一个随机节点向下进行。需要一种停止机制

- 覆盖网络拓扑管理：核心思想为在最底层维护随机的部分视图，在较高层的部分视图上进行表项选择。比如一个N*N的逻辑网络，每个节点维护一个含有c个最近邻的节点的列表，节点(a1,a2)和(b1,b2)之间的距离定义为d1+d2，其中di = min (N-|ai-bi|,|ai-bi|)
- 超级对等节点：核心思想考虑到非结构化的点对点系统中数据项的定位非常困难，因此打破点对点网络的对称性，设置代理程序。超级对等节点即维护一个索引或充当一个代理程序的节点，在非结构化的P2P进行搜索时索引服务器会提高性能，通过代理程序可以更加有效地决定在哪里放置数据。超级对等节点需要维护索引、监控网络状态、建立连接

样例：Skype中A连接B的原理：

- A和B均在公共网络上：A和B之间建立TCP连接用于控制报文的传输，实际通过UDP在商定的端口之间通信
- A在防火墙内而B在公网上：A和超级对等节点S建立TCP连接用于控制报文传输，S与B建立TCP连接用于中继报文的传输。A和B直接通过UDP传输数据
- A和B均在防火墙后：A与在线的超级对等节点S通过TCP连接，S通过TCP与B连接。对于实际的呼叫，另一个超级对等节点R作为中继节点，A和B均会与R建立连接。所有的数据通过R以及两个TCP连接转发

##### 混合架构P2P

很多场景中，客户端-服务器架构是和P2P架构整合在一起的。

边界服务器系统：服务器放置在网络的边界，常用于CDN。边界服务器的主要目的是进行过滤和编码转换后提供相应的内容服务。

协作分布式系统：混合结构主要部署在协作分布式系统中，如Bittorrent，混合了P2P下载协议和客户端-服务器架构。基本原理：一旦节点识别出到哪里下载文件，他就会加入到一个下载机器的集合。这些机器并行地下载文件块，同时把这些数据块分发给其他节点。

### 2.3 架构与中间件比较

问题：分布式系统的透明性；体系结构非最优，需要中间件提供动态自适应能力；中间件的自适应能力（策略和机制分离）

中断器：一种软件结构，具有通用性，能进行基于对象的分布式系统的中断

### 2.4 分布式系统的自管理

自适应中间件：

- 要点分离：要把实现功能的部分与非功能部分如可靠性等分开
- 计算反射：让程序运行时刻检查自身的行为，如果要必要则调整其行为
- 基于组件的设计：通过组件的不同组合来支持自适应，系统可以在设计时静态配置，或是运行时动态配置

在需要完成自适应功能的同时，系统结构和软件架构之间的界线逐渐模糊

------------

## 三、 进程和虚拟化

### 3.1 分布式系统中的线程

#### 3.1.1 概念 

基本思想：在物理处理器上用软件创建虚拟处理器：

- 处理器：提供和运行一系列指令集合的硬件平台
- 线程：一个最小的可执行一系列指令的软件处理器，保存线程的上下文意味着终止线程当前的执行，在其他时刻装载保存的线程上下文后，线程可以继续执行
- 进程：包含多个线程的软件处理器，线程需要在进程的上下文中执行

上下文是系统运行过程中的一系列状态：

- 处理器上下文：处理器运行一系列指令的保存在寄存器中的最小数据集合（栈指针、地址寄存器、程序计数器）
- 线程上下文：执行一系列指令的保存在寄存器和内存中的最小数据集合（处理器上下文、状态等）
- 进程上下文：用于执行线程的保存在寄存器和内存中的最小的数据集合（线程上下文、MMU寄存器值、TLB）

线程共享相同的地址空间，线程的上下文切换可以独立于操作系统。一般来讲进程间的切换要更复杂、代价更高，因为需要陷入到OS内核才能完成。创建和销毁线程代价远小于进程。

为什么要利用线程？

- 避免不必要的阻塞
- 更好地发挥并行性
- 避免进程的上下文切换

#### 3.1.2 线程的实现

线程往往以线程包的形式存在，完全在用户空间下创建线程库，由内核来掌管线程并进行调度。

- 用户级线程：线程在用户空间。上下文切换代价小。但线程的阻塞意味着进程阻塞
- 内核级线程：线程在内核空间。内核中实现软件包，所有的操作变成系统调用。用于阻塞线程的操作不再是问题，处理外部事件更简单，内核直接调度。但每个线程操作都要陷入内核，效率有问题。
- 混合级线程：更优（发挥各自优势），但相当复杂

轻量级线程light weight process LWP：基本思想是引入一种两层线程方法，LWP在内核空间，但能执行用户空间的线程。主要操作有：

- 用户级线程执行系统调用使得LWP执行相应的操作，同时线程被挂起，维持和绑定在LWP上
- 内核调度负责调度另外一个LWP，该LWP绑定了一个活跃线程。该线程可以切换到用户空间中的另外的活跃线程
- 一个线程调用阻塞用户层的操作：上下文切换到一个运行的线程并绑定到相同的LWP
- 当没有线程调用时，LWP保持空闲甚至可能被内核清除回收

多线程在分布式系统中有重要意义：

- 客户端
  - 多线程的Web客户端隐藏了网络的延迟。Web浏览器扫描到达的HTML页面，发现需要获取更多页面。每一个页面由特定的线程获取，每个线程执行HTTP请求。随着文件的到达，浏览器将这些文件展示出来
  - 服务器之间的多个请求-响应调用：客户端同时产生多个调用，每一个线程负责一个。如果调用不同的服务器，将会得到线性加速
- 服务器
  - 提高性能：线程开销比进程小、单线程很难在多处理器系统实现纵向扩展、与多线程客户端相对应，通过并行响应请求隐藏网络延迟
  - 更好的结构：大部分服务器都有较高的I/O需求，使用简单的阻塞调用可以简化整体结构、多线程程序代码少，易理解，因为控制流被简化了

### 3.2 虚拟化

虚拟化本质是软件和硬件的多路复用。硬件比软件变化的快，需要灵活的可移植性和代码迁移。还要考虑失效和攻击隔离。

主要原理：模拟接口：

- 指令集架构：机器指令，分为特权指令和通用指令
- 系统调用，由操作系统提供函数
- 库函数调用，即API

虚拟机分为：

- 进程虚拟机process VM：分离的指令集合，实际是运行在OS上的解释器或模拟器
- 原生虚拟机监控器native VMM：底层的指令，具有跑在硬件上的最小的操作系统
- 主机虚拟机监控器hosted VMM：底层指令，需要完整的OS

机器指令包含一些特殊指令，包括：

- 控制敏感性指令：可以影响到机器配置的指令，如寄存器重定位或中断表
- 行为敏感性指令：效果由上下文决定

虚拟化的必要条件是，敏感指令是特权指令的子集，则可以构建虚拟机监控器。问题在于，存在这样的指令集，在用户空间执行但不会引起操作系统的陷入。解决方案：

- 模拟所有指令
- 包装非特权指令，交给VMM控制执行
- 半虚拟化paravirtualization：修改客户OS，要么组织非特权敏感指令，要么将其变为非敏感的

### 3.3 客户-服务典型结构

- 每种远程服务，客户机都有一个独立的网络模块联系这些服务
- 通过一个统一用户接口对远程服务直接访问

客户端软件包含用于获得分布式透明性的组件：

- 访问透明性：客户端拥有用于RPC访问的存根
- 位置/前移透明性：客户端记录服务器的实际位置
- 副本透明性：客户端存根多个副本的调用
- 故障透明性：经常放在客户端用于屏蔽服务器和通信问题

服务器的两种基本类型：

- 迭代服务器：服务器顺序处理到达的请求
- 并发服务器：用分派器选择请求并传递给分离的进程或线程处理

外带通信：服务器接受了服务器请求后，不能中断服务器的运行：利用分开的端口用于紧急数据通信，或利用传输层的机制，如TCP的紧急信息和OS的信号机制捕捉紧急信息

按状态分类的服务器：

- 无状态服务器：处理完请求后不保存关于客户端的精确信息，不记录文件是否被打开，不保证清空客户端的cache、不追踪客户信息
  - 客户端和服务器完全独立
  - 客户端或服务器宕机导致的状态不一致减少
  - 服务器不能预测客户端的行为，可能导致性能下降
- 有状态服务器：记录客户端的状态信息，知道客户端打开的文件，可以提前预取、知道客户端缓存的数据，运行客户端本地保存共享数据备份
  - 性能很高
  - 可靠性是主要问题

服务器的第一层主要用于请求分发，从而掩盖分布式系统的分布式特征。让第一次处理所有出入集群的通信会导致性能瓶颈，需要新的度量方法：

- 基于传输层交换：前端简单地将TCP请求传递到服务器，只是会考虑某先简单的性能指标，如CPU利用率
- 基于内容可感知的分派方法：前端读取请求的内容然后选择最适合的服务器
- 结合

### 3.4 计算迁移

确保数据中心的服务器的复杂运行更充分以防止浪费能源，让计算更加贴近数据端以最小化通信代价。灵活性：需要的时候将代码迁移到客户端。

对象组件包含：

- 代码片段：实际执行的代码
- 数据片段：包含状态
- 执行状态：包含线程执行的对象代码的上下文

弱移动性仅仅一定代码和数据片段，重启执行。有代码推送push和拉取pull的概念。强移动性移动组件，包括执行状态。能够迁移migration，将整个对象从一个机器移动到另外一个机器，以及克隆cloning，将克隆设置为相同的执行状态

在异构系统中迁移，目标机器可能不适合执行迁移后的代码，进程、线程、处理器上下文的定义依赖硬件、OS和运行时系统。仅有的解决方案：不同平台上抽象机器的实现，如解释性语言，拥有自己的VM，或虚拟机监控器

迁移镜像的方案：

- 将内存页面推送到新的机器，在迁移过程中重新发送被修改的页面
- 停止当前的虚拟机，迁移内存然后重启虚拟机
- 让新的虚拟机按需求拉取内存页面

依次完整的虚拟机迁移可能需要几十秒，前一期间服务可能处于几秒钟的完全不可用状态

--------------

## 四、 系统通信

### 4.1 背景

#### 4.1.1 网络结构

进程间的通信是分布式系统的核心。OSI的网络模型过于复杂，我们只关注消息传递，有些功能通常下用不到，且违背了透明性。对于很多分布式系统而言，最底层的接口其实是网络层。

对于大部分分布式系统，传输层提供实际的通信功能。标准的网络协议：

- TCP：面向连接的、可靠的、面向流的通信
- UDP：不可靠的数据报文通信

中间件提供通用的服务和协议，可用于支撑很多不同的应用：

- 包含丰富的通信协议
- 包装/解包数据，对系统集成非常重要
- 命名协议，允许资源共享
- 安全协议用于安全通信
- 拓展机制，如复制和缓存

改进后的网络模型：物理层-数据链路层-网络层-传输层-中间件层-应用层

#### 4.1.2 通信类型

- 瞬时（瞬态）通信：当消息不能传递到另一个服务器时，消息被丢弃
- 持久通信：消息储存在通信服务器指导消息被传递出去，需要进行同步。同步时间：请求提交时、传输时、处理完后

客户端/服务器计算系统一般是基于瞬态、同步的通信方法，通信时二者必须处于活跃状态。客户端发出请求后被阻塞直到收到应答，服务器只是等待来到的请求然后处理请求。同步通信的缺点：

- 客户端等待回应时不能做其他工作
- 失效必须即刻处理
- 对于一些应用，该模型不适用（mail等）

面向消息的中间件的应用：目的在于进行高层次的持久化、异步化通信：

- 进程之间互相发送消息，消息会被排队
- 发送进程可以继续做其他事情，不需要等待及时回应
- 中间件提供容错机制

### 4.2 远程过程调用RPC

调用者和被调用者之间的通信可以通过调用过程的调用机制隐藏掉。

RPC参数传递不仅仅是将参数封装在消息中：客户端和服务器可能有不同的数据表示，封装参数意味着将一个值转换成一个字节序列。客户端和服务器应具有一致的编码机制。客户端和服务器需要正确地解释消息，并将其转换成与机器无关的表达形式。RPC关键点在于对象序列协议和调用控制协议。

异步RPC：摒弃严格的请求-响应行为，让客户端连续运行而不需要等待服务器返回信息。

多RPC调用：发送RPC请求到一组服务器上

### 4.3 面向消息的通信

远程过程调用的缺点：服务器不一定运行且同步阻塞。面向消息的通信包括瞬时通信和持久通信。

#### 4.3.1 瞬时通信

berkeley套接字。套接字属于底层编程，容易出错。而套接字的使用都非常模板化。三种不同的模式：

- request-reply
- publish-subscribe
- pipeline

套接字的缺点：

- 套接字的抽象层有问题，只能提供简单的send和receive操作
- 套接字的使用协议栈（TCP/IP）进行网络通信，不适用于专用协议
- 灵活性较差，提供的功能简单

#### 4.3.2 持久通信

消息队列系统（面向消息的中间件）：通过中间件层的队列支持实现异步持久的通信，队列相当于服务器的缓冲区。

- 队列管理器：将本地队列中的消息路由到其他地方
- 消息转换器：处理应用的异构性，将输入消息转换成目的格式。起到应用层网关的作用，提供基于主题的路由功能（pub-sub）

#### 4.3.3 IBM WebSphere MQ

基本概念：与应用相关的消息被放进或移出队列，消息队列由队列管理器控制，进程可将消息放在本地队列中，或者通过RPC机制发到远端

消息传输：消息在不同的队列之间进行传输。在不同进程的队列之间传输时需要通信信道（channel）。消息通道的两端是消息通道代理（message channel agent）

MCA的主要作用：

- 利用底层的网络通信协议如TCP/IP等建立通信通道
- 从输入/输出的网络传输包中进行消息的解封装/封装
- 发送和接受传输包

在IBM WebSphere MQ中，通道是单向的，当消息到达的时候自动启动MCA。任何队列管理器都可以创建通道，路由是手动设置的。每一个MCA都有一组相关的属性，这些属性决定了通道的全部特性，如传输协议、消息长度、重试次数等。

路由被显示地存储在队列管理器中的路由表中。路由表的条目为`(destQM,sendQ)`对，路由表中的条目称为别名。

### 4.4 面向流的通信

数据流是数据单元的序列，可以应用于离散的媒介，也可以应用于连续媒体。数据流的传输模式包括异步、同步、等时传输

### 4.5 多播通信

应用层多播：本质是将分布式系统组织成一个覆盖网络，然后利用这个网络分发数据

覆盖网络的构建方法：

- 组织成树，导致每对节点之间只有唯一的路径
- 组织成网络结构，每个节点都有多个邻居节点（健壮性高）

假设信息传播过程中不存在写-写冲突，即更新由单个节点发起，副本仅仅想有限的几个邻居传播，更新传播是滞后的而不是立即执行，最终每一次更新都会到达所有副本，则有两个传播模型：

- 逆商模型anti-entropy：节点P从系统中随机选取节点Q，P的更新请求只对Q生效，也只接受Q的更新请求。经过一番杂乱无章的通信，最终所有节点都会达成一致。
- 流言传播模型rumor spreading：节点向其他节点发送消息，当某个节点成功被传播到，则原来的节点有$p_{stop}$的概率停止向其他节点发送消息。具有良好的拓展性。

-----

## 五、 命名系统

### 5.1 基本概念

命名的本质是用名字标识分布式系统中的实体对象，名称是由字符组成的字符串。实体可以是分布式系统中的任何事物，可以是主机、文件、打印机等硬件资源或用户、邮箱等抽象资源

访问点：对实体可以进行一系列的操作。需要访问实体则需要访问点。访问点是一类特殊的实体，访问点的名称成为地址。实体的访问点的地址即该实体的地址。一个独立于实体地址的名称通常是合理且灵活的，与位置无关。

标识符identifier：具有特殊属性的字符串。一个标识符至多引用一个实体，每一个实体最多由一个标识符引用。一个标识符始终引用一个实体（不会重新使用）。标识符不一定是一个单纯的名字，可以包含特定的内容。

原则上，命名系统含有一个名称到地址的绑定，即一个`(name, address)`的表。

### 5.2 无层次命名

广播，请求实体返回当前地址，如ARP协议找出IP地址相关的MAC地址。难以逾越局域网，需要所有进程监听来到的请求。当网络规模过大时，广播变得低效。解决方案：多播。

#### 5.2.1 转发指针

当实体移动的时候，会在当前位置留下到下一个位置的指针。去引用对于客户端来说变得完全透明，只需要沿着指针连续搜索。当实体的当前地址找到后，更新客户端的引用。有扩展性问题（地理可扩展性）：较长的传播链很脆弱，容易断开；实体定位的开销比较大

#### 5.2.2 宿主机

基于宿主位置的方法：广播和转发指针的使用的主要缺点是可扩展性的问题，且容易受到链断开的影响。单层模式：让宿主机记录实体的位置。实体的素质地址注册在命名服务上，宿主机注册实体的外部地址。客户端需要先于宿主机联系，然后与外部地址联系。

基于宿主机的方法存在的问题：

- 宿主机需要伴随实体的整个生命周期
- 宿主机的地址是固定的，如果实体对象永久迁移会带来不必要的问题（可以通过DNS解决）
- 较差的地理可扩展性（实体可能就在客户端旁边）

#### 5.2.3 分布式散列表

众多节点组织成环形结构，每一个节点被赋予一个由m位构成的标识符，每一个实体被赋予一个唯一的m位的键值。键值为k的实体存储在满足id >= k的最小标识符节点上，作为k的后继，记为`succ(k)​`。无扩展性搜索方法：令每一个节点记录其邻居，并进行线性的搜索。

Chord指状表finger tables：每个节点p有一个指状表$FT_p$，拥有最多m项：$FT_p[i]=succ(p+2^{i-1})$。第 i 项表示后继的首个标识至少为$2^{i-1}$的节点。想要查询键 k ，节点 p 传递请求到节点q，满足：$q=FT_p[j]\leq k<FT_p[j+1]$。若$p<k<FT_p[1]$则请求也被传给$FT_p[1]$。

考虑到覆盖网络的节点之间的组织结构可能导致在底层互联网上的异常的消息传输，如节点p和节点`succ(p+1)`实际记录很远。解决方法：

- 基于拓扑的节点标识符赋值：；邻近节点的标识符也靠近。在chord系统中存在严重问题
- 邻近路由：节点维护一个转发请求的可选列表，每个节点有多个后继，查询时选择最近的一个
- 优化路由表，使得选择最近的节点作为邻节点

#### 5.2.4 分层定位方法

创建一个大规模的搜索树，底层的网络被划分成多个分层的域，每一个域由一个目录节点directory node表示。

树的组织结构：实体E的地址存储在叶节点或中间节点上，中间节点记录了所有子节点记录的实体地址。根节点有所有实体的地址。

查询时，在一个叶子节点上搜索，如果节点知道实体则搜索下游指针，否则回退到父节点。向上搜索的过程最终会以达到根节点而停止。

### 5.3 结构化命名

#### 5.3.1 相关概念

命名图：一张叶节点表示实体的图。此外，叶节点还可以存储实体属性、状态等信息。目录节点有一定数量的边，用于引用其他节点。除了存储目录表以外，目录节点也可以拥有属性。

名称解析：给定一个路径名，查找出存储在由该名称所指向的节点中的任何信息，查询名称的过程称为名称解析。知道如何启动以及在何处启动名称解析通常称为闭包机制。

连接name linking

- 硬链接hard link：路径名即用于在命名图按照特定路径搜索节点的名字
- 软链接soft link：允许一个节点N包含另外一个节点名字。用叶节点表示实体，而不是存储实体的地址和位置。该节点存储绝对路径名。则：
  - 首先解析N的名字
  - 读取N的内容返回名字
  - 利用返回的名字进行名字解析

命名解析也可以应用与合并不同的命名空间，通过过载的方法透明地实现，将另一空间的节点标识符与当前命名空间的节点相关联。相关术语：

- 外部命名空间：需要访问的命名空间
- 挂接点：在当前命名空间中用于存储节点标识符的目录节点称为挂接点
- 挂载点：外部名称空间中的目录节点称为挂载点，挂载点是命名空间的“根”

通过网络挂载需要访问协议的名称、服务器的名称、外部名称空间中挂载点的名称

#### 5.3.2 命名空间的实现

跨越多个机器的分布式命名解析过程与命名空间管理是通过将命名图分布在多个节点上实现的。

三层名称空间：

- 全局层：由最高级别的节点构成，即由根节点以及其他逻辑上靠近根节点的目录节点组成。稳定、目录表很少改变、可以代表组织或组织群
- 行政层：由在单个组织内一起被管理的目录节点组成。代表属于同一组织或行政单位的实体组，相对稳定但是比全局层的目录变化频繁
- 管理层：由经常改变的节点组成。如代表本地主机的节点及本地文件系统等，由终端用户维护

可用性问题：

- 全局层要求具有很高的可用性
- 行政层可用性要求最高
- 管理层的可用性要求不高

性能问题：

- 使用缓冲机制可以增加全局层命名解析的性能
- 使用高性能服务器来运行命名服务器

#### 5.3.3 命名解析方法

##### 迭代命名解析

1. 发送`(dir, [name1, name2,..., namek])`到负责`dir`的`server0`
2. `server0`解析`(dir, name1)`得到`dir1`，返回存储`dir1`的`server1`的标识符（地址）
3. 客户端发送`(dir1, [name2, ..., namek])`到`server1`
4. 以此类推

##### 递归命名解析

1. 发送`(dir, [name1, name2,..., namek])`到负责`dir`的`server0`
2. `server0`解析`(dir, name1)`得到`dir1`，得到存储`dir1`的`server1`的标识符（地址）
3. `server0`发送`(dir1, [name2, ..., namek])`到`server1`
4. 以此类推，最终由`server0`将结果返回客户端

##### 扩展性问题

规模可扩展性：需要保证命名服务器每秒钟可处理大量的请求，高层次的服务器面临较大的挑战。假定（至少在全局层和行政层）节点的内容几乎不发生变化。我们可以应用扩展备份将节点的内容映射到多个服务器，从最近的服务器上开始命名解析。很多节点的一个很重要的属性是代表实体的地址是可以访问的，但是复制节点会让大规模传统的命名服务器不适合用于定位移动实体。

通过将节点内容映射到能够在任何地点访问的服务器上，引入了隐性的位置依赖性。

#### 5.3.4 DNS域名解析系统

命名空间被组织成分层结构，每一个节点有一个显式的进入边。域：子树。域名：指向域的根节点的路径名字，可以是绝对的或相对的。

### 5.4 基于属性的命名

在很多场景中，通过实体的属性查询实体要方便的多，如传统的目录服务（黄页）。查找操作的代价很高，因为需要匹配请求的属性值，理论上需要检查所有的实体。

目录服务：

- 搜索可扩展性方案：利用数据库实现基本的目录服务，并结合传统的结构化的命名系统
- 轻量级目录访问协议LDAP：每一个目录项包含（属性，值）对，并且被赋予唯一的名字方便查找

-------------------

## 六、 协同

同步：时间之间进行协调，在时间上达成一致

- 进程同步：一个进程等待其他进程执行完
- 数据同步：保证两个数据集合相同

协作：管理系统中的行为之间的交互和依赖关系

### 6.1 时钟同步（物理）

统一协调时间UTC：基于铯133原子的每秒钟跃迁的次数进行计数。UTC时间通过无线电和卫星通过短波广播，卫星传播 可能导致±0.5ms的误差。

定义精度$\pi$来保证任意两个机器的时钟偏差在特定范围内：$\forall t,\forall p,q:|C_p(t)-C_q(t)|\leq\pi$，其中$C_p(t)$为机器 p 在UTC为 t 时的时钟时间。

定义准确度保证时钟边界：$\forall t,\forall p:|C_p(t)-t|\leq\alpha$

同步：

- 内部同步保证时钟的精度
- 外部同步保证时钟的准确度

利用硬件时钟中断，我们将软件时钟与硬件时钟耦合时会产生时钟漂移。时钟是会变化的，计算平均值无法包含时钟漂移。可以使用线性回归 （LR）。

没有UTC的情况下保障时间的准确性。Berkeley 算法：时间服务器周期性地扫描所有的服务器，计算时间均值，并告诉所有其他机器如何根据当前时间进行调整。

参考广播同步化：一个节点广播参考信息m，每个接收节点p记录收到消息的本地时间$T_{p,m}$，从而知道节点间的时间偏差。不需要同步。

### 6.2 逻辑时钟

#### 6.2.1 Lamport算法

所有的进程并不一定在时间上达成一致，而只需要在时间发生顺序上达成一致，也就是需要排序。

happen-before关系：

- 如果a和b是统一进程的两个事件，且a在b之前到达，则有：a->b
- 如果a是消息的发送者，b是消息的接收者，则a->b
- 如果a->b且b->c，则a->c

考虑为每个事件e分配一个时间戳C(e)，满足：

- 属性1：如果a和b是同一进程中的时间并且a->b，则$C(a)<C(b)$
- 属性2：如果a是消息m的发送方，b是接收方，则$C(a)<C(b)$

Lamport算法：每个进程都有一个本地计数器$C_i$，需要进行调整：

- 若在$P_i$上发生事件，则$C_i$增大1
- 当$P_i$发送消息，需要带上时间戳$ts(m)=C_i$（发送也是事件，需要先+1）
- 当$P_j$收到消息，$C_j$取$C_j$和$ts(m)$的最大值并加一

前一条保证属性1，后两条保证属性2。

#### 6.2.2 全序多播

在一个副本数据库上的并发更新在任何地方都应该是同样的顺序。类似多线程的并行，对同一个数据的改动会产生冲突。

解决方法：进程将加上时间戳的消息发送到其他所有进程，消息本身保存在各个进程的本地队列中。任何新到达的消息放在队列中，依据它的时间戳进行排序并向所有进程广播，从而确认消息。当消息为队列头，对于每一个其他的进程，队列中保存着来自其他进程的消息并由较大的时间戳（确认消息）时，将该消息发送给应用程序。注意：这里假定通信是可靠的，并且是FIFO排序的

可以利用临界区使用Lamport逻辑时钟解决互斥访问，与全序多播类似，利用全序的多播方法，所有的进程建立单独的队列，以相同的顺序发送消息，互斥访问在进程进入关键区的顺序上达成一致。

#### 6.2.3 向量时钟

Lamport时钟的一个缺点：当一个进程先后收到两个消息时，它不能判断这两个消息发送的先后。

因果依赖（causal dependency）：b**可能**因果依赖于a，则需要满足：

- $ts(a)<ts(b)$
- $\forall k,ts(a)[k]\leq ts(b)[k]$
- $\exist k',ts(a)[k']<ts(b)[k']$

考虑每个进程$P_i$维护一个向量$VC_i$，用$VC_i[i]$表示$P_i$的本地逻辑时钟，$VC_i[j]$表示$P_i$知道的$P_j$发生事件的个数。维护向量时钟：

- $P_i$要执行事件，则$VC_i[i]$增大1
- $P_i$给$P_j$发送消息，则发送时间戳向量$ts(m)$（发送也是事件，需要$VC_i[i]$先+1）
- 收到消息后，遍历向量每个值：$VC_j[k]=\max(VC_j[k],ts(m)[k])$，再$VC_j[j]$加1

因果有序的多播比之前提到的全序多播更弱。尤其是如果两个消息互相没有任何关系，并不关心以什么顺序发送给应用程序。使用向量时钟，可以确保所有因果先于某个消息的所有消息接收后才传送这个消息。调整：仅在$P_i$发消息才增加$VC[i]$，$P_j$收到消息才增加$VC[j]$，$P_j$推迟放送消息，直到：

- $ts(m)[i]=VC_j[i]+1$
- $ts(m)[k]\leq VC_j[k],k\neq1$

### 6.3 互斥

分布式系统中的多个进程需要互斥地访问某些资源。

#### 6.3.1 基于许可的方法

如果进程需要访问临界区或者访问资源，需要从其他进程（协作者）获得许可。协作者只有一个则宕机会失效。假定每种资源有 N 个副本，每一个副本都有自己的协作者，用于控制访问。进程只要获得 m > N/2 个协作者的大多数投票就可以访问 资源。一个协作者总是立即响应请求。当一个协作者宕机后，它会迅速恢复，但是会忘记已经发出去的许可。减少单个协作者由于失效造成的影响，同时提高性能。

拥有单个故障点往往是不可接受，有必要采用分布式互斥算法。

Ricart & Agrawala 算法：要求系统中的所有事件都是完全排序的。对于每对事件，比方说消息，哪个事件先发生都必须非常明确。进程要访问共享资源时，构造一个消息，包括资源名、它的进程号和当前逻辑时间。然后发送给所有的其他进程。接收到消息的决策动作分为三种情况：

- 若接收进程没有访问资源，而且也不想访问资源，向发送者返回 一个OK消息
- 若接收者已获得对资源的访问，那么它就不答应，而是将该请求放入队列中
- 如果接收者想访问资源但尚未访问时，它将收到消息的时间戳与它发送到其他进程的消息的时间戳进行比较。时间戳早的那个进程获胜，如果接收到的消息的时间戳比较早，那么返回一个OK消 息。如果它自己的消息的时间戳比较早，那么接收者将收到的消息放入队列中，并且不发送任何消息

问题：

- 单个故障点被n个故障点所取代。如果任何一个进程崩溃，就不能回答请求，造成阻塞。 故障概率ᨀ高了 n 倍， 同时网络流量大大增加。
- 进程维护开销较大，不适用进程数目较多的情况

#### 6.3.2 基于令牌的方法

仅有的一个令牌在进程之前传递，拥有令牌的进程可以访问临界区或者将令牌传递给其他进程

将进程组织成逻辑环，令牌在这些进程之间传递。拥有令牌 进程允许进入临界区。覆盖网络构成一个逻辑环。

### 6.4 选举算法

某些算法需要一些进程作为一个协作者，问题是如何动态的选择这个特殊的进程。在很多系统中，协作者是手动选取的。这会导致集中化的单点失效问题。

基本假设：

- 所有的进程都有唯一的ID
- 所有的进程都知道系统中的其他进程的ID，但是不知道进程是运行还是停止
- 选举算法一位置找到具有最大ID的运行的进程

#### 6.4.1 Bully算法

假设ID就是进程的下标。当$P_k$发现协作者不再回复请求，则：

- $R_k$发送ELECTION消息给所有有更高ID的进程$P_{k+1},...,P_{N-1}$
- 如果没有回复则$P_k$成为协作者
- 如果有更大ID的进程回复则让更大的来当

#### 6.4.2 Ring算法

进程按照物理或逻辑顺序进行排序，组织成环形结构。具有最大ID的进程被选为协作者。任何进程都可以启动一次选举过程，该进程把选举信息传递给后继者。如果后继者崩溃，消息再依次传递下去。在每一步传输过程中，发送者把自己的进程号加到该消息的列表中， 使自己成为协作者的候选人。消息返回到此次选举的进程，进程发起者接收到一个包含它自己进程号的消息时，消息类型变成Coordinator消息，并再次绕环向所有进程通知谁是协作者以及新环中的成员都有谁。

#### 6.4.3 无线系统环境中的选举算法

传统的选举算法假设消息传送是可靠的，网络的拓扑结构也是不会改变的，但这是错的。考虑发起者广播消息，收到消息不重复，广播到所有进程后形成一棵树，再从叶发消息返回根，记录自身的ID和进程号。

------------

## 七、 一致性和复制

CAP原则：一个分布式系统中，一致性consistency、可用性availability、分区容错性partition tolerance，三者不可得兼。

### 7.1 背景知识

为了保证复制的一致性，通常需要确保所有的冲突操作无论在任何地方都要按照相同的顺序执行。操作冲突有：

- 读写冲突
- 写写冲突

发生冲突操作时，保证全局一致性很困难。折中方案：减弱一致性需求，避免全局一致性。

- 以数据为中心的一致性模型：读写并重的数据存储
- 以客户为中心的一致性模型：读多写少，提供弱一致性，即最终一致性（如果在很长一段时间内没有更新操作，那么所有的副本将逐渐成为一致的）

### 7.2 以数据为中心的一致性模型

一致性模型实际上是进程和数据存储之间的一个约定，如果进程统一遵守某些规则，那么数据存储将正常运行。数据存储精确规约了当出现并发操作时读写操作的返回结果。

连续一致性：定义为“一致性程度”，包括以下几个方面：

- 数值偏差：不同副本之间的数值可能不同
- 新旧偏差：不同副本之间的新旧不同
- 顺序偏差：不同副本更新操作的**顺序和数量**可能不同（即对应不同更新方法）

记 conit 为一致性单元，即一致性可度量的单元。conit 中有多个副本，偏差权重 = 某副本已经提交的值与还没有收到来自其他副本的操作产生的结果之间的最大差分。conit 的粒度需要权衡。

顺序一致性：重要的以数据为中心的一致性模型。任何执行结果都是相同的，就好像所有进程对数据存储的读写操作时按照某种序列顺序执行的，并且某个进程的操作按照程序所制制定的顺序出现在序列中。进程可以看到所有的进程的写操作，但是只能看到自己的读操作。

因果一致性：弱化的顺序一致性模型，所有进程必须以相同的顺序看到具有潜在因果关系的写操作。不同机器上可以以不同的顺序看到并发写操作。

分组操作：

- 在一个进程对被保护的共享数据的所有更新操作执行完之前，不允许另一个进程执行对同步化变量的获取访问
- 一个进程对某个同步化变量进行互斥访问时，其他进程不能拥有该同步化变量，即使是非互斥模式也一样
- 某个进程对某个同步化变量的互斥模式访问完成后，除非该变量的拥有者执行完操作，否则任何其他进程对该变量的下一个非互斥模式访问也是不允许的

对上面三点的解释：

- 当一个进程获得拥有权后，这种拥有权直到所有被保护的数据都已近更新为止。也就是说，对被保护数据的所有远程修改都是可见的。
- 在更新一个共享数据前，进程必须以互斥模式进入临界区，确保不会有其他进程同时更新
- 如果一个进程要以非互斥模式进入临界区，必须首先与该同步化变量的拥有者进行协商，确保临界区获得了被保护共享数据的最新副本。

入口一致性要求我们需要显式或隐式地解锁或解锁数据。可以使用中间件来使得该种一致性对于开发人员更加透明。没有加锁就进行的读操作结果是不保证的。

### 7.3 以客户为中心的一致性模型

举个例子，假如一个笔记本可以作为前端访问分布式数据库。在地点A，对数据库进行读写，在地点B继续工作，除非直接访问A上的服务器，否则会检测到不一致：

- A的更新可能没有传播到B
- 可能访问到比A更新的数据
- 在B的更新可能最终与A的更新发生冲突

单调读一致性：如果一个进程读取数据项 x 的值，那么该进程对 x 执行的任何后序操作总是得到第一次读取的那个值或更新的值。（如果进程已经看到过数据对象的某个值，那么任何后续访问都不会返回该值之前的值）

单调写一致性：一个进程对数据项 x 执行的写操作必须在该进程对 x 执行任何后序写操作之前完成。（系统保证来自同一个进程的写操作顺序执行）

### 7.4 副本管理

对于任何支持副本的分布式系统来说，关键的问题是决定何处、何时、由谁、用什么机制来保持副本的一致性。副本放置问题：副本服务器的放置问题和内容的放置问题。

#### 7.4.1 副本服务器放置

本质：从N个可能的位置找出k个最佳的位置。

- 假定已经放置了k个服务器，需要从N-k个服务器中选择一个最佳的服务器，与所有客户端之间的距离最小，计算复杂度过高

- 选择第k大的自治系统，然后在含有最大数量的连接的路由器上放置一台服务器，以此类推。计算复杂度高
- 假定在一个d维的几何空间中放置服务器，节点之间的距离反映了延迟。把整个空间划分为多个单元，选择k个密度最大的单元放置副本服务器。计算复杂度较低

#### 7.4.2 内容放置

一个进程能维护对象或者数据的副本。三种不同的进程维护：

- 永久副本：进程/机器持久存储副本数据
- 服务器启动的副本：进程可以动态地持有副本，该副本在初始化数据存储的所有者时创建
- 客户端启动的副本：当客户端初始化时创建的副本

不同类型的副本逻辑地组织成三个同心环。

服务器初始化的副本，动态复制要考虑的问题：

- 复制可能是为了减轻一台服务器的负载而进行的
- 一台服务器上制定的文件可能被转移或复制到对这些文件提出很多请求的客户附近的服务器，来自不同客户端的请求计数。一个进程维护对象或者数据的副本，记录访问次数：
  - 如果请求数量低于阈值D则删除文件
  - 如果请求数量高于阈值R则复制文件
  - 如果在D和R之间则考虑移动文件

#### 7.4.3  内容分发

要实际传播哪些信息：

- 只传播更新的通知，常用于缓存
- 将数据从一个副本传送到另一个副本，即被动复制
- 把更新操作传播到其他副本，即主动复制

没有哪一个方法是最佳的选择，高度依赖于可用的网络带宽和副本上的读写比率

在客户端-服务器系统中，有：

- 基于push的更新：服务器初始化的方法，不需要其他副本请求更新，这些更新的就被传播到那些副本中
- 基于pull的更新：客户端初始化的方法，客户端请求更新
- 利用租用lease的方式，在pull个push之间动态切换。租用是服务器作的承诺，在指定的时间内把更新推给客户。租用到期改为pull方式。

### 7.5 一致性协议

一致性协议描述了特定的一致性模型的实现。

#### 7.5.1 连续一致性：限定数值偏差

每个服务器$S_i$有一份日志，记为$L_i$。考虑数据$x$，令$val(W)$表示在写操作$W$后$x$的数值改变。满足：
$$
\forall W,val(W)>0
$$
$W$一开始由$N$个副本中的一个发起，记为$origin(W)$。$TW[i,j]$表示服务器$S_i$执行$S_j$发起的的写操作。有：
$$
TW[i,j]=\sum\{val(W)|origin(W)=S_i\&W\in L_i\}
$$
$x$的实际值为：
$$
v(t)=v_{init}+\sum^N_{k=1}TW[k,k]
$$
在$S_i$上的$v_i$值为：
$$
v_i=v_{init}+\sum^N_{k=1}TW[i,k]
$$
要确保有：
$$
\forall i,v(t)-v_i<\delta_i
$$
考虑让每个服务器$S_k$保存一个视图$T_k[i,j]$表示它对$TW[i,j]$的估计。更新传播时可以用来传递。有：
$$
0\leq TW_k[i,j]\leq TW[i,j]\leq TW[j,j]
$$
其思想是，当服务器$S_k$直到$S_i$与提交给$S_k$的更新操作步调不一致时，它就把写操作从其日志中转发给$S_i$。该转发操作可以有效地把$S_k$的视图$TW_k[i,k]$往$TW[i,k]$靠近，使得偏差更小。尤其当应用程序提交一个新的写操作时，$S_k$会把其视图往$TW[i,k]$推进，这使得偏差大于$\delta_i/(N-1)$。

#### 7.5.2 连续一致性：限定复制的新旧程度偏差

核心思想：让服务器$S_k$保持实时向量时钟$RVC_k$，其中$RVC_k[i]=T(i)$表示到时间$T(i)$时，$S_k$已经看到了已经提交给$S_i$的所有写操作。

只要服务器$S_k$通知$T[k]-RVC_k[i]$将超出指定的界限，那么它就开始拉入来自$S_i$的时间戳晚于$RVC_k[i]$的写操作

#### 7.5.3 连续一致性：限定属性偏差

暂时将写操作加入本地队列。当本地队列的长度超过指定的最大长度时，服务器不再接受任何新提交的写操作，而是按照相应的顺序提交写操作。

#### 7.5.4 其他协议

- 基于主备份的协议：有一个主备份服务器。当发生写操作时，收到写操作的服务器发送写操作请求给主备份。主备份给所有服务器（包括备份服务器）发送更新通知，所有服务器返回更新确定。如果是读操作则直接读，不需要给主备份服务器发送请求。
  - 远程写协议：副本位于LAN，用于传统的分布式数据库和文件系统，有较高的容错性
  - 本地写协议：会将主备份的内容转移到离客户端近的服务器，从而进行主备份服务器的转移。主要用于离线模式下的移动计算机，在断线之前传递相关文件
- 复制的写协议：基于团体的协议：区分写团体和读团体。操作需要大多数投票才执行。

---------

## 八、 容错

分布式系统的设计目标之一是允许部分失效

幂等（idempotent）：重复多次执行与执行一次的结果是相同的；

### 8.1 基本概念

#### 8.1.1 可依赖性dependability

提供服务的软件可能需要来自其他组件的服务（服务依赖），即组件可能依赖于其他组件，那么就要考虑组件是否可靠。相关需求包括：

- 可用性availability：为了使用，能够进行读操作
- 可靠性reliability：服务传输的持续性
- 安全性safety：低概率产生问题
- 可维护性maintainability：失效的系统的修复有多困难

##### 可靠性

组件C的可靠性$R(t)$表示，从开始时刻$T=0$，经历一段时间$[0,t)$后仍然能提供正常功能的条件概率。传统的度量方法包括：

- 平均失效时间MTTF
- 平均恢复时间MTTR
- 两次失效的平均时间MTBF：MTTF+MTTR

##### 可用性

组件C的可用性$A(t)$表示在$[0,t)$的时段内，组件可用的时间比例。长期可用表示为$A$或$A(\infin)$。有：$A=\frac{MTTF}{MTBF}=\frac{MTTF}{MTTR+MTTF}$。可靠性和可用性只有在定义清楚什么是失效时才有意义。

#### 8.1.2 失效

- 失效failure：组件失效，如程序崩溃
- 错误error：组件的部分可能产生失效的部分，如程序bug
- 故障fault：错误的产生原因，如程序员

故障分类：

- 暂时故障：只发生一次，不会重复发生
- 间歇故障：反复周期性发生
- 持久故障：被修复之前持续存在的故障

失效模型：

- 崩溃失效：运行正常，直到崩溃
- 泄漏失效：收发消息失败或回应请求失效
- 时间失效：超时
- 回复失效：回复值、控制流等出错
- 任意失效

泄漏性omission的失效是组件没有执行相应行为导致的失效，而执行性commission失效是组件执行了它不应该执行的行为导致的失效。区分停机和遗漏性失效是几乎不可能的。一般认为系统是同步系统，从而能检测泄漏和及时故障。

考虑冗余掩盖故障：

- 信息冗余：数据单元中添加额外的位数据使得错乱的位恢复正常
- 时间冗余：系统出错时再次执行相关动作（事务处理）
- 物理冗余：通过添加额外的装备或进程使得系统作为一个整体来容忍部分组件的失效或故障

### 8.2 进程恢复

基本思想：通过进程复制来防止进程出现问题。将多个进程放在一个进程组里，包括：

- 平等组：所有进程平等
- 分级组：进程分为组织者和工作者

当一个组可以屏蔽任何K个并发成员的失效，则该组成为K-容错组，K称为容错度。如果发生的是停止失效，则需要K+1个成员数保证结果的有效输出。但是如果发生的是随意失效，则需要2K+1个成员才能保证结果的正确输出。大前提是所有的成员都是同质的，且所有成员以相同的顺序执行命令。

在一个容错组里面，每一个非故障进程执行的命令以及执行的顺序与其他非故障进程相同，则需要使得这些进程就“由谁来执行命令”这一问题达成一致，且在有限的步骤内达成一致。这个过程称为达成“共识”。

#### 8.2.1 基于泛洪的共识

给定一个进程组$P=\{P_1,P_2,...,P_n\}$，且能精确的找到系统失效，则一个客户端让$P_i$执行相关命令时，每个进程$P_i$维护一个发出命令的列表。

基于轮数的基本算法：

1. 在第$r$轮，$P_i$将它知道的命令集$C_i^r$多播给其他进程
2. 每个$P_i$在本轮末归并所有收到的命令，生成下一轮的命令集$C_i^{r+1}$
3. 下一条指令$cmd_i$通过全局共享的决策函数决定

进程之间的通信是不可靠的，消息可能丢失、重复和乱序。

#### 8.2.2 拜占庭协议BA

- BA1：每个没有失效的备份进程存储相同的值
- BA2：如果主进程没失效，则每个没失效的备份进程存储与主进程发送的一致的值

在会出现通信失效的网络环境下，实现一个具有原子读写的共享内存同时又保证每一个请求都得到响应是非常困难的

进程总数>3*出错进程数+1

### 8.3 可靠的通信方式

- 不能定位服务器：将错误信息反馈给客户端
- 请求丢失：重新传输请求

完全透明的服务器恢复是不可能的，没有一种客户策略和服务器策略的结合可以在所有可能的失效事件顺序下正确工作

对于可靠RPC故障：

- 丢失应答信息：客户端感知到的是没有接收到应答，但是不能断定原因是丢失请求，服务器宕机还是丢失响应。
- 服务器宕机：解决方法：至少执行一次和至多执行一次语法
- 客户端崩溃：服务器还在工作，并且持有资源但是没有客户端需要结果（称为孤儿计算）。解决方法：
  - 孤儿消灭：客户端恢复时杀死孤儿
  - 再生：客户端恢复时向所有服务器广播新时期的开始，由服务器杀死和客户端相关的孤儿
  - 优雅再生：服务器检查远程调用，找不到拥有者则杀死计算
  - 到期：设置工作的时间上限

可靠组通信：将消息可靠地发送到进程组，每个进程都能接受到消息：

- 可靠多播：消息发送和接收按照发送者发送的顺序进行。接收方过多时返回确认消息时发送方会被淹没。可以让接收方不反馈，在发现消息丢失时才反馈：
  - 无等级反馈控制：接收方发现丢失一条消息时向组中其他成员反馈，一直其他成员的发送请求，使得最终只有一条反馈信息回到发送方
  - 分等级的反馈控制：接收方分为很多子组，组织成树的形式，包含发送方的子组构成了树的根
- 原子多播：消息要么发送给所有进程，要么不向任何进程发送，而且所有的消息都按照相同的顺序发送给所有的进程。
  - 如果消息的发送方在多播期间崩溃，那么消息要么投递给剩余的进程，要么被每个进程忽略，具有这种属性的可靠多播被称为虚拟同步
  - 将消息排序，分为：不排序多播、FIFO顺序的多播，按因果关系排序的多播和全序多播

### 8.4 分布式提交

一个操作要么被进程组中的每一个成员执行，要么一个都不执行。

#### 8.4.1 两段提交协议2PC

发起计算的客户端作为协调者，其他进程是参与者：

1. 第1a阶段：协调者发送投票请求给参与者（称为预写）
2. 第1b阶段：参与者收到投票请求后，返回投票确认消息或投票终止消息。如果丢弃，则它终止了本地计算
3. 第2a阶段：协调者收集所有投票，如果全都是确认消息则发送全局确认给所有参与者，否则发送全局终止
4. 参与者按照消息执行相应操作

当需要分布式提交时，让参与者使用临时的工作空间保存结果，这样当出现失效时能够比较方便地恢复结果。协作者失效，整个协议执行过程有可能阻塞，因此2PC也称为阻塞协议

#### 8.4.2 三阶段提交协议

两节点提交的一个问题在于当协作者崩溃时，参与者不能做出最后的决定，处于阻塞状态，为了解决这一问题，提出了三阶段提交协议。将二阶段确认改为预确认PRECOMMIT，之后新增一个实际的确认COMMIT

### 8.5 系统恢复

发生错误时，需要将系统变为无错误状态：

- 向前错误恢复：找到系统能继续执行操作的状态
- 向后错误恢复：将系统带回之前的无错误的状态

利用向后恢复，需要设置恢复点。分布式系统中的恢复更加复杂，因为需要多个进程协作找出通过恢复可以达到一致的状态的地方。接收的每一个消息都应该有一个发送者记录。假定每一个进程都会周期性记录检查点，最近一次的全局一致的检查点就是恢复线路。

每个进程的检查点是以一种不协调的方式来按时记录本地状态，这种分布式特性使得找到一个恢复线路非常困难，可能会导致多米诺效应。

- 独立检查点：每个进程独立进入检查点。有级联回滚到系统启动时的风险
- 协调检查点：每个进程在全局协商后进入检查点。可以只考虑依赖于协调者的进程而忽略其他的

- 日志消息：通过重放replay的方式达到一个全局一致的状态而不需要从持久存储中恢复该状态

- 面向恢复的计算RoC

----

### 九、 Paxos

### 9.1 共识问题

有的节点通过发送消息给其他节点来执行操作，所有节点必须通过决定接受或否决这些消息。但并发的不确定性和故障问题带来了很多麻烦。考虑：

- 安全性：
  - 合法性：只有被发送的值可以被选择
  - 一致性：有效节点只能选取相同的值
  - 完整性：一个节点最多选择一次
- 活性：终止，每个节点最终选择了一个值

### 9.2 2PC协议

协调者（事务管理）：发起事务，对提交和中止作出回应

参与者（资源管理）：分布式事务中使用数据的服务器

1. 准备阶段：协调者询问每个参与者是否可以提交commit，参与者检查存储和锁后决定提交或中止。如果确认提交后不允许中止。

2. 提交阶段：协调者收集全部投票，如果全部提交则提交，否则中止，并向参与者发送结果

异步系统中的一组处理器不可能对二进制值达成一致，即使只有一个进程发生了未宣布的故障。问题的核心是异步。

### 9.2 Paxos

#### 9.2.1 基本概念

唯一已知的完全安全且基本有效的协议协议。

角色分为：

- 提议者proposers：提供建议值
- 接受者acceptors：决定提议的值是否可以采用，生成接受或拒绝的决策
- 学习者learners：学习选择的值

一个节点可以扮演多个角色，通常三个都扮演。当只有一个接受者时，和2PC协议类似。接受者的失效可能导致整个协议的堵塞，因此需要多个接受者。接受者必须接受收到的第一个提议。为了防止每个提议票数都很少，每个接受者可以接受多个提议。

在Paxos中，基本概念如下：

- 提议者：发起Paxos进程
- 接受者：存储节点，接收、处理、存储消息
- 仲裁者Quorum：接受者的多数派，n/2+1个接受者
- 轮round：一轮包含2个阶段。每轮的编号`rnd`单增，用于区分提议者

- `last_rnd`：接受者看到的最大的`rnd`，用于识别哪个提议者可以写
- `value(v)`：接受者接受的值
- `vrnd`：接收者接受`v`时的`rnd`
- 值“被确定”：多于半数的接受者接受了该值

#### 9.2.1 两阶段过程

- 阶段1：
  - 接受者收到请求：
    - 请求的`rnd`小于`last_rnd`则直接拒绝，否则用`rnd`更新`last_rnd`。之后该接受者只接受带有该`rnd`的二阶段请求
    - 返回应答（拒绝也要返回），带上自己**之前**的`last_rnd`和**之前**已经接受的`v`
  - 提议者收到应答：
    - 如果应答的`last_rnd`大于发出的`rnd`则退出，否则从所有应答中选择`vrnd`最大的`v`。如果所有的`v`都为空则可以选择自己写入`v`
    - 如果应答不够多数派，退出
- 阶段2：
  - 提议者：发送二阶段请求，带上`rnd`和上一步决定的`v`
  - 接受者：
    - 拒绝`rnd`不等于`last_rnd`的请求
    - 将收到的`v`写入本地作为已接受的值单调

其实还有个第三阶段，接受者发送第三阶段消息给所有学习者，让学习者知道一个值被确定了，而多数场合提议者就是学习者。

活锁：多个提议者并发对一个值进行paxos可能会相互覆盖对方的`rnd`然后提升自己的`rnd`再次尝试，然后再次产生冲突，一直无法完成

### 9.3 RAFT

RAFT分解：

- 领导人选举：选择一个服务器作为领导人
- 日志重复：领导人接收来自客户端的命令并加入日志，将日志复制给其他服务器（重写不一致）
- 安全：保持日志一致，只有有最新的日志的服务器可以成为领导人

保证安全性：每次最多一个领导人、活性：一定有领导人被选出

----------

## 十、 分布式文件系统

- 通过网络互连，文件共享
- 分布式：文件系统的客户端、服务器、存储需要分散在不同的物理机器上
- 透明性：对于用户来说，使用起来就是像集中式文件系统
- 性能
- 并发文件更新：支持多用户

### 10.1 架构

NFS架构（network file system）：采用VFS（虚拟文件系统）实现。VFS是不同文件系统接口的事实标准，屏蔽了访问本地和远程文件的差异性。

数据集非常大时不适用客户端-服务器架构。解决方案：

- 加速文件访问速度，应用文件分片划分技术使得文件可以并行访问
- 将文件分散成较大的数据块，将数据块分布复制到多个物理机器上

基于集群的分布式文件系统GFS：GFS主服务器只是在内存中维护了一张文件名到块服务器的映射表，大量的实际工作是由块服务器完成的。文件采用主备模式复制，主服务器避开循环。因此主服务器往往不会成为瓶颈。

### 10.2 同步

- 立即将缓存文件的所有改动传回服务器，简单但效率低
- 对打开文件的改动只有在关闭时才对其他进程可见
- 文件不可改变
- 使用原子事务处理共享文件

- 文件锁定：加锁、共享预约：客户打开文件时指定访问类型，与服务器要拒绝的其他客户的访问类型

### 10.3 一致性和复制

- 客户打开文件时将它从服务器获得的数据缓存起来进行读写，关闭时把写的结果返回给服务器
- 服务器将某些权限委托给客户（开放式委托），允许客户在本地处理同一机器其他客户的操作

P2P节点的不可用性非常高，考虑冗余性方案。

擦除编码：通过把一个文件分成m块，把它记录到大于m个块（n个）中，任何m个编码块的集合都能用于构造原始文件。则冗余性因子$r_{ce}=\frac nm$。

-------------


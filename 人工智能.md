# 人工智能

## 一、 人工智能概述

### 1.1 理论与概念

 信息与物质及能量构成整个宇宙。人们不能直接认识物质和能量，而是通过物质和能量的信息来认识它们。信息经过感觉输入到神经系统，再经过大脑思维变为认识。认识就是用符号去整理研究对象，并确定其联系。知识是用人们对于可重复信息之间的联系的认识，知识也就是被认识了的信息和信息之间的联系，它是信息经过加工整理、解释、挑选和 改造而形成的。

智能 = 知识集 + 智力，智能主要指运用知识解决问题的能力, 推理、学习和联想是智能的重要因素。

### 1.2 研究方法

- 符号主义学派：人工智能源于数理逻辑。将数学严格公理化，从公理出发经逻辑推理得到引理、定理、推论。
- 联结主义学派：人工智能源于仿生学。通过神经网络的构建与连接机制与学习算法实现人工智能。从微观上模拟人类的认知功能。
- 行为主义学派：人工智能源于控制论及“感知-动作”的控制系统。智能取决于感知和行动，人工智能像人类智能一样逐步进化，智能行为智能在现实世界中与周围环境交互作用而表现出来。

----

## 二、 样例学习：分类

预测离散变量：基于一个包含x值和离散真实y值的训练集构建离散分类模型，用该模型预测新的只包含x值的测试数据集的y值。

评测指标：

- 准确率
- 速度（训练速度、预测速度）
- 鲁棒性：处理噪音和缺失值方面的能力
- 可扩展性：用在更大规模的数据集上的能力
- 可解释性

### 2.1 K-近邻

将测试数据的特征与训练集数据的特征进行比较，找到K个最相似的数据（K一般不大于20），用这K个数据的标签决定测试数据的标签。

优点：精度高、对异常值不敏感、无数据输入假定；缺点：时间和空间复杂度高；适用范围：同时适用于离散和连续型数据

判断数据相似性一般使用`Lp`距离：
$$
\displaystyle L_p(x_i,x_j)=(\sum^n_{l=1}|x_i^{(l)}-x_j^{(l)}|^p)^{\frac{1}{p}}
$$
其中，`l`表示一个样本数据（向量）的不同维度，下标`i`和`j`表示两个不同的样本，`p`为参数。当`p=2`时就是日常生活常用的**欧式距离**（如二维或三维空间求两点的距离），`p=1`称为**曼哈顿距离**或**街道距离**。当`p=∞`时称为**L∞距离**，此时$\displaystyle L_\infin(x_i,x_j)=\max_l|x_i^{(l)}-x_j^{(l)}|$。

`K`和`p`值的确定一般都依据经验法则，换句话说，“炼丹”。通过不断的调整测试参数，选取最优的。

### 2.2 决策树

决策树技术发现数据模式和规则的核心是归纳算法，是从特殊到一般的过程。归纳对于认识的发展和完善具有重要的意义。人类 知识的增长主要来源于归纳学习。归纳学习由于依赖于检验数据，因此又称为检验学习。 任一假设如果能够在足够大的训练样本 集中很好的逼近目标函数，则它也能在 未见样本中很好地逼近目标函数，该假定是归纳学习的有效性的前提条件。

基本步骤：

1. 模型构建（归纳）：通过对训练集的归纳，建立分类模型
2. 预测应用（推论）：依据建好的模型对测试集合进行测试

决策树是一种典型的分类方法，本质上是通过一系列规则对数据进行分类的过程。

优点：

- 推理过程易理解，都能用`if-then`形式表示
- 推理过程完全依赖于属性变量的取值特点
- 可以自动忽略对目标变量没有贡献的属性变量，也为判断属性变量重要性，减少变量数目提供参考

#### 2.2.1 CLS算法

 CLS是早期的决策树学习算法，是许多决策算法的基础。

基本步骤：

1. 初始化为一颗空决策树和一个训练样本属性表
2. 若样本集T中的所有样本属于同一类则生成节点T并终止算法，否则进行下面的步骤：
3. 依据**某种策略**选取一个属性A作为测试实现，并生成测试节点A
4. 依据A的取值的不同将T划分为若干子集
5. 从训练样本属性表中删除属性A
6. 对每个子集递归调用本过程

步骤3中的策略选择对模型构建有着举足轻重的效果。

#### 2.2.2 ID3算法

##### 公式与定义

ID3算法是一种经典的决策树学习算法，主要针对属性选择问题，是决策树学习方法中最具影响和 最为典型的算法。 

设`X`是一个取值个数有限的离散随机变量，概率分布为$P(X=x_i)=p_i, i=1,2,3...,n$，则随机变量X的**熵**定义为：
$$
\displaystyle H(X)=-\sum_{i=1}^np_i\log p_i
$$
**熵越大，随机变量的不确定性越大。**熵只依赖于X的分布，与其具体取值无关，故上述公式的`H(X)`也可以写作`H(p)`。对数以2为底或以e为底，此时熵的单位分别称为比特`bit`或纳特`nat`。

设有随机变量`(X,Y)`，其联合概率的分布为$P(X=x_i,Y=y_j)=p_{ij}, i=1,2,...,n; j=1,2,...,m$。则有**条件熵**`H(Y|X)`表示已知`X`的条件下随机变量`Y`的不确定性。定义为`X`给定条件下`Y`的条件概率分布的熵对`X`的数学期望：
$$
H(Y|X)=\sum^n_{i=1}p_iH(Y|X=x_i)
$$
简单理解，$p_i$就是`X`的每种取值的概率，$H(Y|X=x_i)$就是在`X`的该种取值下，将数据集划出了一个子集，求该子集的熵。

当熵和条件熵中的概率分别由数据估计得到时，所对应的熵与条件熵分别称为经验熵和经验条件熵。定义特征A对训练数据集D的**信息增益**为集合D的经验熵与特征A给定条件下的经验条件熵之差：
$$
g(D,A)=H(D)-H(D|A)
$$
信息增益表示得知特征X的信息而使得类Y的信息的不确定性减少的程度。熵`H(Y)`和条件熵`H(Y|X)`之差称为互信息mutual information。决策树学习中的信息增益等价于训练数据集中类与特征的互信息。

##### 信息增益算法

- 训练数据集为D，|D|表示样本容量
- 设有K个类$C_k, k=1,2,...,K$，模表示属于该类的样本个数
- 依据特征A的n个不同取值$\{a_1,a_2,...,a_n\}$，将D划分为n个子集$\{D_1,...,D_n\}$
- 记子集$D_i$中属于类$C_k$的样本集合为$D_{ik}$

输入训练数据集D和特征A，输出`g(D,A)`

1. 计算数据集D的经验熵：

$$
\displaystyle H(D)=-\sum_{k=1}^K\frac{|C_k|}{|D|}\log_2\frac{|C_k|}{|D|}
$$

2. 计算特征A对数据集D的经验条件熵：

$$
\displaystyle H(D|A)=\sum^n_{i=1}\frac{|D_i|}{|D|}H(D_i)=-\sum^n_{i=1}\frac{|D_i|}{|D|}\sum^K_{k=1}\frac{|D_{ik}|}{|D_i|}\log_2\frac{|D_{ik}|}{|D_i|}
$$

3. 计算信息增益

$$
g(D,A)=H(D)-H(D|A)
$$

以信息增益作为划分训练数据集的特征，存在偏向于选择取值较多的特征的问题（即该属性划分出的子类很多，信息增益大），使用**信息增益比**可以对这一问题进行校正。C4.5决策树使用的就是信息增益比。特征`A`对训练数据集`D`的信息增益比定义为信息增益与训练数据集`D`关于特征`A`的值的熵之比：
$$
g_R(D,A)=\frac{g(D,A)}{H_A(D)}
$$
 其中，若n为特征A取值的个数，
$$
\displaystyle H_A(D)=-\sum^n_{i=1}\frac{|D_i|}{|D|}\log_2\frac{|D_i|}{|D|}
$$
简单理解就是为对A求熵。

##### ID3算法

1. 若当前数据集的标签相同，则当前位置形成树叶。否则：
2. 算出各个属性对数据集的信息增益，选取信息增益最大的属性作为节点将数据集拆分成各个子集，并删去该属性
3. 各个子集重复本算法

基本思想：以信息熵为度量用于决策树的节点的属性选择。每次优先选择信息量最多的属性，即使得熵变得最小的属性，以构造使得熵下降最快的决策树，到叶子节点时熵为0。

#### 2.2.3 决策树面临的问题

理想的决策树要求叶子节点数最少、叶子节点深度最小。找到最优决策树是NP难问题。

过度拟合over fitting。分类模型的误差可分为：

- 训练误差：训练记录上误分类样本比例
- 泛化误差：在未知记录上的期望误差

过度拟合即为训练误差低，泛化误差高。

决策树一般处理的是属性为离散数值的数据。但属性连续的数据的分类也很常见。一般将连续数值划分到几个区间进行分类。

#### 2.2.4 决策树的剪枝

通过及消化决策树整体的损失函数或代价函数来实现。设树`T`有`|T|`个叶子节点，`t`为叶节点，包含$N_t$个样本点，其中有$N_{tk}$个`k`类样本点，则有：

损失函数：
$$
\displaystyle C_\alpha(T)=-\sum_{t=1}^{|T|}N_tH_t(T)+\alpha|T|
$$
其中α是参数，大于等于0。

叶节点`t`上的经验熵为：
$$
\displaystyle H_t(T)=-\sum_k\frac{N_{tk}}{N_t}\log\frac{N_{tk}}{N_t}
$$
损失函数的第一项：
$$
\displaystyle C(T)=\sum_{t=1}^{|T|}N_tH_t(T)=-\sum^{|T|}_{t=1}\sum^K_{k=1}N_{tk}\log\frac{N_{tk}}{N_t}
$$
则：
$$
C_\alpha(T)=C(T)+\alpha|T|
$$
剪枝算法：

1. 计算每个节点的经验熵
2. 递归地从树的叶节点向上回缩
3. 所有节点都不能回缩为止

可以回缩的条件是回缩后损失函数减小了。

#### 2.2.5 分类回归树CART

CART是二叉树，不易产生数据碎片，精确度往往高于多叉树。

##### 最小二乘回归树生成算法

对于数据集$D={(x_1,y_1,(x_2,y_2,...,(x_N,y_N)}$，输入空间有M种取值，分别为$R_1,R_2,...,R_m$，使用平方误差来预测误差$\displaystyle \sum_{X_i\in R_m}(y_i-f(x_i))^2$。其中$R_m$上$c_m$的最优值为$\hat{c_m}=ave(y_i|x_i\in R_m)$。

构建二叉决策树的算法：

1. 选择最优切分变量`j`与切分点`s`。求解：

$$
\displaystyle \min_{j,s}[\min_{c_1}\sum_{x_i\in R_i(j,s)}(y_i-c_1)^2+\min_{c_2}\sum_{x_i\in R_i(j,s)}(y_i-c_2)^2]
$$

​		遍历变量`j`，对固定的切分变量`j`扫描点`s`，选择使得上式达到最小的数对`(j,s)`。

2. 用选定的数对划分区域并且决定相应的输出值：

   区域一：$R_1(j,s)=\{x|x^{(j)}\leq s\}$；区域二：$R_2(j,s)=\{x|x^{(j)}>s\}$
   $$
   \displaystyle\hat{c_m}=\frac{1}{N_m}\sum_{x_i\in R_m(j,s)}y_i,x\in R_m,m=1,2
   $$

3. 继续对两个子区域调用上述步骤，直到满足停止条件

##### 基尼指数

分类问题中，假设有`k`个类，样本点属于`k`的概率为$P_k$，则概率分布的基尼指数为：
$$
\displaystyle Gini(p)=\sum^K_{k=1}p_k(1-p_k)=1-\sum^K_{k=1}p_k^2
$$
对于二分类问题，有：
$$
Gini(p)=2p(1-p)
$$
对于给定的样本集合，有：
$$
Gini(D)=1-\sum^K_{k=1}(\frac{|C_k|}{|D|})^2
$$
如果样本集合`D`根据特征`A`是否为`a`分割成$D_1$和 $D_2$，即
$$
D_1=\{(x,y)\in D|A(x)=a\},D_2=D-D_1
$$
则在特征`A`的条件下，集合`D`的基尼指数为：
$$
Gini(D,A)=\frac{|D_1|}{|D|}Gini(D_1)+\frac{|D_2|}{|D|}Gini(D_2)
$$

##### CART的生成

1. 设节点数据集为`D`，对于每个特征`A`的每个值`a`，根据样本点对`A=a`与否将`D`分为$D_1$和$D_2$，并计算`A=a`的基尼指数
2. 在**所有特征**`A`以及**所有可能的切分点**`a`中，选择基尼指数最小的特征和切分点，将数据集分配到两个子节点中
3. 对子节点递归调用上述步骤

---------

## 三、 样例学习：回归

### 3.1 线性回归与最小二乘法

线性回归就是找到合适的$w_0$和$w1$，使得$\displaystyle\sum^n_{i=1}(y_i-w_0-w_1x_i)^2$最小。记
$$
Q(w_0,w_1)=\min_{w_0,w_1}\sum^n_{i=1}(y_i-w_0-w_1x_i)^2
$$
则必须满足：
$$
\frac{dQ(w_0,w_1)}{dw_0}=\frac{dQ(w_0,w_1)}{dw_1}=0
$$
即对$w0$有：
$$
-2\sum^n_{i=1}(y_i-w_0-w_1x_i)=0
$$
对$w1$有：
$$
-2\sum^n_{i=1}x_i(y_i-w_0-w_1x_i)=0
$$
最小二乘法，取：
$$
w_0=\overline y - w_1 \overline x
$$

$$
w_1=\frac{\sum^n_{i=1}x_i(y_i-\overline y)}{\sum^n_{i=1}x_1(x_1-\overline x)}=\frac{\sum^n_{i=1}(x_i-\overline x)(y_i-\overline y)}{\sum^n_{i=1}(x_i-\overline x)^2}
$$

### 3.2 逻辑回归模型

使用最小二乘法的回归模型进行二分类任务（真实结果为0或1），用`y`值表示属于其中一个类的概率，则：
$$
y=w_0+\sum^d_{j=1}w_jx_j+u=\tilde W^T\tilde X
$$
预测值可能不在范围[0,1]内。logit变换可以解决该问题：
$$
\log(\frac{p}{1-p})=w_0+\sum^d_{j=1}w_jx_j+u
$$
其中$p$为事件$y$发生的概率，$p/(1-p)$被称为几率比或优势比。取对数称为logit。logistic函数使得输出的概率在(0,1)的范围内。样本$X$标签为正的概率$p(y=1|X)$为：
$$
p=\frac{1}{1+e^{-w_0-\sum^d_{j=1}w_jx_j}}=\frac{e^{w_0+\sum^d_{j=1}w_jx_j}}{1+e^{w_0+\sum^d_{j=1}w_jx_j}}=\frac{1}{1+e^{-\tilde W^T\tilde X}}=\frac{e^{\tilde W^T\tilde X}}{1+e^{\tilde W^T\tilde X}}
$$
如果$w_0\sum^d_{j=1}w_jx_j$为0则$p$为0.5，如果原式趋于负无穷或正无穷，则$p$趋近于0或1。对于权重参数$w$的获得，可以使用极大似然估计，配合迭代式方法，计算出最终的模型：

1. 随机初始化权重，并对某个样本进行预测
2. 计算这个模型在这次预测上的误差，改变权重，以提高模型在这个样本上的似然度
3. 重复这个过程，直到模型收敛，即当前模型和上一步的模型的表现相差无几

似然函数：
$$
\prod^n_{i=1}(p_i)^{y_i}(1-p_i)^{1-y_i}
$$
极大似然法：
$$
L(\tilde W)=\sum^n_{i=1}(y_i\log p_i+(1-y_i)\log(1-p_i))=\sum^n_{i=1}(y_i\log\frac{p_i}{i-p_i}+\log(1-p_i))=\sum^n_{i=1}(y_i\tilde W^T\tilde X_i-\log(1+e^{\tilde W^T\tilde X_i}))
$$

$$
\frac{dL(\tilde W)}{d\tilde W}=\sum^n_{i=1}[(y_i-\frac{e^{\tilde W^T\tilde X_i}}{1+e^{\tilde W^T\tilde X_i}})\tilde X_i]
$$

等价于最小化下面的代价函数（交叉熵）：
$$
C(\tilde W)=-L(\tilde W)=-\sum^n_{i=1}(y_i\log p_i+(1-y_i)\log(1-p_i))
$$

### 3.3 梯度下降

计算梯度向量，每次用梯度向量的反方向来更新权重：

重复下式直至收敛：
$$
\tilde W_{new}^{(j)}=\tilde W^{(j)}-\eta\frac{dC(\tilde W)}{d\tilde W^{(j)}}=\tilde W^{(j)}-\eta\sum^n_{i=1}[(\frac{e^{\tilde W^T\tilde X_i}}{1+e^{\tilde W^T\tilde X_i}}-y_i)\tilde X_i^{(j)}]
$$

------

## 四、 人工神经网络：感知机Perceptron

感知机学习算法PLA：对连续性数据做统一处理。离散型属性需要转化为连续随机变量。对于拥有d个特征的$\bold x=(x_1,x_2,...,x_d)$计算其带权分数：如果$\sum^d_{k=1}w_kx_k>threshold$则预测为1，否则为-1。换言之，预测值：
$$
h(\bold x)=sign((\sum^d_{k=1}w_kx_k)-threshold)=sign((\sum^d_{k=1}w_kx_k)+(-threshold)*1）
$$
若记$-threshold$为$w_0$，1为$x_0$，则上式可写为：
$$
h(\bold x)=sign(\sum^d_{j=0}w_jx_j)=sign(\tilde W^T\tilde X)
$$
需要确定权值向量$\bold w$。可以先初始化$\bold w_{(0)}$，然后通过数据集来修正$\bold w$：

1. 找到$\bold w_{(t)}$预测错误的数据$(x_{i(t)},y_{i(t)})$，即$sign(\tilde w_{(t)}^T\tilde x_{i(t)})\neq y_{i(t)}$
2. 修正权值：$\tilde w_{(t+1)}=\tilde w_{(t)}+y_{i(t)}*\tilde x_{i(t)}$(等号表示赋值)

3. 重复上述步骤直到没有错误

最终的结果记为$\bold w_{PLA}$。

 仅当存在某个超平面，能够正确划分所有数据时, PLA算法会收敛。遍历数据的顺序不同，可能会导致结果不同， 因此有多个解存在。

-----

## 五、 人工神经网络：神经网络模型

神经网络模型由大量简单的交互节点组成 (人工神经元)，知识由这些节点之间的连接强度来表示。知识是通过学习过程调整连接而获得的，所有的神经元同时并独立地处理他们的输入，神经网络中的计算单位是人工神经元。

人工神经元的组分：

- 输入信号`x`，代表来自环境的数据或其他神经元的激活activation
- 一组实数值权重`w`，表示连接强度
- 激活层$\sum_iw_ix_i$，神经元的激活层由加权输入的总和确定
- 阈值函数`f`，通过确定激活是低于还是高于阈值来计算最终输出

感知学习机算法PLA可以用于调整人工神经元的权重，直到神经元的输出和训练样例的真实输出一致。$w_{(t+1)}=w_{(t)}+y_{n(t)}x_{n(t)}$(等号表示赋值)。但是感知机学习算法不能解决模式不可线性分离的问题。需要多层网络来解决这个问题。

输入和输出节点之间的附加层称为隐藏层，嵌入在这些层中的节点被称为隐藏节点。一个前馈神经网络(feedforward neural networks)，其中一层中的节点仅连接到下一层中的节点。神经网络的模型训练算法的每次迭代有两个阶段：

- 前向传递阶段forward phase：从前一次迭代获得的权重被用来计算每个神经元的输出值，在计算第(l + 1)层的输出之前计算第(l) 层处的神经元的输出
- 反向传递阶段backward phase：权重更新方程应用于 相反的方向，第(l + 1)层的权重在更新第(l) 层的权重之前被更新。这种学习算法允许我们使用第(l + 1)层 神经元的误差来估计第(l)层神经元的误差

对于这种类型的网络，不使用PLA的阈值函数，而是使用另一个激活函数activation function。常用激活函数：

- 双曲正切函数：

$$
f(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}}=\frac{e^{2x}-1}{e^{2x}+1}
$$

$$
f'(x)=1-f^2(x)
$$

- sigmoid函数：

$$
f(x)=\frac{1}{1+e^{-x}}
$$

$$
f'(x)=f(x)(1-f(x))
$$

前向传播输入：

给定隐藏层或输出层的单元`j`，单位`j`的净输入$I_j$为：
$$
I_j=\sum_iw_{ij}O_i+\theta_j
$$
其中，$w_{ij}$是从上一层单元`i`到单元`j`的连接权重，$O_j$是上一层单元`i`的输出，$\theta_j$为单元偏置。

给定单元`j`的输入$I_j$，则单位`j`的输出$O_j$为（使用sigmoid函数）：
$$
O_j=\frac{1}{1+e^{-I_j}}
$$
反向传播误差：

对于输出层中的单元`k`，`T`为真实值，则计算误差：
$$
Err_k=O_k(1-O_k)(T_k-O_k)
$$
隐藏层单元`j`的误差为：
$$
Err_j=O_j(1-O_j)\sum_kErr_kw_{jk}
$$
更新的权值：
$$
w_{jk}=w_{jk}+\eta Err_kO_j
$$

$$
\theta_k=\theta_k+\eta Err_k
$$

为了最小化节点$O_k$的误差，将其定义为$E=\frac{1}{2}e^2=\frac{1}{2}(T-O)^2$，为了调整，先$w_{jk}$计算在$w_{jk}$上`E`的偏导数：
$$
\frac{dE}{dw_{jk}}=\frac{dE}{de}*\frac{dE}{dO_k}*\frac{dE}{dw_{jk}}=-e*(O_k(1-O_k))*O_j=-(T_k-O_k)O_k(1-O_k)O_j
$$
然后使用梯度下降法。

反向传播学习算法是基于错误曲面的思想，表面代表了作为网络权重函数的数据集上的累积误差，曲面表示数据集上的累积误差每个可能的网络权重配置，由表面上的点表示为网络权重的函数。

缺点：

- 训练时间长
- 通常需要经验最佳确定的多个参数，例如网络拓扑或结构
- 可解释性差：难解释网络总学习权重和隐藏单位背后的象征意义

优点：

- 高鲁棒性
- 非常适合于连续值输入和输出
- 在广泛的实现数据上取得成功
- 最近已经开发了用于训练的神经网络提取规则的技术：
  - 网络修剪network pruning：通过取出影响最小的加权连接简化网络结构
  - 敏感性分析：评估给定输出变量对网络输出的影响

-------

## 六、 盲目搜索

### 6.1 问题引入和形式化描述

考虑以下部分对搜索问题进行形式化定义：

- 状态空间state space：表示需要进行搜索的空间。状态空间是对问题的形式化定义。
- 动作action：表示从一个状态到另一个状态。动作是对真实的动作的形式化
- 初始状态initial state：当前状态的表示
- 目标goal：需要到达的目标状态的表示
- 启发方法heuristics：用于指挥搜索的前进方向

把问题形式化为对状态空间的搜索问题之后，就可以使用各种搜索算法解决问题。问题的解是由“动作”构成的序列。序列中的动作可以将初始状态转化为目标状态。

例子1：罗马尼亚旅行问题（带权图起点到终点最短路径）：

- 状态：可以到达的任意一个城市
- 动作：在相邻的城市之间移动
- 初始状态：在起点城市
- 目标状态：在终点城市
- 问题的解：旅行路线

例2：八数码问题：3*3的格子里有8个各不相同的方块和一个空。如何移动方块到达目标的排列。

- 状态：各种不同方块的摆放方式
- 动作：空格向上下左右移动。不是所有位置都能完成四种动作
- 初始状态、目标状态：某种排列方式
- 问题的解：移动空格的步骤组成的序列

例3：吸尘器世界（前面的示例中，一个状态是对应一个真实世界中的状态，但一个状态也可以对应智能体如何认识世界的情况：智能体的认知状态）：吸尘器要打扫左右两个房间。房间有两个状态：干净和不干净。吸尘器有向左和向右两个动作和吸尘的动作。

认知层面的状态空间：一个认知状态是物理状态空间的一个子集。也就是智能体知道自己处于几个物理状态中的 一个状态中，但是不知道具体是哪一个。如吸尘器世界中，依据左右房间各自是否干净和吸尘器初始在左还是右，有8种可能。认知状态是一些物理状态的集合 。

### 6.2 搜索算法

输入：

- 初始状态：一个具体的物理状态，或是多个物理状态的集合表示的认知状态
- 后继函数S(x)：x状态经过一个动作后可以到达的状态的集合
- 目标测试：一个作用于状态上，当状态满足条件时返回真的函数（停止条件）
- 前进成本C(x,a,y)：从x状态通过动作a到达y状态所需要的成本。无法到达则为无穷大。

输出：从初始状态到满足目标测试的状态的状态序列

状态x的后继状态可能来自不同的动作，后继函数S(x)返回的状态集合中的状态是x通过任何一个动作能达到的状态，因此需要把来自不同动作的后继状态加以区分。S(x)的返回值不仅要包括后继状态，还要记录获得这个后继状态所经过的动作。

 边界：还没有被探索，但准备下一步探索的状态的集合。边界不是状态的集合而是路径的集合，因此只要路径不同就会往边界上添加新的元素，导致了循环问题。

状态选择的顺序会对搜索操作产生重要的影响:

- 影响搜索是否能找到解 
- 影响搜索到的解的成本大小 
- 影响搜索过程中所需要的时间和空间资源

因此，搜索算法需要有以下特性：

- 完备性completeness：搜索算法是否总能在 问题存在解的情况下找到解 
- 最优性optimality：当问题中的动作需要成本时，搜索算法是否总能找到成本最小的解 
- 较低的复杂度：
  - 时间复杂度：搜索算法最多需要探索/生成多少个节点来找到解 
  - 空间复杂度：搜索算法最多需要将多少个节点储存在内存中

### 6.3 盲目搜索策略

盲目搜索策略采用固定的规则来选择下一 需要被扩展的状态，规则不会随着要搜索解决的问题的变化而变化 ，不考虑任何与要解决的问题领 域相关的信息。如：

- 宽度优先
- 深度优先
- 一致代价
- 深度受限
- 迭代加深算法

通用的选择方式： 对边界上的元素进行排序，总是选择第一个元素。任何选择规则都可以视为对边界采用某种合适的排序方式。

#### 6.3.1 宽度优先

宽度优先把当前要扩展的状态的后继状态放在边界的最后（队列处理）。

定义b为问题中一个状态最大的后继状态个数，d为最短解的动作个数，宽度优先搜索具有完备性和最优性 ：

- 短的路径会在任何比它长的路径之前被遍历 

- 给定路径长度，该长度的路径是有限的 

- 最终可以遍历所有长度为d的路径，因此一定可以找出最短的解

时间复杂度：
$$
1+b+b^2+...+b^d+b(b^d-1)=O(b^{d+1})
$$
空间复杂度：
$$
b(b^d-1)=O(b^{d+1})
$$
实际情况下，内存需求会先于时间限制算法的运行，也就是空间复杂度太大。

#### 6.3.2 深度优先

把当前要扩展的状态的后继状态放在边界的最前面，边界上总是扩展最深的那个节点。

在状态空间无限或在状态空间有限，但是存在无限的路径（例如存在回路） 的情况下不具有完备性。在状态空间有限，且对重复路径进行剪枝的情况下才有。不具有最优性。

时间复杂度：$O(b^m)$，其中m是遍历过程中最长路径的长度。当m远远大于d时，时间效率会很差。当存在多条解路径的情况下深度优先搜索可以比宽度优先搜索更快找到解 (可以碰运气先遍历了到达解的那条路径)。

空间复杂度：$O(n=bm)$，边界上只包含当前探索的最深的节点，以及回溯点 。线性的空间复杂度是深度优先搜索的一个显著的优点。

#### 6.3.3 一致代价搜索

边界中，按路径的成本升序排列，总是扩展成本最低的那条路径。当每种动作的成本是一样的时候，和宽度优先是一样的。

假设每个动作的成本≥ s > 0 ，一致代价搜索中，所有成本较低的路径都会在成本高的路径之前被扩展。给定成本，该成本的路径数量是有限的；成本小于最优路径的路径数量是有限的，最终，我们可以找到最短的路径，因此具备完备性和最优性。

当最优解的路径长度为d时，宽度优先搜索的时间和空间复杂度都是 $O(b^{d+1}) $，对于一致代价搜索，当最优解的成本为C* ，则时间和空间 复杂度为$O(b^{C^*/s+1})$。

#### 6.3.4 深度受限搜索

宽度优先搜索存在空间复杂度过大的问题，深度优先搜索存在可能运行时间非常长，甚至在存在无限路径时无限运行下去的问题。

深度受限搜索是深度优先搜索，但是预先限制了搜索的深度L，因此无限长度的路径不会导致深度优先搜索无法停止的问题。 但只有当解路径的长度 ≤ L 时，才能找到解。

不具有完备性和最优性，时间复杂度为$O(b^L)$，空间复杂度为$O(bL)$。

#### 6.3.5 迭代加深搜索

为了解决深度优先搜索和宽度优先搜索存在的问题 ，一开始设置深度限制为L = 0，迭代地增加深度限制，对于每个深度限制都进行深度受限搜索 。如果找到解，或者深度受限搜索没有节点可以扩展的时候可以停止当前迭代，并提高深度限制L 。如果没有节点可以被剪掉（深度限制不能再提高）仍然 没有找到解，那么说明已经搜索所有路径，因此这个搜索不存在解。

具有完备性，且在每个动作的成本一致时具有最优性。如果动作成本不一致，则可以使用成本边界(cost bound)代替深度限制L：只扩展成本低于成本边界的路径，每次迭代时记录当前还未扩展路径中的最小成本 ，下一次迭代则提高成本边界。这样开销会很大，迭代数量为成本数值的构成的集合的大小。

时间复杂度：
$$
(d+1)b^0+db+(d-1)b^2+...+b^d=O(b^d)
$$
迭代加深搜索可以比宽度优先搜索更高效: 不用扩展深度限制上的节点。但是宽度优先搜索需要扩展直到目标节点。 

空间复杂度：$O(bd)$。

#### 6.3.6 双向搜索

同时进行从初始状态向前的搜索和从目标节点向后搜索，在两个搜索在中间相遇时停止搜索。假设两个搜索都使用宽度优先搜索，则具有完备性，在每条边/每个动作的成本一致的情况下具有最优性。时间和空间复杂度都为$O(b^{d/2})$。

### 6.4 路径检测

在边界上保存了路径，路径检测用于确保新的状态到达的节点与它所在路径上的祖先节点都不相等，也就是说，单独检测每条路径是否出现重复节点。

环检测/多路检测：记录下在之前的搜索过程中扩展过的所有节点，当扩展当前节点获得新子节点时，确保新节点不等于之前任何扩展过的节点。不能将这个方法用于深度优先搜索，因为深度优先搜索会产生较高的空间复杂度，因此只能用于宽度优先搜索。

对于一致代价搜索，使用环检测后仍能找到最优的解。一致代价搜索在第一次扩展到某个节点时，其实已经找到了到达这个节点的成本最低的路径 ，这意味着被环检测剔除的节点不可能出现一条更短/成 本更低的路径。对于之后的启发式搜索，这个性质不一定会成立。

- 路径检测：当扩展节点n来获得子节点c时，确保节点c不等于到达节点c的路径上的**任何祖先节点**

- 环检测：记录下在之前的搜索过程中扩展过的所有节点，当扩展节点n获得子节点c时，确保节点c不等于之前**任何扩展过的节点** 

对于一致代价搜索，环检测可以保留一致代价搜索的最优性。

-------

## 七、 启发式搜索

在盲目搜索中，我们没有考虑边界上的节点哪一个更具有“前景”（promising），在许多情况下，我们可以有额外的知识来衡量当前节点，例如可以知道当前节点到达目标节点的成本，因此出现了启发式搜索。

对于一个具体的问题，构造一个专用于该领域的启发式函数h(n), 该函数用于估计从节点n到达目标节点的成本 ，要求对于所有满足目标条件的节点n有：h(n)=0。在不同的问题领域中，对成本的估计有不同的方法，如直线距离（欧氏距离）。

贪心最佳优先搜索(Greedy BFS)： 利用启发式函数来对边界上的节点进行排序，贪心地希望找到成本最低的解。这种做法忽略了从初始状态到达节点n的成本 因此这种做法可能“误入歧途”，选择了离初始状态很远（成本很高），但根据h(n)看起来离目标状态很近的节点。因此Greedy BFS 既不是完备的，也不是最优的。

### 7.1 A*搜索

定义评价函数$f(n)=g(n)+h(n)$，其中g(n)是从初始节点到达节点n的路径成本，h(n)是从n节点到达目标节点的成本的启发式估计值。 因此，f(n)是经过节点n从初始节点到达目标节点的路径成本的估计值。利用节点对应的f(n)来对边界上的节点进行排序。

h(n)的条件：

- 可采纳性：假设每个状态转移（每条边）的成本是非负的，而且不能无穷地小，假设h\*(n)是从节点n到目标节点的最优路径成本（不连通则为无穷大）。当对于所有的节点n，满足h(n)<=h\*(n)时，则称h(n)是可采纳的。也就是说，可采纳的启发式函数低估了当前节点到达目标节点的成本，使得实际成本最小的最优路径能够被选上。因此，对于任何目标节点g，有h(g)=0。

- 一致性（单调性）：对任意节点n1和n2有：h(n1)<=cost(n1->n2)+h(n2)。满足一致性的启发式函数也一定满足可采纳性，大部分的可采纳的启发式函数也满足一致性/单调性。

可采纳性意味着最优性，最优解一定会在所有成本大于最优开销的路径之前被扩展到。

h(n)= 0 时，对于任何n这个启发式函数都是单调的。 A\*搜索会变成一致代价搜索，因此一致代价的时间/空间复杂度的下界也适用于A\*搜索。 需要找到更好的h函数。

环检测的影响：启发式函数的一致性可以保证我们在第一次遍历到一个节点时，就是沿着到这个节点的最优路径扩展的，因此，只要启发式函数具备一致性，就能在进行环检测之后仍然保持最优性。如果启发式函数只有可采纳性，则不一定能在使用 了环检测之后仍保持最优性。为了解决这个问题，对于之前遍历过的节点，必须记录其扩展路径的成本。这样的话，若出现到达已遍历过节点但成本更低的路径，则需重新扩展而不能剪枝。

因为一致性，搜索第一次扩展到某个状态，就是沿着最小成本的路径进行扩展的 ，而且在遍历节点n时，所有f值小于f(n)的节点都已经被遍历过了 。

A\*搜索和宽度优先搜索、一致代价搜索一样，有潜在的空间复杂度过大的问题，因此有了IDA\*搜索，即迭代加深的A\*搜索，类似于迭代加深搜索。但用于划定界限的不是深度，而是使用f值。在每次迭代时，划定的界限是f值超过上次迭代的界限最少的节点的f值。

总结：

- 评价函数$f(n)=g(n)+h(n)$

- 利用f(n)对边界节点排序
- 可接纳性$h(n)\leq h^*(n)$
- 一致性：对于任意节点n1和n2有：$h(n1)\leq c(n1\to n2)+h(n2)$
- 启发式函数具有一致性说明其也具有可接纳性
- 启发式函数具有可接纳性说明其也具有最优性 

- A*搜索具有指数级的空间复杂度

一致性导致的结果：

- 一条路径上的节点的 f 值应该是非递减的
-  如果n2节点在n1节点之后扩展，那么f(n1) ≤ f(n2) 

-  当节点n被扩展时，f值小于节点n的路径都被扩展过了 
- A*搜索第一次扩展到某个状态，就是沿着最小成本的路径进行扩展的
- 只要启发式函数具备一致性，就能在进行环检测之后仍然保持最优性

### 7.2 启发式函数的构建

通过考虑一个比较简单的问题，并将h(n)设置为简单问题中到达目标的成本。

八数码问题中，需要满足以下条件才能将方块A移动到位置B：A方块和B位置相邻且B位置为空。

可以放松一些条件使得问题变得简单：

1. 只要方块A和位置B相邻就可以将A移动到B（不考虑B是否为空）
2. 只要B为空则可以把A移动到B（不考虑是否相邻）
3. 任何情况都可以把A移动到B（两个条件都不考虑）

由上述的1可以推导出曼哈顿距离的启发式函数，即h(n)=所有方块到达其目标位置的曼哈顿距离之和。满足可采纳性和单调性。

由上述的3可以推导出“不在目标位置方块数”的启发式函数，满足可采纳性和单调性。

所以，在松弛问题（放宽问题条件后的问题）中，到达某个节点的最优成本是原始问题中到达该节点的可采纳的启发式函数值。如果P是初始问题，$P_j$为其的松弛问题，那么问题P的解节点集合有：$Sol(P)\subseteq Sol(P_j)$。于是有$mincost(Sol(P_j))\leq mincost(Sol(P))$，从而有$h(n)\leq h^*(n)$。

### 7.3 启发式函数的比较

加入h1和h2两个启发式函数都是可采纳的，并且对于除了目标节点之外的其他节点，都有$h1(n)\leq h2(n)$，则称h2函数**支配**了h1函数，或者说，h2函数比h1含有更多信息。那么使用A*算法时，使用h2函数拓展过的节点，使用h1函数也会拓展到。

### 7.4 一些例子

#### 7.4.1 积木世界

现有互不相同的积木若干，叠在一起。有两种操作：

- 交换两块积木，前提是两块积木上方都没有其他积木
- 将一块积木放在桌子上，前提是这块积木上面没有其他积木且其不再桌子上。

初始状态：一叠积木的排列；目标状态：一叠积木的另一种排列

启发式函数：h(n)为不再目标状态中的积木数。可采纳性：对于每个不在目标状态的积木，至少需要动一步来到达。单调性：任何动作最多只能消除一个不在目标位置的积木 。

另外一种策略：积木x已经处于目标位置则说x为good tower，如果当前状态下采取某一个动作可以创建一个good tower则进行该懂你工作，否则将一个不是good tower的积木移到桌上。

#### 7.4.2 滑动积木游戏

一个盒子有七个格子，放着黑白两种木块。三个黑色在左边，三个白色在右边，最右边一个格子空着。一个木块移到相邻格子，成本为1，一个木块相邻一个或两个其他木块跳入空格，成本为跳过的木块数。目标状态为所有白色木块在黑色的左边。

令h(n)为每个白色木块前的黑色木块数目和。每个代价为n的动作使得h(n)下降至多为n，所以h(n)是单调的。

#### 7.4.3 野蛮人和传教士

N个野蛮人和N个传教士在河流的左岸，有一艘可以载K个人的船。寻求一种可以把所有人运到右岸的方法。要求在左岸、右岸、船上都要有：传教士人数大于等于野蛮人人数，或传教士人数为0。

形式化：状态使用(M,C,B)表示。M为左岸的传教士人数，C为左岸的野人人数，B=1为船在左岸，否则在右岸。动作用(m,c)表示，m为坐船的传教士人数，c为坐船的野人人数。前提条件：传教士和野蛮人人数满足题目约束。动作的效果，例如：(M,C,1)经过(m,c)变成了(M-m,C-c,0)。

当K<=3时，考虑h(n)=M+C-2B。单调性：
$$
左岸到右岸：h(n1)-h(n2)=m+c-2\leq K-2\leq1
$$

$$
右岸到左岸：h(n1)-h(n2)=2-m-c\leq1, m+c\geq 1
$$

当B=1时，最好的情况下可以在最后一步把3人送到右岸。在此之前可以把三人送到右岸在由一个人把船划回左岸。因此每次来回都只能渡两个人过河。因此需要至少$2*|\frac{M+C-3}{2}|+1$个动作，大于等于M+C-2个动作。

B=0时，需要将一个人把船摆渡到左岸变成B=1的情形，然后把M+C+1个人摆到右岸。按此需要至少M+C个动作，大于M+C-2。

--------

## 八、 博弈树搜索

搜索问题的泛化：对环境没有完全的控制，环境受到其他智能体的影响。如：存在竞争对手使得自己的搜索空间总体往不利的方向发展。在这种情况下，我们需要通过扩展搜索的视角（泛化）来处理不是由我们的智能体所控制的状态的变化。

### 8.1 博弈树

博弈特点：

- 玩家有自己的利益取向
- 玩家根据利益来改变世界（状态）
- 难点在于自己的行动要考虑对方会如何行动，对方也如此

一般来说，博弈是离散的，状态和决策可以映射为离散的值，且状态是有限的，没有不确定因素和不完整信息，如掷骰子等。

零和博弈：一方赢得的分数从对手身上扣，所有玩家总分之和为0。将零和博弈形式化：

- 两个玩家A（max）和B（Min）
- 状态集合S（游戏状态的有限集合）
- 初始状态$I\in S$
- 终止位置$T\in S$
- 后继函数
- 效益utility函数或收益payoff函数$V：T\to \R$，将终止位置映射到实数，表示每个终止位置对玩家A多有利或对B多不利

玩家A希望最大化终止状态的收益，玩家B希望最小化。

Nim问题：有几堆火柴，每次每个玩家从一堆移走任意数目火柴，移走最后一根的玩家输。

### 8.2 Mini-Max策略

假设对方总能作出最优的决策，所有玩家都尽量使得自己的收益最大。

构建完整的博弈树，每个叶子节点都表示终止状态。每个叶子节点都标记对应的效益值，然后反向传播效益值U(n)。每个叶子节点t的U(t)值提前预设好。

- 若节点n为Min节点：$U(n)=\min[U(c)]$，其中c是n的子节点
- 若节点n为Max节点：$U(n)=\max[U(c)]$，其中c是n的子节点

我们希望能构建整个博弈树并且记录每个玩家决策所需的值，但是博弈树的大小是指数增长的。Mini-Max的决策没有必要计算整个博弈树。则需要进行剪枝。

### 8.3 Alpha Beta剪枝

对Max节点的剪枝称为α-cuts，Min节点剪枝为β-cuts。

#### 8.4.1 α剪枝

在Max节点，设β是n被遍历过的**兄弟节点**中的最低值（n左边的兄弟节点都被遍历过了），α为n被遍历过的**子节点**中的最高值。如果α大于等于β则可以停止遍历n的子节点。

推广：当一个 Max 节点的 α值≥任何一个Min祖先节点的β值时 ，剪掉该节点的所有子节点

#### 8.4.2 β剪枝

在Min节点n，设α是目前n节点的**兄弟节点**中值最高的，β为**子节点**中值最低的，如果β小于等于α则可以停止扩展n的子节点。

同样， 在Min节点 n, 如果β 变得 ≤ 某个 Max祖先节点的α值, 那么n节点的扩展就可以停止了

没有剪枝的话，需要扩展$O(b^D)$个节点，与普通的MiniMax 算法一样，但是，如果节点遍历的顺序是最优的（即最优的动作被优先遍历），使用alpha-beta剪枝需要遍历的节点数是$O(b^{D/2})$

### 8.4 评价函数

真实游戏很难把整个博弈树都枚举出来，必须限制搜索树的深度。需要启发式地计算（非终止节点）叶子节点的值，这样的启发式方法被称为评价函数。

- 必须使得终止节点的排序和原来的效用函数一致

- 计算不能太耗时

- 对于非终止节点，评价函数需要与这个节点实际能获得胜利的概率强相关

大多数的评价函数会分别计算各个特征的数值贡献，之后再进行结合。如象棋中，每个兵评价为1，马或象评价为3，车评价为5，皇后评价为9。进行加权求和即可。当然，可能不是线性的。

以井字棋为例，定义：

- $X_n$为只有n个X而没有O的直线，同样也有$O_n$

- 令$X_3=1$的状态赋值为1，$O_3=1$为-1，其他情况为0

- 评价函数

$$
Eval(s)=3X_2(s)+X_1(s)-(3O_2(s)+O_1(s))
$$

即使在标准搜索中，也无法把树扩展到终止节点，因此我们经常通过限制往前看的能力，并且在不知道路径是否能达 到目标的情况下就做出行动。这种方法被称为在线或实时搜索。使用启发式函数不仅是为了引导搜索，也为了得到可以前进的动作。一般情况下，这种方法是无法保证最优性的，但是可以极 大地降低时间和空间消耗。

拓展 -> 评价函数选择路径 ->进入路径，继续拓展、选择 ... ... 

------------

## 九、约束满足问题CSP

### 9.1 形式化表述

用特征值组成的向量表示状态，每个特征有一个取值域，能取其中不同的值。一个状态由确定的一组特征值表示。目标是找到满足条件的向量。

例子：数独，81个变量。域：{1~9}。状态：所有的变量都有确定的值组成的向量。部分状态：部分变量还没有取值。解：满足条件的向量。

CSP包含：

- 一组变量$V_1,...,V_n$

- 每个变量的取值都有一个特定的域domain，记为$Dom[V_i]$，域的大小有限
- 限制条件$C_1,...,C_m$，限制条件由变量作为参数，结果为True或False。依据变量多少分为一元、二元等

我们不关系到达解的方法和步骤，只关心是否能找到解，解是什么。

### 9.2 回溯算法

深度优先搜索，遇到不满足条件的节点则回溯。得爬。

可以使用启发式搜索决定先搜哪些变量、变量先取哪些值。下一个变量的选择可能因分支的不同而不同。这些动态选择对性能有很大影响。

N皇后问题：N*N的棋盘上放N个棋子，每个棋子的行、列、斜线上不能有另一个棋子。

约束传播指的是对搜索中尚未分配的变量进行“预先查看”的技术，尝试检测明显的失败。传播可以在搜索过程中应用，甚至在搜索开始前应用。传播本身是一个推理步骤，需要一些资源。有时传播会使得搜索更慢，需要权衡。有了约束传播的概念，就有了之后的两个小节：向前检测FC和广义边一致性GAC

### 9.3 向前检测算法Forward Checking

当一个变量被实例化时，我们检查所有只剩下一个未实例化变量的约束。对于未实例化的变量，我们检查它的所有值，删除那些违反约束的值。在搜索过程中，这里也需要回溯。需要记住域中的哪些值是因为哪个变量取什么值时去掉的。

找下一个变量进行取值时，优先找域更小的变量。这种启发式倾向于在顶部产生细树，这意味着可以用更少的搜索节点实例化更多的变量。当树开始分叉时，会出现更多的约束传播/DWO（Domain Wipe Out）失败。

就经验来说，FC比单纯的回溯算法BT快100倍，采取最小剩余变量值的策略块10000倍。

### 9.4 GAC算法Generalized Arc Consistency

 称条件$C(X,Y)$关于X是一致的，如果对任意的X，都能找到Y满足C。同样，$C(V_1,...,V_n)$关于$V_i$是GAC的，则对任意$V_i$，其他变量都有取值使得C满足。如果限制条件对所有变量都GAC，则这个限制条件是GAC。如果CSP的所有约束条件都是GAC，那么CSP就是GAC。

如果$V_i$的某个取值d使得约束中其他的变量无论怎么取值都不能满足，则d是弧不一致的，需要将d从$V_i$的域中移除。GAC和FC很像，但GAC更强。从域中删除值可能会引发进一步的不一致，因此我们必须重复这个过程，直到所有内容都一致为止。

改进点：

- 当V=d时，不找所有其他变量的可能性而是找其他变量的域
- 将指数级复杂度的条件简化为多项式复杂度

--------

## 十、 知识表示与推理

Knowledge representation and reasoning (KRR)定义：符号化命题并进行操作，产生未被明确表示的命题的表征。

假设所有AI系统都是基于知识的系统，即能从命题上解释并确定系统行为。这种结构叫做知识库KB。基于知识的系统最适合开放式的任务。知识系统的标志：认知穿透性，即行动依赖于信念，包括隐含表现的信念。

逻辑是研究KRR的主要工具，工作主要是形式化地表示“信念”，并通过显式的信念推理出隐式的。本章使用一阶逻辑(FOL)作为研究KRR的工具。

一个例子：Tony、Mike、John是高山俱乐部成员，已知：

- 每个俱乐部成员如果不是滑雪者则是登山者
- 登山者不喜欢下雨，不喜欢下雪的不是滑雪者
- Mike不喜欢所有Tony喜欢的事物，喜欢所有Tony不喜欢的事物
- Tony喜欢下雨和下雪

问：是否有高山俱乐部成员是登山者，但不是滑雪者？

### 10.1 一阶逻辑的公式化表示

- 个体：常量或零元函数
  - Tony、Mike、John
  - rain、snow
- 种类：一元谓词
  - A(x)：x属于高山俱乐部
  - S(x)：x是滑雪者
  - C(x)：x是登山者
- 关系：二元谓词
  - L(x,y)：x喜欢y

从而有以下公式表示：

- A(Tony)，A(Mike)，A(John)
- L(Tony,rain)，L(tony,snow)
- $\forall x(A(x)\and\neg S(x))\to C(x)$
- $\forall x(C(x)\to\neg L(x,rain))$
- $\forall x(\neg L(x,snow)\to\neg S(x))$
- $\forall(L(Tony,x)\to\neg L(Mike,x))$

- $\forall(\neg L(Tony,x)\to L(Mike,x))$

- $\exist x(A(x)\and C(x)\and \neg S(x))$

例子：以之前提及的方块世界为例，方块A、B、C、E，存在关系：在方块上面：On(A,B)、在方块上方Above(A,B)、上面为空Clear(A)、紧贴桌子Ontable(C)

- 项term：
  - 每个变量是一个项
  - 如果$t_1,t_2,...,t_n$是项，且f是n元函数，则$f(t_1,...,t_n)$也是项。
- 公式formula：
  - 如果$t_1,...,t_n$是项，$P$是n元谓词，则$P(t_1,...,t_n)$是原子公式
  - 如果$t_1,t_2$是项，$(t_1=t_2)$是原子公式
  - 如果$\alpha$和$\beta$是公式，$v$是变量，则$\neg \alpha,(\alpha\and\beta),(\alpha\or\beta),\exist v.\alpha,\forall v.\alpha$都是公式
- $(\alpha\to\beta)$等价于$(\neg\alpha\or\beta)$
- $(\alpha\leftrightarrow\beta)$等价于$(\alpha\to\beta)\and(\beta\to\alpha)$
- 有界变量：有量词（任意、存在）限定的变量；自由变量：没有量词限定
- 句子sentence：没有自由变量的公式
- 替换substitution：$\alpha[v/t]$表示$\alpha$的所有自由变量v使用项t替代
- 解释Interpretations：解释是一个数对$\xi=<D,I>$
  - D是一个域，可以是任何非空集。项决定了域中的元素。如方块世界有$D=\{A,B,C,E\}$
  - I是谓词和函数符号的映射
  - 如果P是n元谓词符号，$I(P)$是D中的n元关系，即$I(P)\subseteq D^n$。如果p是零元谓词符号，则$I(p)\in\{true,false\}$。如方块世界中有$on={(A,B),(B,C)}$
  - 如果f是一个n元函数符号，则$I(f)$是D中的n元函数，即$I(f):D^n\to D$。如果c是零元函数符号，即常数符号，则$I(c)\in D$
- 变量赋值$\mu$：从变量集到域D的映射
  - $||v||_{\xi,\mu}=\mu(v)$
  - $||f(t_1,...,t_n)||_{\xi,\mu}=I(f)(||t_1||_{\xi,\mu},...,||t_n||_{\xi,\mu})$
- 满足satisfy：$\xi,\mu$满足$\alpha$记为$\xi,\mu\models \alpha$
  - $\xi,\mu\models P(t_1,...,t_n)$当且仅当$<||t_1||_{\xi,\mu},...,||t_n||_{\xi,\mu}>\in I(P)$
  - $\xi,\mu\models (t_1=t_2)$当且仅当$||t_1||_{\xi,\mu}=||t_2||_{\xi,\mu}$
  - $\xi,\mu\models\neg\alpha$当且仅当$\xi,\mu\not\models\alpha$
  - $\xi,\mu\models(\alpha\and\beta)$当且仅当$\xi,\mu\models\alpha$且$\xi,\mu\models\beta$
  - $\xi,\mu\models(\alpha\or\beta)$当且仅当$\xi,\mu\models\alpha$或$\xi,\mu\models\beta$
- $\mu\{d;v\}$表示和$\mu$类似的赋值，但它将v映射到d
  - $\xi,\mu\models\exist v.\alpha$当且仅当存在$d\in D,\xi,\mu\{d;v\}\models\alpha$
  - $\xi,\mu\models\forall v.\alpha$当且仅当对所有$d\in D,\xi,\mu\{d;v\}\models\alpha$
  - 当$\alpha$是句子，则与赋值$\mu$独立，简写为$\xi\models\alpha$

- 句子集的满足关系：设S为句子集合
  - $\xi\models S$，如果所有的$\alpha\in\xi,\xi\models\alpha$
  - 如果$\xi\models S$，则说$\xi$是S的模型model
  - 如果存在$\xi$使得$\xi\models S$则说S是可满足的
- 逻辑蕴含
  - $S\models \alpha$当且仅当对于每个$\xi$都有：如果$\xi\models S$则$\xi\models\alpha$
  - $S\models \alpha$读作：S蕴含$\alpha$或$\alpha$是S的逻辑结论logical consequence
  - 特殊情况：$\emptyset\models\alpha$写作$\models\alpha$，读作$\alpha$是合法valid的
  - $\{a_1,...,a_n\}\models\alpha$当且仅当$a_1\and...\and a_n\to\alpha$合法当且仅当$a_1\and...\and a_n\and\neg\alpha$不可满足

以方块世界为例，有：

- $S=\{On(a,b),On(b,c),Green(a),\neg Green(c)\}$
- $\alpha=\exist x\exist y[Green(x)\and\neg Green(y)\and On(x,y)]$
- 需要证明：$S\models \alpha$

S就是知识库KB。要证明知识库不满足$\alpha$唯一的方式是给一个解释满足KB但不满足$\alpha$

### 10.2 推理过程Inference procedure

检验是否$KB\models \alpha$，解是推理的规则。基于解的推理过程称为辩驳refutation。

文字literal是原子公式或它的否定，如$p,\neg p$。从句Clausal 是文字的析取 disjunction，如有：$p\or\neg r\or s$，从句为$(p,\neg r,s)$。空从句表示假false。公式是从句的析取，写作从句集合。

对于两个从句$\{p\}\cup c_1$和$\{\neg p\}\cup c_2$，可以推出$c_1\cup c_2$。$c_1\cup c_2$称为关于原子p的输入从句的解析resolvent 。

从句集合S中的从句c的衍生derivation是一个从句序列$c_1,c_2,...,c_n$，且$c_n=c$，并且对每个$c_i$，要么$c_i\in S$，要么$c_i$是推导中前面两个从句的解析式。如果S中的c存在衍生，则写作$S\vdash c$

定理：

- 若$S\vdash c$，则$S\models c$

- $S\vdash ()$当且仅当$S\models ()$当且仅当S不可满足

- $KB\models \alpha$当且仅当$KB\and\neg\alpha$不可满足。故要检查$KB\models \alpha$则：
  - 将KB和$\neg\alpha$放入从句来获得S
  - 检查是否有$S\vdash ()$

### 10.3 一阶的情况

需要一种方法将KB和f（查询）转换成从句形式。还需要即便有变量也能解决问题的方法。

#### 10.3.1 变换成从句

转换到从句形式的步骤：

1. 消除蕴含内容（将$\to$转换为$\neg\or$，等价同理）
2. 将否定内移并简化（将$\neg$放到最底层并且合并所有连续两个$\neg$）
3. 标准化变量：重命名变量，使得每个变量符号都是唯一的
4. 斯克林化：通过引入新的函数符号来删除存在量词
5. 转换为Prenex形式：将所有量词放在前面，只显示通用的量词，每个量词都有不同的名称
6. 将析取分布在连取之上：所有$A\or(B\and C)$转换为$(A\or B)\and(A\or C)$
7. 平嵌套连词和析词
8. 转换为从句：删除量词和拆开连词$\and$

斯克林化Skolemization：

- 比如$\exist y.Elephant(y)\and Friendly(y)$，为了消除存在符号，将具体的y代入值a，其中a是未知数但是是常量。

- 再比如$\forall x\exist y.Loves(x,y)$，要正确转换由全称域量词限定的存在量词，我们必须使用函数而不仅仅是常量。这里使用g(x)替换y，g是一个新的函数符号。

举个例子，如：
$$
\forall x\{P(x)\to[\forall yP(y)\to P(f(x,y))\and\neg\forall y(\neg Q(x,y)and P(y))]\}
$$

1. 消除蕴含内容去掉$\to$符号，得到：

$$
\forall x\{\neg P(x)\or[\forall y(\neg P(y)\or P(f(x,y))\and\neg\forall y(\neg Q(x,y)\and P(y)))]\}
$$

2. 将所有$\neg$符号放到括号里面，并消除两个连续的$\neg$，得到：

$$
\forall x\{\neg P(x)\or[\forall y(\neg P(y)\or P(f(x,y)))\exist y(Q(x,y)\or\neg P(y))]\}
$$

3. 标准化变量，针对不同的存在或全称量词，使用不同的变量符号：

$$
\forall x\{\neg P(x)\or[\forall y(\neg P(y)\or P(f(x,y)))\and\exist z(Q(x,z)\or\neg P(z))]\}
$$

4. 斯克林化，消除存在量词：

$$
\forall x\{\neg P(x)\or[\forall y(\neg P(y)\or P(f(x,y)))\and (Q(x,g(x))\or\neg P(g(x)))]\}
$$

5. 将所有全称量词放在最前面

$$
\forall x\forall y\{\neg P(x)\or[(\neg P(y)\or P(f(x,y)))\and (Q(x,g(x))\or\neg P(g(x)))]\}
$$

6. 7. 化成析取$\and$所有合取$\or$的形式

$$
\forall x\forall y\{(\neg P(x)\or\neg P(y)\or P(f(x,y)))\and(\neg P(x)\or Q(x,g(x))\or\neg P(g(x)))\}
$$

8. 转换为从句，得到：
   - $\neg P(x)\or\neg P(y)\or P(f(x,y))$
   - $\neg P(x)\or Q(x,g(x,y))\or\neg P(g(x))$

#### 10.3.2 变量的处理

为了确定变量取值，需要对从句进行统一Unification。统一是一种寻找最普遍匹配的机制。如果把所有的可能代入变量，会变得非常复杂。需要用到替代substitution，形式为$\sigma=\{V_1=t_1,...,V_n=t_n\}$。其中V是变量，t是不包含V的项term。t可能包含了其他变量。将替换$\sigma$应用于公式f得到新的公式$f\sigma$。如：
$$
P(x,g(y,z))\{x=y,y=f(a)\}\Rightarrow P(y,g(f(a),z))
$$
注意替换是不按顺序替换的，如上述替换中的第一个y没有被f(a)替换。

如果有两个替换$\theta$和$\sigma$，可以合并成一个新的替换$\theta\sigma$。方法：

1. 将两个合并的所有内容写在一起，其中$\theta$中等号右边的内容用$\sigma$中的表示
2. 删除所有具有形式V=V的内容
3. 如果有某个变量y=x，删除所有y=常数的内容

例子：$\theta=\{x=f(y),y=z\},\sigma=\{x=a,y=b,z=y\}$

1. 简单合并，$S=\{x=f(b),y=y,x=a,y=b,z=y\}$

2. 删除y=y
3. 因为x=f(b)，删除x=a

结果为：$S=\{x=f(b),y=b,z=y\}$

性质：

- 空替换$\epsilon=\{\}$也是替换，满足：$\theta\epsilon=\theta$

- 结合律：$(f\theta)\sigma=f(\theta\sigma)$

统一unifier是使得两个公式句法上相同的替换。如$P(f(x),a)$和$P(y,f(w))$就不能统一，因为没有替换能够使得$a=f(w)$。两个公式f和g的替换$\sigma$称为Most General Unifier（MGU），则需要满足：

- $\sigma$是统一

- 对所有f和g的其他的统一$\theta$，必须存在第三个替换$\lambda$使得$\theta=\sigma\lambda$，也就是说所有其他的统一是$\sigma$的“更加具体化”的代入结果。公式f和g的MGU是唯一的。

比如$P(f(x),z)$和$P(y,a)$的MGU为$\theta=\{y=f(x),z=a\}$，而$\sigma=\{y=f(a),x=a,z=a\}$虽然是统一，但是不是MGU。存在$\lambda=\{x=a\}$使得$\sigma=\theta\lambda$。

MGU是最小被具体化的使得带变量原子公式匹配的替换。构建MGU则需要依次比较公式的各项，第一个不一致的地方称为不一致集。连续修复不一致集，直到两个公式在语法上完全相同，修复过程中得到的替换即为MGU。

#### 10.3.3 一阶求解

定理：$S\vdash()$当且仅当S不可满足。

例子：现有从句$(P(x),Q(g(x)))$和$(R(a),Q(z),\neg P(a))$

得到：$R[1a,2c]\{x=a\}(Q(g(a)),R(a),Q(z))$。其中：

- R表示求解步骤
- “1a”表示第一个从句中的第一个（第a个）文字P(x)，“2c”表示第二个从句的第三个（第c个）文字$\neg P(a)$。这两个文字是冲突的。{x=a}是使用的MGU。

要证明$P\models Q$，证明$P\and\neg Q$即可。如：证明：$\exist y\forall xP(x,y)\models\forall x\exist y P(x,y)$，则：

- 由$\exist y\forall xP(x,y)$得到：$1. P(x,a)$
- 由$\neg\forall x\exist y P(x,y)$得到：$2.\neg P(b,y)$

- R[1,2]{x=b,y=a}()，故为真。

除了检验结论是否正确，还可以用来寻找答案。对于“是否存在某变量满足某条件”的结论$\exist xP(x)$，使用$\exist x[P(x)\and\neg answer(x)]$代替。其中answer为自己设置的谓词。经过求解过程后若可以得到$answer(a)$，则说明a是满足上述条件的解。

求解的归结过程可能无限长，导致不能得出结论。判断从句是否可以满足已经被证明了是个NP难的问题。在查询空()时，可以使用序Prolog，用特定的深度优先左右策略。

---------

## 十一、 规划planning

人工智能不能只是被动地解决问题或进行推理，还要有目的地采取行动。需要推理采取什么行动后世界会发生什么样的变化。有时对世界的认知是不完整的，需要通过概率方法来建立模型。

### 11. 1经典规划

只关注确定性情形。完整的初始状态决定了动作的效果。

情景演算：

- 行动action：动作函数，函数变量是参与动作或动作作用的对象
- 情境situation：记录初始状态$S_0$和执行动作的历史。`do(a,s)`函数记录在s情境做动作A的结果
- 影响fluent：谓词或函数，最后一个参数通常是情境

动作需要有先决条件，所有前置条件为真动作才能执行。同时，动作又会改变现有条件。

使用知识库KB来表示对世界的描述，包括动作的前置条件和效果。

封闭世界假设CWA：表示世界状态的知识库是一个正原子事实的列表。也就是说，如果一个基本的原子事实不在已知的事实列表中，那它的否定一定是真的。这样的知识库称为封闭世界知识库CWKB。

#### 11.1 1 STRIPS

STRIPS（斯坦福研究所问题解决者）：自动规划器，这个名称后来被用来指这个计划器输入的正式语言。STRIPS用三个列表表示动作（以拿起一个方块`pickup(X)`为例）：

- 前置条件`Pre`：{`handempty`, `clear(X)`, `ontable(X)`}
- 动作添加的效果`Adds`：{`holding(X)`}
- 动作删除的效果`Dels`：{`handempty`, `clear(X)`, `ontable(X)`}

先决条件列表中只有原子事实。如果所有条件都被满足，则在KB中添加`Adds`并删除`Dels`。

STRIPS没有条件影响，也就是说动作对象有类型要求。我们有时必须利用额外的动作，针对每种类型的条件使用一个动作。

#### 11.1.2 ADL

ADL（动作描述语言）拓展了STRIPS的表达能力，前置条件可以是任意的公式，可以有条件效应和普遍效应。比如，将方块A放在方块B上需要去掉`clear(B)`，但放在足够大的桌子C上不需要去掉$clear(C)$。以将c从a移动到b为例，`move`的动作描述为：

- Pre：`on(c,a)`$\and$`clear(b)`
- `Effs`：
  - `ADD[on(c,b)]`
  - `DEL[on(c,a)]`
  - `b!=talbe -> DEL[clear(b)]`
  - `a!=talbe -> ADD[clear(a)]`

### 11.2 解决规划问题

将规划问题看做搜索问题，给定CW-KB、STRPIS或ADL操作、目标状态，这被称为经典规划任务。通常目标是将基本事实结合起来，因此我们只需要检查是否所有事实都包含在CW-KB中。

#### 11.2.1 启发式搜索

考虑宽松的启发式规划。假设前置条件和目标都是正面事实（不出现非）。如果不删去删除列表的条件，则能够产生一个有用的启发式估计。

定理：松弛问题的最优计划的长度与原问题的最优计划的长度是有界的。

考虑从当前状态到目标状态建立一个分层结构，计数宽松的规划需要多少行动，使用它作为我们对当前状态到目标距离的启发式估计：

1. 初始状态为$S_0$
2. 找到所有前置条件能被$S_0$满足的动作，组成动作层$A_0$
3. $S_1=S_0\cup$所有$A_0$的动作添加的条件
4. 迭代直到目标出现在状态层或状态层不再改变（达到固定点）

命题：$a_0,...,a_{n-1}$为可以施加在$S_0$层的一系列动作，令$s_0=S_0$，对于任意$i<n,s_{i+1}=s_i\cup add(a_i)-del(a_i)$，则对任意$i<n$，$\exist j,k\leq i$使得$a_i\in A_k$且$s_i\subseteq S_j$。

定理：假设状态层停止改变，目标不满足。那么原来的规划问题就无法解决了。

#### 11.2.2 动作计数

通过上述启发式搜索，得到一个状态包含目标状态G后，需要得到一个松弛规划方案。考虑对每个 i 找到$A_i$的最小子集。

```pseudocode
CountActions(G, S_k):
/* S_k 包含G */
	if k=0 then return 0;
	G_P = G与S_{k-1}的交集		/* G_p包含了所有S_{k-1}已存在的状态 */
	G_N = G - G_P			   /* G_N包含了S_K新增的状态 */
	A = 动作的最小集合，使得附加列表包含G_N的状态（集合覆盖问题，NP难）
	新G = G_p 和 A前置条件的并集
	return CountActions(新G, S_{k-1}) + size(A)
```

定理：假定目标G被$S_k$包含，$\forall i<k$，令$A'_{i-1}$为A调用`CountActions(G_i,S_i)`的A，则$A'_0,...A'_{k-1}$是一个宽松规划方案。

需要注意的是，每次选择最小集合A难以选到最优，就算每次选到最优整体也不一定是最优的。

--------

## 12. 不确定性推理

初始状态和动作造成的结果可能是不确定的。推理时依据已有的事实是不够的，还要依据不确定时间的可能性进行推算。

### 12.1 有限集合下的可能性

可能性是通过事件集合U定义的函数，称为事件宇宙universe of events，将每个事件映射到一个概率。像CSP一样，我们定义一组变量$V_1,...,V_n$，每个变量都有自己的域$Dom[V]$。每个原子事件可以用$\{<d_1,...d_n>|d_i\in Dom[V_i]\}$表示。则事件空间的大小为$\Pi_i|Dom[V_i]|$，即所有域的大小的乘积。使用大括号表示满足特定条件的事件的集合，如$\{V_1=a\}$表示所有满足$V_1=a$的事件的集合，则有：
$$
Pr(\{V_1=a\})=\sum_{x_2\in D[V_2]}...\sum_{x_n\in D[V_n]}Pr(V_1=a,V_2=x_2,...,V_n=x_n)
$$
定义$B_1,...,B_k$为U的一个分割，则满足：

- 互斥性：$B_i\cap B_j=\empty,i\neq j$
- 详尽性：$B_1\cup B_2\cup...\cup B_k=U$
- $Pr(A)=\sum^K_{k=1}Pr(A\cap B_k)$
- $Pr(A)=\sum^K_{k=1}Pr(A|B_k)Pr(B_k)$

A和B**独立**：$Pr(B|A)=Pr(B)$，等价于$Pr(A\cap B)=Pr(A)Pr(B)$此时A的确定不能对确定B提供任何帮助。如果$Pr(B|A\cap C)=Pr(B|A)$，等价于$Pr(B\cap C|A)=Pr(B|A)Pr(C|A)$则说B在给定A的条件下与C**条件独立**。

贝叶斯定理：
$$
Pr(Y|X)=Pr(X|Y)Pr(Y)/Pr(X)
$$
链式法则：
$$
Pr(A_1\cap A_2\cap...\cap A_n)=Pr(A_1|A_2\cap...\cap A_n)Pr(A_2|A_3\cap...\cap A_n)...Pr(A_{n-1}|A_n)Pr(A_n)
$$
类似事件的可能性，对于变量也有变量的可能性一说，基本法则相同。

### 12.2 贝叶斯网络BN

#### 12.2.1 贝叶斯网络的性质

考虑：如果A为真则B大概率也为真，若B为真则C大概率为真。当什么都不知道时，显然A的真假可以影响C的真假，A为真时，C更可能为真，C和A或B都不是独立的；但如果已经知道了B的真假，因为C是由B决定的，因此A的真假不再影响C的真假。换句话说，在给定B的条件下，A和C条件独立。**总结：在给定某个变量的直接相关的前置变量条件后，它和其他的变量条件独立。**如此一来，推出拓扑顺序靠后的变量的复杂度由指数变为了线性。如果依赖关系是链状结构则是线性的。

贝叶斯网络BN是用变量的直接依赖关系与条件概率表CPT表示的图。也就是说，含有变量$\{X_1,X_2,...,X_n\}$的BN包含：

- 有向无环图DAG，每个节点是一个变量
- CPT：对每个$X_i$都给出了$Pr(X_1|Par(X_i))$，其中$Par$为直接连接的前置节点parent，可能有多个

如此一来，就有：
$$
Pr(X_1，X_2,...,X_n)=Pr(X_n|Par(X_n))*Pr(X_{n-1}|Par(X_{n-1}))*...*Pr(X_1|Par(X_1))
$$

#### 12.2.2 贝叶斯网络的构建

1. 使用链式法则将析取变量的概率值写成条件概率的乘积
2. 删除每个条件概率中，与当前变量条件独立的条件变量
3. 通过剩下的条件关系建立DAG，条件变量为当前变量的父节点
4. 创建CPT表

贝叶斯网络的构建是一个拓扑排序的过程，不合适的排序会使得网络中的节点有大量的父节点，从而造成指数级别的复杂度。因此通常考虑基于因果关系的排序，使得网络更自然、更紧凑。这是从自然的因果关系出发的推断，不能作为理论依据。

#### 12.2.3 贝叶斯网络的求解

一个问题一般是给出部分变量的真实值，求某个变量的取值概率。给出的真实值的变量集合为证据E，要求的变量的每种取值的概率都需要求出来。则具体步骤如下：

1. 计算变量的每种取值与E的联合概率
2. 单独计算产生E的概率
3. 通过联合概率和E的概率求E的条件下的变量的条件概率

### 12.3 D-拆分

如果E在BN中**阻塞**了每条X和Y之间的无向路径，则X和Y是在E的条件下条件独立的。

阻塞的定义：E阻塞了路径P，当且仅当路径上存在节点Z，满足下面三个条件之一：

- 路径P上一条箭头进入Z，一条出Z，Z在E中
- 所有与Z相关的箭头都是出去的，Z在E中
- 所有与Z相关的箭头都是进入的，且Z和它的任何后代都不在E中

#### 12.3.1 基础的变量消除

变量消除：在计算联合分布时，对没有给出具体值的变量要对所有的可能进行讨论，将概率进行加和。如此一来，需要对很多变量的不同可能进行求和操作。如果**从外向内**拆开求和符号可以产生很多重复的子项，从而减少计算量。考虑变量消除VE方法：

1. 将条件全部已知的求解概率从式子中去除。这些概率是常数，算完之后乘进结果即可。
2. **从内往外**拆解求和符号，直到一次拆解一个拆解不了
3. 将一次拆解一个拆解不了的部分提出来，**从外往内**拆解，从而形成重复子项简化运算

#### 12.3.2 函数操作的变量消除

定义函数叉乘：
$$
h(X,Y,Z)=f(X,Y)\times g(Y,Z)
$$
函数加和（$f(x,Y)$的值实则为$Pr(Y|x)$）：
$$
h(Y)=\sum_{x\in Dom(X)}f(x,Y)
$$
函数限制（函数给定部分变量取值）：
$$
h(Y)=f(a,Y)
$$
则VE算法为：

1. 通过CPT替换所有E中出现的、需要计算概率的项（即先计算常数项）
2. 计算加和，去除其他变量
3. 使用叉乘得到E当条件、要求的变量Q为变量的条件概率

-------------------

举个例子。在一个BN中有：$A\rightarrow C、B\rightarrow C、C\rightarrow D$，且有：

- 因子factors（由网络得到）：$f_1(A)$、$f_2(B)$、$f_3(A,B,C)$、$f_4(C,D)$
- 查询Query：$P(A)$
- 证据Evidence：$D=d$

从外到内的加和依次为A、B、C、D。计算方法：

1. 替换：$f_4(C,D)$在给定$D=d$时，得到：$f_5(C)=f_4(C,d)$

2. 消除C：$f_6(A,B)=\sum_Cf_5(C)f_3(A,B,C)$

3. 消除B：$f_7(A)=\sum_Bf_6(A,B)f_2(B)$
4. 计算$f_1(A)*f_7(A)$，并进行归一化

---------

#### 12.3.3 桶消除方法的变量消除

为每个变量建立一个桶，桶中放与该变量相关的函数。首先要对变量进行排序，优先放进前面的桶，然后按照桶的顺序进行变量消除，桶中的函数相乘，得到一个新的函数，放进之后的桶中。

总之，桶消除方法可以从任意位置拆解加和符号。复杂度和拆解加和的顺序有关。那么如何找到这一个变量消除的顺序呢？考虑使用超图hypergraph，超图有超边hyperedge，超边是顶点的集合，可能不止一个节点。每个节点是一个变量，每个超边是CPT表中出现的所有项中出现的变量。比如，需要计算的概率出现了$Pr(F|E,D)$，则$F、E、D$三个顶点由一个超边连接。为了消除变量X，需要从超图中：

- 去除X顶点
- 生成新的超边H，等于所有包含X的超边减去X顶点后的并集
- 去掉所有与X有关的超边并加入超边H

整个变量消除过程中，全部函数含有的最大的变量数称为消除宽度elimination width。不同的变量排序可以有不同的宽度。最小的宽度减一就是超图的树宽tree width。则最好情况下，VE的复杂度为2的树宽次方，最坏情况下，树宽等于变量数。找到最小的树宽是NP难问题。

对于polytree（每一对节点之间最多只有一条路径），最小树宽等于所有节点的最大父节点数目，得到线性复杂度。

排序的启发式方法：每次找产生最小的因子数的变量消除

### 12. 4 贝叶斯预测、MAP预测、ML预测

在不同的初始世界状态下进行动作。通过动作后的世界状态来推断原来的世界状态（的概率）。如一包糖有两种糖，可能1种糖占所有糖的100%、75%、50%、25%、0%，经过多次取出通过看糖的种类，来推断这包糖是哪一种情况。也就是说，在每种可能的状态的前提下，看出现后续状态的可能性。可能性越大的，假定状态为真的可能性就越大。

#### 12.4.1 MAP预测

如果状态空间过大，考虑极大后验MAP：基于最可能的假设进行预测：
$$
h_{MAP}=arg\max_{h_i}P(h_i|d)
$$
其中$h$为初始状态，$h_i$为初始状态的一种可能，$d$为已知经过什么动作后得到了什么结果（如从袋子中取出一颗糖，得知该糖的种类）。

贝叶斯学习是通过不同的可能性进行加权得到的概率，而MAP是选用极大后验选出状态从而直接选用该状态作为初始状态。因此MAP预测比贝叶斯预测更不准确，因为它只选取了一个初始状态，而不是将每种状态的可能进行加权。但随着数据量的增大， 二者的预测会趋同。不过，使用MAP也测，计算$h_{MAP}$可能会很难。

#### 12.4.2 ML预测

考虑对MAP用极大似然ML进行优化：
$$
h_{MAP}=arg\max_hP(h)P(d|h)\\
h_{ML}=arg\max_hP(d|h)
$$
前提：
$$
P(X|d)\approx P(X|h_{ML})
$$

ML也是选取一个情况进行计算，其准确度比贝叶斯和MAP都低，但三者都随着数据增加而趋同。而找$h_{ML}$比$h_{MAP}$容易。

只选择一种情况可能使得预测过拟合。考虑将每种变量最终的计数加一，从而能有效优化，成为拉普拉斯平滑。

### 12.5 EM算法

使用软聚类。初始条件为C，有k种情况，在C的条件下得到了一系列变量值$X_1,X_2,...$重复下面两步：

- E-step：依据给定的概率预测为观测到的变量的数据点数量
- M-step：使用ML或MAP，从数据中对概率进行推断

起始时，使用假定的数据或概率。EM将收敛于局部极大值。
# 操作系统

操作系统的笔记怕是都能出书了

## 1. 计算机系统概述

纯吹水

-------------------------------------------------------

## 2. 操作系统概述

OS的定义：OS是一组程序的集合，其功能为：

- 控制管理计算机软硬件资源
- 合理的对各类作业（单一程序）进行调度
- 方便用户使用计算机系统

### 2.1 OS的目标和功能

操作系统是机器与应用程序之间的接口程序，主要功能是动态分配系统的共享资源给正在执行的程序。

除去固件（固化在硬件上的软件，如BIOS），OS是在硬件基础上的第一层软件。应该能控制应用程序的执行、充当应用程序和硬件之间的接口。

OS的设计需要：

- 方便，使得计算机易于使用
- 有效，合理分配计算机资源
- 易扩展，可引入新的系统功能

#### 2.1.1 操作方便

通过抽象和接口调用实现。

计算机系统的3个关键接口：

- ISA指令集体系结构：定义计算机的机器语言指令系统，是软硬件的分界接口。依据指令权限又可以分为用户ISA和系统ISA
- ABI应用程序二进制接口：定义二进制可移植交叉程序的标准。即系统调用。
- API应用编程接口：让程序能通过调用HLL库来实现服务

#### 2.1.2 资源管理有效

操作系统负责管理计算机的软硬件资源。操作系统和用户程序同为程序。操作系统经常放弃控制，必须依赖处理器才能重获控制。

#### 2.1.3易扩展性

一个操作系统应该能不断的发展。要考虑到硬件升级和新硬件的出现（触摸屏、APU等）、新的服务的需要（图形界面、多点触控等）、错误的修正（如补丁机制）

### 2.2 OS的发展历史

#### 2.2.1 串行处理serial processing

早期计算机**没有操作系统**，用户必须顺序访问计算机的操作模式。需要人工调度，准备时间很长。

#### 2.2.2 简单批处理系统simple batch system

为了提高利用率，实现了**监控程序**，即批处理操作系统，用于按次序调用各个用户程序（自动作业序列）。使用作业控制语言JCL。

监控程序需要的硬件支持：

- 内存保护：保护监控程序
- 计数器：防止一个作业独占系统
- 特权指令
- 中断：使得操作系统放弃和获取控制权更加灵活

由内存保护和特权指令，出现了用户态和和心态的操作模式。

使用单道程序批处理技术：处理器必须等到I/O操作结束后才能继续，大量的等待降低了效率

#### 2.2.3 多道程序批处理系统Multi-programmed batch system

为了解决监控程序CPU利用率低的问题，实现多道程序设计/多任务处理：多个作业同时进入主存，可以切换运行。

需要的硬件功能：

- I/O中断
- DMA（Direct Memory Access，直接内存存取）：处理器将I/O操作委托给DMA模块执行，处理器可以同时处理其他指令

软件功能：

- 内存管理
- 作业调度

#### 2.2.4 分时系统time sharing system

用于满足用户与计算机交互的需要（如：运行时输入），减小响应时间。依据是否能交互，有脱机和联机的概念。

分时系统有多个交互作业，多个用户分享处理器时间。简单说就是处理器同时处理多个用户程序。

核心技术：分时技术，将时间分成很短的时间片，按时间轮流分配处理器资源给各个联机作业。

#### 2.2.5 实时系统real time system

用于专用系统，进行实时控制和信息处理，强调即时响应和高可靠性。如工业过程控制、金融领域等。

当代的操作系统通常同时具有分时、实时、多道批处理功能，称为通用操作系统。

#### 2.2.6 OS的进一步发展

- 微机/PC机的OS：图形用户界面、多媒体、人性化
- 网络OS：网络功能、云计算等
- 分布式OS：尚处于研究阶段
- 嵌入式OS：智能手机、机顶盒、相机等

总结：OS的发展动力：

- 不断提高计算机资源利用率的需要
- 方便用户
- 硬件的更新换代
- 计算机体系结构的发展

### 2.3 OS的主要理论模块

基本都在讲很泛的概念。很多部分的详细内容在后续章节会讲到，不详细记录。

- 进程
- 内存管理
- 信息保护与安全
- 进程调度和资源管理
- 系统结构

### 2.4 现代操作系统的发展

新硬件和新应用、微内核、多线程、对称多处理、分布式、面向对象

----------------------------------------------------------

## 3. 进程描述和控制

### 3.1 进程概念

#### 顺序与并发

- 顺序执行（单道单线程批处理）
  - 一个有独立功能的程序独占处理机直到结束
  - 特征：
    - 顺序性：前一个操作结束，后续操作才能执行
    - 封闭性：运行时独占全机资源，执行不收外界影响
    - 可再现性：结果与运行速度无关
  - 符合冯诺依曼体系结构要求
- 并发执行（多道批处理、单道多线程批处理）
  - 逻辑上相互独立的程序在宏观时间上重叠。一个未结束，另一个已经开始。
  - 与冯诺依曼体系结构的要求相悖

#### 程序的并发执行

并发与并行的简单区分：

- 并行：A程序和B程序同时运行
- 并发：A程序运行到一半，去运行B程序，然后再回来运行A剩余的部分

特征：

- 间断性
- 失去了封闭性，一个程序的执行受到其他程序的影响
- 不可再现性，程序的结果与执行的相对速度有关

好处：充分利用系统资源，提高系统处理能力

坏处：破坏了冯诺依曼体系结构，引发了很多难题（互斥、同步、死锁、饥饿等）

#### 进程的定义

进程是程序的一次执行，是正在运行的一个程序实例，是分配给处理器并由处理器执行的实体。进程是系统进行资源分配和调度的一个独立单位。

#### 进程的特征

- 动态性：一定的生命周期
- 并发性：多个进程实体同时存在于内存中，能在一段时间内同时运行（不一定是在同一时刻）
- 独立性：进程实体是一个能独立运行的基本单位，也是系统中获得资源和独立调度的基本单位
- 异步性：进程之间按异步方式运行
- 结构特征：进程实体由程序段、数据段、进程控制块等部分组成，称为进程映象

#### 进程控制块PCB

用于描述进程，实现对进程的管理和调度

- 标识符：唯一标识进程
- 状态：运行、就绪、等待... ...
- 优先级
- 程序计数器PC：下一条程序指令地址的指针
- 内存指针：包括代码段指针、数据段指针等
- 上下文数据：进程中断时寄存器的数据
- I/O状态信息：显示I/O请求、分配的I/O设备等
- 记账信息（商业操作系统常用）：占用处理器时间、时钟数、时限、账号等

### 3.2 进程状态

轨迹：进程执行的指令序列

分派程序dispatcher：让处理器从一个进程切换到另一个进程，即进程调度程序。本质是操作系统中的切换进程的模块。

#### 3.2.1 两状态模型

运行/未运行

未运行的进程位于队列中，依次运行。运行时中断的进程回到队列。

#### 3.2.2 进程的创建和终止

- 建立管理进程的数据结构
- 为进程分配内存空间
- 创建进程映象

进程可以派生出新进程，由此有父进程、子进程、进程树的概念

#### 3.2.3 五状态模型

创建和终止有：新建、退出两个状态

运行过程中有三个基本状态：就绪（随时可以开始运行）、阻塞（因为等待事件而不能运行）、运行

运行态超时则直接进入就绪态，而如果发生了等待事件（如I/O操作）则进入阻塞态。阻塞态的进程在事件发生后进入就绪态。只有就绪态的进程才能被分派，进入运行态。

除了就绪队列，还要有阻塞队列，阻塞事件完成后回到就绪队列，就绪队列的进程被分派则进入运行态。如果超时则直接进入就绪队列。依据等待事件的不同，可以有多条阻塞队列。

#### 3.2.4 进程的挂起状态（六、七状态模型）

交换：进程映象整体或部分地从主存转移到辅存中（换出）或从辅存转移到主存中（换入）

原因：主存不足

六状态模型：五状态模型的基础上，在阻塞时可以进入挂起状态，激活后进入就绪态

七状态模型：五状态模型的基础上，加入阻塞挂起态和就绪挂起态。阻塞态挂起则进入阻塞挂起态，事件出现进入就绪挂起态。就绪态和新建态可以直接进入就绪挂起态。阻塞挂起态和就绪挂起态可以被激活，分别进入阻塞态和就绪态。

### 3.3 进程描述

操作系统是资源管理者，进程是资源分配的对象。

#### 3.3.1 OS的控制结构

OS把进程和系统和资源当做实体，构造和维护每个被管理实体的信息表。内存表、I/O表、文件表、主进程表等。

#### 3.3.2 进程控制结构

进程的物理表示：进程映象

- 用户数据
- 用户程序
- 系统栈（跟踪过程调用和过程间的参数传递）
- 进程控制块PCB：由OS维护的用于记录和控制进程属性的集合（ID、寄存器状态等）

进程属性

- 进程标识信息
  - 进程标识符（process ID）
  - 父进程标识符
  - 用户标识符（user ID）
- 处理器状态信息（CPU上下文）
  - 用户可见寄存器
  - 控制和状态寄存器
  - 栈指针（指向栈顶）

- 进程控制信息
  - 调度和状态信息（状态、优先级、等待的事件等）
  - 数据结构
  - 进程间通信
  - 进程特权
  - 存储管理（该进程虚存空间的指针）
  - 资源所有权和使用情况

##### 进程控制块的组织

同一状态的进程与PCB成一链表，多个状态对应多个不同的链表。各个状态的进程形成不同的链表：就绪链表、阻塞链表等。相当于之前提到的状态队列。

用户进程有共享地址空间，共享同一份代码，用于常见的公共操作。如打开文件等系统调用。

PCB只允许专门的例程访问。

### 3.4 进程控制

进程控制的功能：完成进程的创建、撤销以及进程状态的切换。

进程控制由原语primitive完成。原语是原子操作，不可分割，要么不执行，要执行就要全部完成才能做其他的事。

#### 3.4.1 执行模式

两类指令：

- 特权指令：允许操作系统使用而不允许一般用户使用
- 非特权指令：操作系统和用户都可以用

两种执行模式（CPU状态）：

- 用户模式（用户态、目标状态）：只能执行非特权指令

- 系统模式（系统态、内核模式、特权模式、监管状态）：能执行全部指令集，还能改变CPU执行状态

##### 内核

OS中包含重要系统功能的部分，**在系统模式下运行**，响应来自进程的调用和来自设备的中断。

内核的经典功能：

- 进程管理

- 存储管理
- I/O管理
- 中断处理、审计、监视

##### 程序状态字

程序状态字PSW，又称状态寄存器，主要用于反映处理器的状态及某些计算结果以及控制指令的执行。如CPU的零标志ZF、进位标志CF等，还有专门记录特权级的寄存器，如IOPL，记录I/O特权级。控制CPU状态的方式就是通过程序状态字的部分寄存器的值判断。

##### 执行模式切换

- 用户模式到系统模式：唯一途径是通过中断机制
- 系统模式到用户模式：可以修改PSW，由指令实现

#### 3.4.2 进程创建与撤销

用原语操作实现。

创建原语的主要操作：

- 分配唯一标识号
- 分配空间
- 初始化进程控制块
- 设置正确的连接
- 创建或扩充其他数据结构（如审计文件）

进程撤消原语：

- 撤销该进程所有的子进程
- 收回进程所占用的资源
- 撤销该进程的PCB

#### 3.4.3 进程切换

操作系统指定一个进程为运行态，并将CPU控制权交给该进程。当OS从正在运行的进程那里取得控制权，**可能**进行进程切换。

时机：

- 外部中断/硬中断
  - 时钟中断：时间片到
  - I/O中断：I/O完成，高优先级进程就绪
  - 内存失效：调页时阻塞（所需数据不在主存）
- 内部中断/软终端
  - 陷阱trap：系统调用中断
  - 异常exception：当前指令执行出错

只有通过中断，操作系统才能获得控制权。

##### 进程切换步骤

1. 保存当前进程的上下文环境（保存到PCB）
2. 更新PCB，如改变进程状态
3. 将进程控制块移到相应的队列
4. 选择另一个就绪程序
5. 更新所选进程PCB，如改变进程状态
6. 更新内存转换机构的数据（页表等）
7. 恢复所选进程的CPU上下文环境

### 3.5 OS的执行

- 非进程内核（传统方法）：进程概念只适用于用户程序，OS代码是在特权模式下工作的独立实体（巨核操作系统）

- 在用户进程中执行：OS是用户进程调用的一组例程，OS代码为所有进程映象共享，执行OS代码时切换到系统模式（小核操作系统）

- 基于进程的OS：主要内核功能被组织成独立进程。适合多处理器和多机环境（微内核操作系统）

### 3.6 安全问题

进程权限问题

关键问题：阻止/探测用户程序获取系统权限的企图

#### 3.6.1 系统访问威胁

- 入侵者
  - 冒充者：穿透系统的访问控制，冒用合法账户的账号
  - 滥用职权者：滥用权限或访问未授权数据
  - 秘密用户：利用系统管理控制漏洞逃避审计和访问限制
- 恶意软件
  - 寄生在宿主程序里，病毒、后门等
  - 独立程序，蠕虫等

#### 3.6.2 对抗措施

入侵检测、用户认证、访问控制、防火墙

### 3.7 历史上具体操作系统实现的介绍

Unix SVR4：

- OS实现一些函数，用户程序共享同一段代码，可以直接调用
- 九状态模型：七状态的变形：运行态细分为内核和用户、就绪态细分为内存就绪（未运行，在内存中就绪的进程）和强占就绪（因时间片到了而强制中断的进程）
- 进程映象：用户级上下文（代码、数据、用户栈、共享内存区）、寄存器上下文（寄存器群、栈指针等）、系统级上下文（进程表项、内核栈等）

---------------------------------------------



## 4. 线程

### 4.1 进程与线程

没有线程的进程的特点：资源分配的单位和调度/执行的单位，这两个特点本质独立，可以分开处理：进程作为资源所有权的单位，用线程作为CPU调度/执行/分派单位。

进程的主要问题：

- 切换开销大，每次切换都要保存和恢复进程的全部信息
- 占用资源多，多个同类进程占用多份资源，而一个进程中的多个同类线程共享资源

线程：一个进程内的基本调度单位。一个进程可以有一个或多个线程

#### 4.1.1 多线程

指OS支持在一个进程中执行多个线程的能力。

进程/任务是资源分配和保护的单位，拥有用于保存进程映象的虚地址空间，能受保护地访问文件、I/O资源等。而线程是分派的执行单位，每个线程有自己的执行状态，非运行时保存的是线程的上下文，有自己的执行栈，有独立的用来存储局部变量的静态存储空间，与同一进程内的其他线程共享内存和其他资源的访问。

单线程进程模型中有一个PCB、用户地址空间和栈，而多线程进程模型有一个PCB、用户地址空间，而没个线程有自己的线程控制块TCB和栈。

与进程比较，线程的优点：

- 在已有的进程内，创建速度快
- 终止所用的时间少
- 切换时间少（保存和恢复的工作量小）
- 通信效率高，在同一进程内，无需调用OS内核，可利用共享存储空间

应用举例：

- 服务器的文件管理和通信控制

- 前后台操作（如前台交互后台更新数据）

- 异步处理（如字处理、周期性备份）
- 加速执行（并行执行）
- 模块化程序结构

#### 4.1.2 线程的功能特性（执行特征）

线程状态：运行/就绪/阻塞。挂起、终止等是进程级的概念。

线程相关操作：

- 派生：线程派生新线程

- 阻塞：等待事件发生
- 唤醒/解除阻塞：由阻塞变为就绪
- 调度：由操作系统将就绪线程调度到处理器执行
- 结束：释放寄存器上下文和栈

##### 线程同步

线程共享地址空间和其他资源，需要对各个线程的活动进行同步，使得它们互不干涉且不会破坏数据结构

### 4.2 线程分类

#### 4.2.1 用户级与内核级线程

- 用户级线程ULT
- 内核级线程KLT
- 混合方法

##### 用户级线程ULT

线程管理均有应用程序完成，内核不知道线程的存在（用户程序的线程库）。

优点：

- 线程切换不需要模式切换
- 调度算法可应用程序专用
- ULT不需要内核支持，线程库可以在任何OS上执行

缺点：

- 一个线程阻塞会导致整个进程阻塞
- 不能利用多核和多处理器技术

##### 内核级线程KLT

线程管理由内核完成（提供API），调度基于线程执行

优点：

- 线程阻塞不会导致进程阻塞
- 可以利用多核和多处理器技术
- 内核例程本身也可以使用多线程

缺点：线程切换需要模式切换

##### 组合方法

线程创建在用户空间，而调度和同步在内核空间。应用程序的m个ULT被映射到n个KLT（n<=m）。

#### 4.2.2 其他方案

线程：进程=1：1或M：1或1：M或M：N

### 4.3 多核与多线程

处理器可以有多核（CPU）甚至众核（GPU）

对称多处理SMP：每个处理器可以执行的功能相同（对称），内核可以运行在任意一个处理器上。每个处理器各自处理进程/线程。对称的多核是SMP的特例，是片上的SMP。

#### 4.3.1 多核系统上的软件性能

阿姆德尔定律、SISD、SIMD、MISD、MIMD

这部分只简略过了一遍，在并行计算课程详细学过，不在这里做笔记了

多处理器OS的设计需要解决的关键问题：

- 并发与可重入
- 调度：多处理器调度冲突
- 同步：控制共享资源的访问
- 存储器管理
- 可靠性和容错

##### 微内核

分层内核（宏内核、单体内核）：所有功能按层次组织，只在相邻层之间发生交互。缺点：

- 某一层的主要变化可能对相邻层产生巨大影响
- 相邻层之间大量的交互难以保证安全性

微内核的基本思想是只有最基本的OS功能放在内核中、运行在内核模式，其他的运行在用户模式。特点：垂直分层、客户/服务器结构（内核相当于服务器，操作系统提供的特殊功能和用户进程都相当于用户）

优点：

- 一致接口：所有服务都以消息的形式提供
- 可扩展性：运行增加新的服务
- 灵活性：可以增加新的功能、删除现有功能
- 可以执行：移植系统到新处理器只要改内核而不需要改服务

- 可靠性：模块化设计、微内核很小，可以被严格测试
- 分布式消息支持：消息传送不需要知道目标机器的位置
- 面向对象操作系统的支持：组件是具有明确定义接口的对象，可互连构造软件

微内核设计：

- 低级存储器管理：控制物理地址空间、虚页映射（分页相关算法可核外实现）
- 进程间的通信：消息是进程间通信的基本形式。消息结构：消息头+消息体
- I/O和中断管理：微内核进程捕捉和识别中断，处理交给用户级进程

### 4.4~4.7 win7、Solaris、Linux、Mac OS、iOS的线程与SMP管理

windows7进程/线程作为对象实现，一个进程包含一个或多个线程，进程和线程都有内置的同步能力。

Solaris（Unix的一种开发版）有轻量级进程的概念，有父进程且享有父进程的资源，但结构为进程而不是线程

Linux中通过clone()来从进程派生进程或线程。参数控制共享的资源，线程和进程界限更加模糊。

Mac OS、iOS使用GCD技术（大中央分派），将多线程操作交给操作系统，依据核的数量和运行情况自动调整工作负荷和线程数量

-----------------------------------

## 5. 并发：互斥与同步

术语表

- 原子操作atomic operation：不可分割

- 临界区critical section：不允许多个进程同时进入的一段访问共享资源的代码
- 死锁deadlock：两个或以上进程都在等待其他进程做完某事而不继续执行，使得所有的进程都不执行
- 互斥mutual exclusion：一个进程在临界区访问资源，不允许其他进程进入访问
- 竞态race condition：多个进程或线程同时读写共享数据，结果依赖与它们执行的相对速度或相对时序
- 饥饿starvation：可运行的进程长时间未被调度执行

### 5.1 并发的原理

- 交错（不可并行的并发）：单处理器的多道程序设计（一个时刻最多一个在运行，其他的可能在阻塞。运行时间不重叠）

- 交错与重叠（可并行的并发）：多处理器的多道程序设计（运行时间能重叠，本质是能并行执行）

相对执行速度不可预测，全局资源的共享有危险，资源分配难以优化，调试困难（不可在现）

#### 5.1.1 并发产生的错误

两个进程P1和P2卖票，余票为共享变量，在汇编级上，卖票有三个操作：将变量读入寄存器，寄存器值减一，寄存器值写回变量。二者先后读入变量，各自减去1后再写回，最终变量只减少了1。

解决方法是控制代码片段的并发时序。

#### 5.1.2 竞态

在并发环境中，多个进程共享数据，多个读取数据且至少一个进程写入，各个读入数据的进程的具体结果取决于进程执行的相对速度。共享数据产生了错误结果。

#### 5.1.3 OS必须考虑的问题

并发环境下跟踪每个进程，知道它们的状态，为每个进程分配和回收资源，保护进程的资源，防止并发竞态的发生。

#### 5.1.4 进程间的相互作用

- 间接作用
  - 共享产生竞争
  - 通过共享实现合作
- 直接作用
  - 通过通信的合作

#### 5.1.5 解决互斥问题的要求

互斥是并发中防止产生错误的一种模式。条件：

- 强制排他：一次只允许一个进程进入临界区
- 充分并发：非临界区停止的进程不干涉其他进程
- 空闲让进：没有进程访问临界区时任何需要访问临界区的进程必须能立即进入
- 有限等待：不允许出现一个需要访问临界区的进程被无限延迟
- 满足异步：进程的执行素的和处理机数目没有要求或限制
- 让权等待：进程不能进入临界区时应立即释放，防止忙等待

##### 软件方法的尝试

###### 方案1（共享变量取值控制）

设置共享变量`turn`作为对方是否进入临界区的标志

```c
//process 0
while(turn != 0);	//do nothing
... ...				//critical section
turn = 1;
```

```c
//process 1
while(turn != 1);	//do nothing
... ...				//critical section
turn = 0;
```

保证了互斥，通过硬性规定顺序：两个进程轮流进入临界区

缺点：

- 忙等待：`while`循环白白消耗CPU时间
- 必须轮流进入（依据`turn`的初始值），限制推进速度

- 如果一个进程失败，另一个则永远阻塞

总之，难以满足并发要求。

###### 方案2（`flag[i]`标志表示进程`i`进入临界区）

```c
//process 0
while(flag[1]);		//do nothing
flag[0] = true;
... ...				//critical section
flag[0] = false;
```

```c
//process 1
while(flag[0]);		//do nothing
flag[1] = true;
... ...				//critical section
flag[1] = false;
```

每个线程有单独的标志表示进入和离开。先检查对方标志再设置自己的标志

缺点：

- 不能保证互斥。时序问题：在`while`处被切换，二者都能进入临界区
- 一个进程失败，另一个永远阻塞

总之，方案完全错误（所以特意拿出来讲是干嘛）

###### 方案3（`flag[i]`设置到循环等待前）

```c
//process 0
flag[0] = true;
while(flag[1]);		//do nothing
... ...				//critical section
flag[0] = false;
```

```c
//process 1
flag[1] = true;
while(flag[0]);		//do nothing
... ...				//critical section
flag[1] = false;
```

可以保证互斥但是可能导致死锁：二者都设置`flag`为1，然后谁也进不去临界区

###### 方案4(循环中用延时给其他进程进入的机会)

```c
//process 0
flag[0] = true;
while(flag[1]){
    flag[0] = false;
    Sleep(rand());		//delay
    flag[0] = true;
}
... ...					//critical section
flag[0] = false;
```

```c
//process 1
flag[1] = true;
while(flag[0]){
    flag[1] = false;
    Sleep(rand());		//delay
    flag[1] = true;
}
... ...					//critical section
flag[1] = false;
```

礼让方式，可以保证互斥。但是会导致活锁（等待时间恰好相同，都要进去的时候冲突，又开始礼让等待，有几率无止境等待）。

死锁：都要进临界区，都进不了

活锁：任意一个都能进临界区，都不进

###### Dekker算法：避免无原则的礼让

```c
flag[0] = true;			//自己想进入临界区
while(flag[1]){			//还有线程想访问则判断谁礼让谁坚持
    if(turn == 1){		//turn==1才礼让
        flag[0] = false;
        while(turn==1);	//do nothing
        flag[0] = true
    }
}
... ...					//critical section
turn = 1;
flag[0] = false;
```

逻辑复杂、正确性难证明、存在轮流问题、存在忙等待

###### Peterson算法

```c
flag[0] = true;
turn = 1;
while(flag[1]&&turn==1);	//do nothing
... ...					//critical section
flag[0] = false;
```

不存在轮流问题。

##### 硬件方法的尝试

###### 关中断

单CPU体系结构中进程访问临界资源时不能被中断。

使用开关中断指令即可。如x86的STI和CLI

缺点：

- 限制了处理器交替执行各个进程的能力
- 不能用于多核处理器或多处理器结构

###### 专用指令

原子指令，一个指令周期完成，不会被中断。如486以上的x86CPU的CMP和XCHG

- `TestSet`指令（TS）：将某位取反并将结果存入`ZF`寄存器，由此可进行加锁解锁
- `exchange`指令（XCHG）：交换一个寄存器和内存单元的内容

优点：

- 适用广
- 简单易证
- 可以使用多个变量支持多个临界区

缺点：

- 忙等待
- 可能饥饿
- 可能死锁

### 5.3 信号量semaphore

信号量机制由内核实现，进程通过信号合作，可以满足任何复杂的合作要求。信号量是由OS提供的用于进程并发控制的一种特殊的数据结构，含有一个整数变量和三个专门操作：初始化、P操作、V操作。

- 初始化：将信号量的值设置为可用资源数
- P操作：信号量的值减一。如果减后信号量为负数，执行P操作的进程将被阻塞
- V操作：信号量的值加一。如果加后信号量的值不是正数，则使一个因执行P操作被阻塞的进程唤醒。

除此之外，没有任何检查和修改信号量值的操作。

二元信号量：信号量的取值只能是0或1。因为值不会小于0，要用另外的方法判断等待队列是否为空。

##### 信号量的实际含义

- 信号量的初值：表示资源数目
- P操作：申请一个单位的资源。如果信号量小于0，表示资源分配完毕，故使进程阻塞
- V操作：释放一个单位的资源。如果信号量不大于0，表示有进程等待资源，故唤醒
- 信号量的值：若大于等于0，表示现在可用的资源数，若小于0，绝对值等于等待队列中的进程数

##### 基本实现

P和V操作必须是原子操作。软件方案可以考虑Dekker算法、Peterson算法，硬件方案可以考虑关中断或TS指令。

##### 优缺点

- 简单且表达能力强
- PV操作可以解决多种同步、互斥问题
- 不够安全，PV操作使用不当会产生死锁
- 遇到复杂同步互斥问题实现也复杂

#### 5.3.1 用信号量实现互斥与同步

多个进程访问临界区，将信号量初值设为1即可。这样，每个进程进入临界区执行P操作，离开执行V操作，可以保证最多只有一个进程进入临界区，从而实现了共享资源的互斥访问。

进程的同步：一些进程需要相互合作共同完成一项任务。一个进程到达某一点需要另一进程提供消息。未获得消息前则进入阻塞状态，获得消息才会被唤醒。

比如进程1访问写完共享资源后进程2才能读，进程2写完后进程3才能读。设置四个信号量`empty1`、`full1`、`empty2`、`full2`，分别初始化为1、0、1、0。三个进程的没描述如下：

```c
//p1
P(empty1);
//访问临界区（写）
V(full1);
```

```c
//p2
P(full1);
V(empty1);
//访问临界区（读、写）
P(empty2);
V(full2);
```

```c
//p3
P(full2);
//访问临界区（读）
V(empty2);
```

`empty`信号量表示是否能写入（不能连续写），`full`信号量表示是否能读出（写过才能读）。

#### 5.3.2 生产者/消费者问题

生产者不断写入数据进缓冲区，消费者不断读出，任一时刻只能有一个进程能访问缓冲区。

**为了表述简洁直观，我使用了类c的伪代码，但实际上信号量实现需要在汇编层面上进行**

##### 无限缓存

```c
int n = 0;			//表示缓冲区的产品数
int s = 1;			//实现互斥的信号量

void producer(){
    while(true){
    	produce();	//生产产品
        P(s);		//准备将产品放入缓冲区，需要互斥访问
        append();	//将产品放入缓冲区
        V(s);		
        V(n);		//缓冲区商品量增加
    }
}

void consumer(){
    while(true){
        P(n);
        P(s);		//P(n)P(s)次序颠倒会产生死锁。有产品才考虑访问缓冲区
        take();		//取出商品
        P(s);
        consume();	//消耗产品
    }
}
```

##### 有限缓存

```c
int buffer = N;		//缓冲区大小
int n = 0;			//产品数，控制能否继续取
int e = N;			//空闲数，控制能否继续存
int s = 1;			//实现互斥

void producer(){
    while(true){
    	produce();
        P(e);		//先判断能否继续存
        P(s);		//互斥访问
        append();
        V(s);		
        V(n);
    }
}

void consumer(){
    while(true){
        P(n);
        P(s);	
        take();		
        P(s);
        V(e);		//取走商品后，空闲数+1
        consume();	
    }
}
```

总结：一个信号量实现互斥，有几个需要同步的数据则定几个信号量。

### 5.4 管程monitor

同步机制与策略灵活但危险。集中的封装管理更加安全。

管程是一种封装同步机制与同步策略的**程序设计语言结构**。

#### 5.4.1 使用信号的管程

特点：

- 本地变量只能通过管程访问（封装）
- 进程通过调用管程来进入管程（调用）
- 每次只能一个进程执行相关管程的过程（互斥）

缺陷：

- 可能增加两次多余的进程切换
- 对进程调度要特殊要求（不允许插队）

#### 5.4.2 使用通知和广播的管程

- `cnotify`原语：将等待队列中的第一个进程变为就绪，自己继续执行。就绪的进程还要重新检查条件判断是否能访问临界区
- `cbroadcast`原语：通知所有等待队列中的进程

### 5.5 消息传递

通过`send`和`receive`操作。实现形式有多种。

#### 5.5.1 消息传递的同步

消息传递自然隐含了同步：只有发送方发送了消息，接受者才能收到消息。

`send`可以阻塞（阻塞到确定对方收到）或不阻塞，而`receive`一般是阻塞的。

#### 5.5.2 消息传递的寻址

- 直接寻址：发送方给出接收方的标识号，如进程ID
- 间接寻址
  - 共享信箱（共享内存地址）
  - 耦合方式：一对一、多对一、一对多、多对多
  - 进程与信箱的关联：
    - 静态方式：端口绑定
    - 动态方式：`connect`和`disconnect`的实现

#### 5.5.3/5.5.4 消息格式、排队原则

消息格式取决于运行环境（单机/分布式），可定长或变长，具体格式看协议

排队有FIFO原则与优先级原则。

#### 5.5.5 消息传递的互斥

使用无阻塞`send`和阻塞`receive`。信箱一开始有消息。要访问临界区先从信箱取消息，取到才能访问。访问后再将消息存入信箱。消息相当于使用临界区的令牌。

### 5.6 读者/写者问题

多个进程读写同一缓冲区。任意多的进程可以同时读，一次只有一个进程能写。写的时候不允许其他进程读。

#### 5.6.1 读者优先的信号量方案

```c
int readCount = 0;
int w = 1;			//控制写的信号量
int x = 1;			//对写readCount的互斥

void reader(){
 	while(true){
		P(x);
        readCount++;
        if(readCount == 1)P(w);	//只有当读者由0变1才禁止写入，其他n变n+1不重复禁止
        //如果改为readCount>=1，则后来的读者会被P(w)阻塞。
        V(x);
        read();
        P(x);
        readCount--;
        if(readCount == 0)V(w);	//只有没有读者才允许写
        V(x);
    }   
}

void writer(){
    while(true){
        P(w);
        write();
        V(w);　
	}
}
```

只有`readCount==0`才有`w == 1`。此时开始写，经过`writer`的`P(w)`，w变为0，此时如果有新的读者，则`readCount++`，此时`readCount==1`，需要`P(w)`，从而被阻塞。其他后来的读者会直接被开始的`P(x)`阻塞。

#### 5.6.1 写者优先的信号量方案

```c
int readCount = 0, writeCount =0;
int w = 1;			//控制写的信号量
int r = 1;			//控制读
int x = 1;			//对写readCount的互斥
int y = 1;			//对写writeCount的互斥
int z = 1;			//阻塞除去第一个以外的读者

void reader(){
	while(true){
        P(z);			//除了第一个读者，其他都在这里排队。如果只用一个r来阻塞读，那writer写的时候难以阻塞全部的读进程（可以看做占用全部的读资源，但读资源是无限的）
        P(r);
        P(x);
        readCount++;
        if(readCount==1)P(w);
        V(x);
        V(r);
        V(z);
        read();
        P(x);
        readCount--;
        if(readCount==0)V(w);
        V(x);
    }
}

void writer(){
    while(true){
        P(y);
        writeCount++;
        if(writeCount==1)P(r);
        V(y);
        P(w);
        write();
        V(w);
        P(y);
        writeCount--;
        if(writeCount==0)V(r);
        V(y);
    }
}
```

-----------------------------

## 6. 并发：死锁与饥饿（资源管理）

### 6.1 死锁原理

#### 6.1.1 死锁的概念

死锁是一个进程**集合**中每个进程都在等待只能由该集合的另一个进程才能引发的事件，导致全部都在等待。死锁是多个进程因为资源竞争且推进速度不合理形成的僵死现象。

##### 联合进程图

一种记录进程共享资源历史和分析死锁的工具。几个进程就有几维。

四种区域：

- 白色：安全区域
- 黑色：敏感区域（致命区域）

- 黑色：死锁区域
- 彩色：不可达区域

#### 6.1.2 资源

- 可重用资源：一次只能供一个进程使用，不会消耗资源
  - 特征：获得、使用、释放、重复上述步骤
  - 例子：处理器、I/O通道、存储器、信号量等

- 消耗性资源：可以生产也可以消耗
  - 特征：一个进程得到一个可消费资源，之后这个资源就不存在了
  - 例子：中断、信号、消息

#### 6.1.3 资源分配图

有向图描述进程的死锁模型。

表示法：

- 资源类：方框
- 资源实例：黑圆点。画在资源类里。
- 进程：圆圈中加进程名
- 分配边：**资源实例**指向进程的有向边
- 申请边：进程指向**资源类**的有向边

如果资源分配图没有环路则**一定**没有死锁。如果有环路则**可能**有死锁。如果每个资源类只有一个资源实例，则环路是死锁存在的充要条件。

#### 6.1.4 死锁的条件

必要条件：

- 互斥条件：
  - 进程对资源进行排他式使用，即同一时刻只有一个资源能占有该资源。
  - 要求却得不到资源的进程只能阻塞
- 占有等待条件：
  - 有资源的进程可以提出新的资源要求
  - 如果新资源已经被占有则进程阻塞，不释放已有资源
- 不可剥夺条件：资源只能在进程使用后自己主动释放

- 环路等待条件：资源分配图存在环路

### 6.2 死锁的预防prevention

通过破坏死锁条件来保证不会死锁。

鸵鸟算法：对死锁视而不见、完全不管。（其合理性在于管理死锁的高复杂性开销）

#### 6.2.1 破坏互斥条件

不直接操作资源或多个进程同时使用虚拟资源。比如：操作系统中有打印管理进程，直接调用打印资源。其他进程只能和打印管理进程交互，提交打印申请。

适用条件：

- 资源的故有特性运行多个进程使用（如文件运行同时读）
- 借助特殊技术允许同时使用（如打印机spooling技术）

缺点：不适用于绝大多数资源

#### 6.2.2 破坏占有且等待条件

禁止已经拥有资源的进程再申请其他资源，只能一次性申请全部资源。

简单安全、易于实现

进程延迟运行、资源严重浪费

#### 6.2.3 破坏不剥夺条件

申请新资源失败的进程必须释放已有的资源，之后需要再重新申请

适用条件：资源可以容易地保存和恢复

缺点：实现复杂、代价大、反复申请释放、开销大、降低吞吐量

#### 6.2.4 破坏环路等待条件

要求任何时刻一个进程只能占有一个资源（不现实）或对所有资源进行线性排队，申请资源必须严格按照序号递增顺序（按照1、2、3、4...的顺序依次申请，不需要的资源拒绝申请）

缺点：

- 排序方法与排序合理性难确定，限制了用户自主编程
- 资源浪费：不必要地拒绝资源访问
- 低效

### 6.3 死锁避免avoidance

不是预先破坏死锁条件，而是在资源动态分配过程中采用策略防止系统进入不安全状态。

不启用导致死锁的进程或不允许导致死锁的资源请求。

#### 6.3.1 进程启动拒绝

模型：

- n个进程和m种资源
- 系统资源总量向量`R=(R1,R2,R3,...,Rm)`，其中`Rj`为第j种资源的总个数
- 可用资源总量向量`V=(V1,V2,V3,...,Vm)`，其中`Vj`为第j种资源的剩余数
- 进程-资源需求矩阵C，其中`cij`为进程`i`对资源`j`的请求数
- 进程-资源分配矩阵A，其中`Aij`为当前已经分配给进程`i`的资源`j`的数量

正常情况下，有：

- 对`j=1~m`都有`Rj = Vj + (A1j+A2j+...+Anj)`
- 对`i=1~n,j=1~m`都有`cij <= Rj`
- 对`i=1~n,j=1~m`都有`cij >= Aij`

拒绝策略：若新加入的进程为n+1，若对`i=1~n,j=1~m`都有`Rj >= C(n+1)j +(c1j+c2j+...+cnj) `则运行启动进程（总需求小于总量），否则不启动。

本策略不能保证资源的最优使用率，但可以保证不会死锁。

#### 6.3.2 资源分配拒绝

安全状态：至少存在一个执行时序，使得当前所有进程都能运行到结束状态。

只要处于安全状态，则通过拒绝资源分配使得必定不会进入死锁状态。不安全状态不一定会死锁，但不能保证不会进入死锁状态。

#### 死锁避免优缺点

- 优点
  - 比死锁预防限制少
  - 无序死锁检测中的资源博多和进程重启
- 缺点
  - 必须声明进程需要的最大资源
  - 进程必须是无关的，执行顺序没有同步要求限制
  - 分配的资源数目必须固定
  - 占有资源的进程不会退出

### 6.4 死锁检测

没有任何预先措施，而是检测死锁并进行死锁恢复

#### 6.4.1 死锁检测时机与算法

- 检测时机
  - 资源申请时：算法简单但处理时间开销大
  - 周期检测或死锁“好像”发生时（如CPU使用率降低到某阈值）
- 检测方法（都很复杂）
  - 检查环路
  - 安全检查

#### 6.4.2 恢复

- 剥夺法：剥夺资源
- 回退：设置检查点与回滚（死锁可能重现）
- 杀死进程：
  - 杀死所有进程
  - 连续杀死死锁进程直至不再有死锁
  - 杀死一个非死锁进程

### 6.5 综合死锁策略

资源分类，各个类使用最合适的算法

### 6.6 哲学家就餐问题

饥饿：一组进程中，某个或某些进程无限等待其他进程所占用的资源

五个哲学家思考（和共享资源无关联的内容）和恰饭，一个人要两把叉子，总共只有五把。

#### 6.6.1 信号量

方案1（错误答案）：

```c
int fork[5] = {1,1,1,1,1};
int i;
void philosopher(int i){
	while(true){
        think();
        P(fork[i]);
        P(fork[(i+1)%5]);
        eat();
        V(fork[(i+1)%5]);
        V(fork[i]);
    }
}
//五个线程的i分别为0~4
```

方案1会产生死锁导致全部饥饿。

方案2：每次只允许四个人进入吃的状态

```c
int fork[5] = {1,1,1,1,1};
int i;
int room = 4;
void philosopher(int i){
	while(true){
        think();
        P(room);
        P(fork[i]);
        P(fork[(i+1)%5]);
        eat();
        V(fork[(i+1)%5]);
        V(fork[i]);
        V(room);
    }
}
```

#### 6.6.2 管程解决方案

略过

### 6.7~6.10 各种OS的机制

- Unix并发机制
  - 管道pipe与命名管道（FIFO）
  - 信号（模拟硬件的中断机制）
  - 信号量、套接字、共享内存、消息机制

- Linux内核并发机制
  - 原子操作
  - 自旋锁（忙等待）
  - 屏障：避免编译器和处理器为了优化而改变指令执行顺序所设置的内存屏障
  - 管道、消息、信号量、信号、共享内存、套接字

- Solaris线程同步机制
  - 互斥锁
  - 多读者/单写者锁：读者/写者问题的加锁实现
  - 条件变量：与互斥锁联合使用，实现管程功能
  - 管道、消息、信号、共享内存、套接字、信号量

- windows并发机制
  - 等待函数：用于执行体分派对象的同步
  - 同步对象
    - 互斥
    - 信号量
    - 通知/同步事件
    - 可等待计时器
  - 临界区
  - 轻量级读写锁和条件变量
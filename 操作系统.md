# 操作系统

操作系统的笔记怕是都能出书了。最后快结课时课程很赶，有点虎头蛇尾的。

## 1. 计算机系统概述

纯吹水

-------------------------------------------------------

## 2. 操作系统概述

OS的定义：OS是一组程序的集合，其功能为：

- 控制管理计算机软硬件资源
- 合理的对各类作业（单一程序）进行调度
- 方便用户使用计算机系统

### 2.1 OS的目标和功能

操作系统是机器与应用程序之间的接口程序，主要功能是动态分配系统的共享资源给正在执行的程序。

除去固件（固化在硬件上的软件，如BIOS），OS是在硬件基础上的第一层软件。应该能控制应用程序的执行、充当应用程序和硬件之间的接口。

OS的设计需要：

- 方便，使得计算机易于使用
- 有效，合理分配计算机资源
- 易扩展，可引入新的系统功能

#### 2.1.1 操作方便

通过抽象和接口调用实现。

计算机系统的3个关键接口：

- ISA指令集体系结构：定义计算机的机器语言指令系统，是软硬件的分界接口。依据指令权限又可以分为用户ISA和系统ISA
- ABI应用程序二进制接口：定义二进制可移植交叉程序的标准。即系统调用。
- API应用编程接口：让程序能通过调用HLL库来实现服务

#### 2.1.2 资源管理有效

操作系统负责管理计算机的软硬件资源。操作系统和用户程序同为程序。操作系统经常放弃控制，必须依赖处理器才能重获控制。

#### 2.1.3易扩展性

一个操作系统应该能不断的发展。要考虑到硬件升级和新硬件的出现（触摸屏、APU等）、新的服务的需要（图形界面、多点触控等）、错误的修正（如补丁机制）

### 2.2 OS的发展历史

#### 2.2.1 串行处理serial processing

早期计算机**没有操作系统**，用户必须顺序访问计算机的操作模式。需要人工调度，准备时间很长。

#### 2.2.2 简单批处理系统simple batch system

为了提高利用率，实现了**监控程序**，即批处理操作系统，用于按次序调用各个用户程序（自动作业序列）。使用作业控制语言JCL。

监控程序需要的硬件支持：

- 内存保护：保护监控程序
- 计数器：防止一个作业独占系统
- 特权指令
- 中断：使得操作系统放弃和获取控制权更加灵活

由内存保护和特权指令，出现了用户态和和心态的操作模式。

使用单道程序批处理技术：处理器必须等到I/O操作结束后才能继续，大量的等待降低了效率

#### 2.2.3 多道程序批处理系统Multi-programmed batch system

为了解决监控程序CPU利用率低的问题，实现多道程序设计/多任务处理：多个作业同时进入主存，可以切换运行。

需要的硬件功能：

- I/O中断
- DMA（Direct Memory Access，直接内存存取）：处理器将I/O操作委托给DMA模块执行，处理器可以同时处理其他指令

软件功能：

- 内存管理
- 作业调度

#### 2.2.4 分时系统time sharing system

用于满足用户与计算机交互的需要（如：运行时输入），减小响应时间。依据是否能交互，有脱机和联机的概念。

分时系统有多个交互作业，多个用户分享处理器时间。简单说就是处理器同时处理多个用户程序。

核心技术：分时技术，将时间分成很短的时间片，按时间轮流分配处理器资源给各个联机作业。

#### 2.2.5 实时系统real time system

用于专用系统，进行实时控制和信息处理，强调即时响应和高可靠性。如工业过程控制、金融领域等。

当代的操作系统通常同时具有分时、实时、多道批处理功能，称为通用操作系统。

#### 2.2.6 OS的进一步发展

- 微机/PC机的OS：图形用户界面、多媒体、人性化
- 网络OS：网络功能、云计算等
- 分布式OS：尚处于研究阶段
- 嵌入式OS：智能手机、机顶盒、相机等

总结：OS的发展动力：

- 不断提高计算机资源利用率的需要
- 方便用户
- 硬件的更新换代
- 计算机体系结构的发展

### 2.3 OS的主要理论模块

基本都在讲很泛的概念。很多部分的详细内容在后续章节会讲到，不详细记录。

- 进程
- 内存管理
- 信息保护与安全
- 进程调度和资源管理
- 系统结构

### 2.4 现代操作系统的发展

新硬件和新应用、微内核、多线程、对称多处理、分布式、面向对象

----------------------------------------------------------

## 3. 进程描述和控制

### 3.1 进程概念

#### 顺序与并发

- 顺序执行（单道单线程批处理）
  - 一个有独立功能的程序独占处理机直到结束
  - 特征：
    - 顺序性：前一个操作结束，后续操作才能执行
    - 封闭性：运行时独占全机资源，执行不收外界影响
    - 可再现性：结果与运行速度无关
  - 符合冯诺依曼体系结构要求
- 并发执行（多道批处理、单道多线程批处理）
  - 逻辑上相互独立的程序在宏观时间上重叠。一个未结束，另一个已经开始。
  - 与冯诺依曼体系结构的要求相悖

#### 程序的并发执行

并发与并行的简单区分：

- 并行：A程序和B程序同时运行
- 并发：A程序运行到一半，去运行B程序，然后再回来运行A剩余的部分

特征：

- 间断性
- 失去了封闭性，一个程序的执行受到其他程序的影响
- 不可再现性，程序的结果与执行的相对速度有关

好处：充分利用系统资源，提高系统处理能力

坏处：破坏了冯诺依曼体系结构，引发了很多难题（互斥、同步、死锁、饥饿等）

#### 进程的定义

进程是程序的一次执行，是正在运行的一个程序实例，是分配给处理器并由处理器执行的实体。进程是系统进行资源分配和调度的一个独立单位。

#### 进程的特征

- 动态性：一定的生命周期
- 并发性：多个进程实体同时存在于内存中，能在一段时间内同时运行（不一定是在同一时刻）
- 独立性：进程实体是一个能独立运行的基本单位，也是系统中获得资源和独立调度的基本单位
- 异步性：进程之间按异步方式运行
- 结构特征：进程实体由程序段、数据段、进程控制块等部分组成，称为进程映象

#### 进程控制块PCB

用于描述进程，实现对进程的管理和调度

- 标识符：唯一标识进程
- 状态：运行、就绪、等待... ...
- 优先级
- 程序计数器PC：下一条程序指令地址的指针
- 内存指针：包括代码段指针、数据段指针等
- 上下文数据：进程中断时寄存器的数据
- I/O状态信息：显示I/O请求、分配的I/O设备等
- 记账信息（商业操作系统常用）：占用处理器时间、时钟数、时限、账号等

### 3.2 进程状态

轨迹：进程执行的指令序列

分派程序dispatcher：让处理器从一个进程切换到另一个进程，即进程调度程序。本质是操作系统中的切换进程的模块。

#### 3.2.1 两状态模型

运行/未运行

未运行的进程位于队列中，依次运行。运行时中断的进程回到队列。

#### 3.2.2 进程的创建和终止

- 建立管理进程的数据结构
- 为进程分配内存空间
- 创建进程映象

进程可以派生出新进程，由此有父进程、子进程、进程树的概念

#### 3.2.3 五状态模型

创建和终止有：新建、退出两个状态

运行过程中有三个基本状态：就绪（随时可以开始运行）、阻塞（因为等待事件而不能运行）、运行

运行态超时则直接进入就绪态，而如果发生了等待事件（如I/O操作）则进入阻塞态。阻塞态的进程在事件发生后进入就绪态。只有就绪态的进程才能被分派，进入运行态。

除了就绪队列，还要有阻塞队列，阻塞事件完成后回到就绪队列，就绪队列的进程被分派则进入运行态。如果超时则直接进入就绪队列。依据等待事件的不同，可以有多条阻塞队列。

#### 3.2.4 进程的挂起状态（六、七状态模型）

交换：进程映象整体或部分地从主存转移到辅存中（换出）或从辅存转移到主存中（换入）

原因：主存不足

六状态模型：五状态模型的基础上，在阻塞时可以进入挂起状态，激活后进入就绪态

七状态模型：五状态模型的基础上，加入阻塞挂起态和就绪挂起态。阻塞态挂起则进入阻塞挂起态，事件出现进入就绪挂起态。就绪态和新建态可以直接进入就绪挂起态。阻塞挂起态和就绪挂起态可以被激活，分别进入阻塞态和就绪态。

### 3.3 进程描述

操作系统是资源管理者，进程是资源分配的对象。

#### 3.3.1 OS的控制结构

OS把进程和系统和资源当做实体，构造和维护每个被管理实体的信息表。内存表、I/O表、文件表、主进程表等。

#### 3.3.2 进程控制结构

进程的物理表示：进程映象

- 用户数据
- 用户程序
- 系统栈（跟踪过程调用和过程间的参数传递）
- 进程控制块PCB：由OS维护的用于记录和控制进程属性的集合（ID、寄存器状态等）

进程属性

- 进程标识信息
  - 进程标识符（process ID）
  - 父进程标识符
  - 用户标识符（user ID）
- 处理器状态信息（CPU上下文）
  - 用户可见寄存器
  - 控制和状态寄存器
  - 栈指针（指向栈顶）

- 进程控制信息
  - 调度和状态信息（状态、优先级、等待的事件等）
  - 数据结构
  - 进程间通信
  - 进程特权
  - 存储管理（该进程虚存空间的指针）
  - 资源所有权和使用情况

##### 进程控制块的组织

同一状态的进程与PCB成一链表，多个状态对应多个不同的链表。各个状态的进程形成不同的链表：就绪链表、阻塞链表等。相当于之前提到的状态队列。

用户进程有共享地址空间，共享同一份代码，用于常见的公共操作。如打开文件等系统调用。

PCB只允许专门的例程访问。

### 3.4 进程控制

进程控制的功能：完成进程的创建、撤销以及进程状态的切换。

进程控制由原语primitive完成。原语是原子操作，不可分割，要么不执行，要执行就要全部完成才能做其他的事。

#### 3.4.1 执行模式

两类指令：

- 特权指令：允许操作系统使用而不允许一般用户使用
- 非特权指令：操作系统和用户都可以用

两种执行模式（CPU状态）：

- 用户模式（用户态、目标状态）：只能执行非特权指令

- 系统模式（系统态、内核模式、特权模式、监管状态）：能执行全部指令集，还能改变CPU执行状态

##### 内核

OS中包含重要系统功能的部分，**在系统模式下运行**，响应来自进程的调用和来自设备的中断。

内核的经典功能：

- 进程管理

- 存储管理
- I/O管理
- 中断处理、审计、监视

##### 程序状态字

程序状态字PSW，又称状态寄存器，主要用于反映处理器的状态及某些计算结果以及控制指令的执行。如CPU的零标志ZF、进位标志CF等，还有专门记录特权级的寄存器，如IOPL，记录I/O特权级。控制CPU状态的方式就是通过程序状态字的部分寄存器的值判断。

##### 执行模式切换

- 用户模式到系统模式：唯一途径是通过中断机制
- 系统模式到用户模式：可以修改PSW，由指令实现

#### 3.4.2 进程创建与撤销

用原语操作实现。

创建原语的主要操作：

- 分配唯一标识号
- 分配空间
- 初始化进程控制块
- 设置正确的连接
- 创建或扩充其他数据结构（如审计文件）

进程撤消原语：

- 撤销该进程所有的子进程
- 收回进程所占用的资源
- 撤销该进程的PCB

#### 3.4.3 进程切换

操作系统指定一个进程为运行态，并将CPU控制权交给该进程。当OS从正在运行的进程那里取得控制权，**可能**进行进程切换。

时机：

- 外部中断/硬中断
  - 时钟中断：时间片到
  - I/O中断：I/O完成，高优先级进程就绪
  - 内存失效：调页时阻塞（所需数据不在主存）
- 内部中断/软终端
  - 陷阱trap：系统调用中断
  - 异常exception：当前指令执行出错

只有通过中断，操作系统才能获得控制权。

##### 进程切换步骤

1. 保存当前进程的上下文环境（保存到PCB）
2. 更新PCB，如改变进程状态
3. 将进程控制块移到相应的队列
4. 选择另一个就绪程序
5. 更新所选进程PCB，如改变进程状态
6. 更新内存转换机构的数据（页表等）
7. 恢复所选进程的CPU上下文环境

### 3.5 OS的执行

- 非进程内核（传统方法）：进程概念只适用于用户程序，OS代码是在特权模式下工作的独立实体（巨核操作系统）

- 在用户进程中执行：OS是用户进程调用的一组例程，OS代码为所有进程映象共享，执行OS代码时切换到系统模式（小核操作系统）

- 基于进程的OS：主要内核功能被组织成独立进程。适合多处理器和多机环境（微内核操作系统）

### 3.6 安全问题

进程权限问题

关键问题：阻止/探测用户程序获取系统权限的企图

#### 3.6.1 系统访问威胁

- 入侵者
  - 冒充者：穿透系统的访问控制，冒用合法账户的账号
  - 滥用职权者：滥用权限或访问未授权数据
  - 秘密用户：利用系统管理控制漏洞逃避审计和访问限制
- 恶意软件
  - 寄生在宿主程序里，病毒、后门等
  - 独立程序，蠕虫等

#### 3.6.2 对抗措施

入侵检测、用户认证、访问控制、防火墙

### 3.7 历史上具体操作系统实现的介绍

Unix SVR4：

- OS实现一些函数，用户程序共享同一段代码，可以直接调用
- 九状态模型：七状态的变形：运行态细分为内核和用户、就绪态细分为内存就绪（未运行，在内存中就绪的进程）和强占就绪（因时间片到了而强制中断的进程）
- 进程映象：用户级上下文（代码、数据、用户栈、共享内存区）、寄存器上下文（寄存器群、栈指针等）、系统级上下文（进程表项、内核栈等）

---------------------------------------------



## 4. 线程

### 4.1 进程与线程

没有线程的进程的特点：资源分配的单位和调度/执行的单位，这两个特点本质独立，可以分开处理：进程作为资源所有权的单位，用线程作为CPU调度/执行/分派单位。

进程的主要问题：

- 切换开销大，每次切换都要保存和恢复进程的全部信息
- 占用资源多，多个同类进程占用多份资源，而一个进程中的多个同类线程共享资源

线程：一个进程内的基本调度单位。一个进程可以有一个或多个线程

#### 4.1.1 多线程

指OS支持在一个进程中执行多个线程的能力。

进程/任务是资源分配和保护的单位，拥有用于保存进程映象的虚地址空间，能受保护地访问文件、I/O资源等。而线程是分派的执行单位，每个线程有自己的执行状态，非运行时保存的是线程的上下文，有自己的执行栈，有独立的用来存储局部变量的静态存储空间，与同一进程内的其他线程共享内存和其他资源的访问。

单线程进程模型中有一个PCB、用户地址空间和栈，而多线程进程模型有一个PCB、用户地址空间，而没个线程有自己的线程控制块TCB和栈。

与进程比较，线程的优点：

- 在已有的进程内，创建速度快
- 终止所用的时间少
- 切换时间少（保存和恢复的工作量小）
- 通信效率高，在同一进程内，无需调用OS内核，可利用共享存储空间

应用举例：

- 服务器的文件管理和通信控制

- 前后台操作（如前台交互后台更新数据）

- 异步处理（如字处理、周期性备份）
- 加速执行（并行执行）
- 模块化程序结构

#### 4.1.2 线程的功能特性（执行特征）

线程状态：运行/就绪/阻塞。挂起、终止等是进程级的概念。

线程相关操作：

- 派生：线程派生新线程

- 阻塞：等待事件发生
- 唤醒/解除阻塞：由阻塞变为就绪
- 调度：由操作系统将就绪线程调度到处理器执行
- 结束：释放寄存器上下文和栈

##### 线程同步

线程共享地址空间和其他资源，需要对各个线程的活动进行同步，使得它们互不干涉且不会破坏数据结构

### 4.2 线程分类

#### 4.2.1 用户级与内核级线程

- 用户级线程ULT
- 内核级线程KLT
- 混合方法

##### 用户级线程ULT

线程管理均有应用程序完成，内核不知道线程的存在（用户程序的线程库）。

优点：

- 线程切换不需要模式切换
- 调度算法可应用程序专用
- ULT不需要内核支持，线程库可以在任何OS上执行

缺点：

- 一个线程阻塞会导致整个进程阻塞
- 不能利用多核和多处理器技术

##### 内核级线程KLT

线程管理由内核完成（提供API），调度基于线程执行

优点：

- 线程阻塞不会导致进程阻塞
- 可以利用多核和多处理器技术
- 内核例程本身也可以使用多线程

缺点：线程切换需要模式切换

##### 组合方法

线程创建在用户空间，而调度和同步在内核空间。应用程序的m个ULT被映射到n个KLT（n<=m）。

#### 4.2.2 其他方案

线程：进程=1：1或M：1或1：M或M：N

### 4.3 多核与多线程

处理器可以有多核（CPU）甚至众核（GPU）

对称多处理SMP：每个处理器可以执行的功能相同（对称），内核可以运行在任意一个处理器上。每个处理器各自处理进程/线程。对称的多核是SMP的特例，是片上的SMP。

#### 4.3.1 多核系统上的软件性能

阿姆德尔定律、SISD、SIMD、MISD、MIMD

这部分只简略过了一遍，在并行计算课程详细学过，不在这里做笔记了

多处理器OS的设计需要解决的关键问题：

- 并发与可重入
- 调度：多处理器调度冲突
- 同步：控制共享资源的访问
- 存储器管理
- 可靠性和容错

##### 微内核

分层内核（宏内核、单体内核）：所有功能按层次组织，只在相邻层之间发生交互。缺点：

- 某一层的主要变化可能对相邻层产生巨大影响
- 相邻层之间大量的交互难以保证安全性

微内核的基本思想是只有最基本的OS功能放在内核中、运行在内核模式，其他的运行在用户模式。特点：垂直分层、客户/服务器结构（内核相当于服务器，操作系统提供的特殊功能和用户进程都相当于用户）

优点：

- 一致接口：所有服务都以消息的形式提供
- 可扩展性：运行增加新的服务
- 灵活性：可以增加新的功能、删除现有功能
- 可以执行：移植系统到新处理器只要改内核而不需要改服务

- 可靠性：模块化设计、微内核很小，可以被严格测试
- 分布式消息支持：消息传送不需要知道目标机器的位置
- 面向对象操作系统的支持：组件是具有明确定义接口的对象，可互连构造软件

微内核设计：

- 低级存储器管理：控制物理地址空间、虚页映射（分区相关算法可核外实现）
- 进程间的通信：消息是进程间通信的基本形式。消息结构：消息头+消息体
- I/O和中断管理：微内核进程捕捉和识别中断，处理交给用户级进程

### 4.4~4.7 win7、Solaris、Linux、Mac OS、iOS的线程与SMP管理

windows7进程/线程作为对象实现，一个进程包含一个或多个线程，进程和线程都有内置的同步能力。

Solaris（Unix的一种开发版）有轻量级进程的概念，有父进程且享有父进程的资源，但结构为进程而不是线程

Linux中通过clone()来从进程派生进程或线程。参数控制共享的资源，线程和进程界限更加模糊。

Mac OS、iOS使用GCD技术（大中央分派），将多线程操作交给操作系统，依据核的数量和运行情况自动调整工作负荷和线程数量

-----------------------------------

## 5. 并发：互斥与同步

术语表

- 原子操作atomic operation：不可分割

- 临界区critical section：不允许多个进程同时进入的一段访问共享资源的代码
- 死锁deadlock：两个或以上进程都在等待其他进程做完某事而不继续执行，使得所有的进程都不执行
- 互斥mutual exclusion：一个进程在临界区访问资源，不允许其他进程进入访问
- 竞态race condition：多个进程或线程同时读写共享数据，结果依赖与它们执行的相对速度或相对时序
- 饥饿starvation：可运行的进程长时间未被调度执行

### 5.1 并发的原理

- 交错（不可并行的并发）：单处理器的多道程序设计（一个时刻最多一个在运行，其他的可能在阻塞。运行时间不重叠）

- 交错与重叠（可并行的并发）：多处理器的多道程序设计（运行时间能重叠，本质是能并行执行）

相对执行速度不可预测，全局资源的共享有危险，资源分配难以优化，调试困难（不可在现）

#### 5.1.1 并发产生的错误

两个进程P1和P2卖票，余票为共享变量，在汇编级上，卖票有三个操作：将变量读入寄存器，寄存器值减一，寄存器值写回变量。二者先后读入变量，各自减去1后再写回，最终变量只减少了1。

解决方法是控制代码片段的并发时序。

#### 5.1.2 竞态

在并发环境中，多个进程共享数据，多个读取数据且至少一个进程写入，各个读入数据的进程的具体结果取决于进程执行的相对速度。共享数据产生了错误结果。

#### 5.1.3 OS必须考虑的问题

并发环境下跟踪每个进程，知道它们的状态，为每个进程分配和回收资源，保护进程的资源，防止并发竞态的发生。

#### 5.1.4 进程间的相互作用

- 间接作用
  - 共享产生竞争
  - 通过共享实现合作
- 直接作用
  - 通过通信的合作

#### 5.1.5 解决互斥问题的要求

互斥是并发中防止产生错误的一种模式。条件：

- 强制排他：一次只允许一个进程进入临界区
- 充分并发：非临界区停止的进程不干涉其他进程
- 空闲让进：没有进程访问临界区时任何需要访问临界区的进程必须能立即进入
- 有限等待：不允许出现一个需要访问临界区的进程被无限延迟
- 满足异步：进程的执行素的和处理机数目没有要求或限制
- 让权等待：进程不能进入临界区时应立即释放，防止忙等待

##### 软件方法的尝试

###### 方案1（共享变量取值控制）

设置共享变量`turn`作为对方是否进入临界区的标志

```c
//process 0
while(turn != 0);	//do nothing
... ...				//critical section
turn = 1;
```

```c
//process 1
while(turn != 1);	//do nothing
... ...				//critical section
turn = 0;
```

保证了互斥，通过硬性规定顺序：两个进程轮流进入临界区

缺点：

- 忙等待：`while`循环白白消耗CPU时间
- 必须轮流进入（依据`turn`的初始值），限制推进速度

- 如果一个进程失败，另一个则永远阻塞

总之，难以满足并发要求。

###### 方案2（`flag[i]`标志表示进程`i`进入临界区）

```c
//process 0
while(flag[1]);		//do nothing
flag[0] = true;
... ...				//critical section
flag[0] = false;
```

```c
//process 1
while(flag[0]);		//do nothing
flag[1] = true;
... ...				//critical section
flag[1] = false;
```

每个线程有单独的标志表示进入和离开。先检查对方标志再设置自己的标志

缺点：

- 不能保证互斥。时序问题：在`while`处被切换，二者都能进入临界区
- 一个进程失败，另一个永远阻塞

总之，方案完全错误（所以特意拿出来讲是干嘛）

###### 方案3（`flag[i]`设置到循环等待前）

```c
//process 0
flag[0] = true;
while(flag[1]);		//do nothing
... ...				//critical section
flag[0] = false;
```

```c
//process 1
flag[1] = true;
while(flag[0]);		//do nothing
... ...				//critical section
flag[1] = false;
```

可以保证互斥但是可能导致死锁：二者都设置`flag`为1，然后谁也进不去临界区

###### 方案4(循环中用延时给其他进程进入的机会)

```c
//process 0
flag[0] = true;
while(flag[1]){
    flag[0] = false;
    Sleep(rand());		//delay
    flag[0] = true;
}
... ...					//critical section
flag[0] = false;
```

```c
//process 1
flag[1] = true;
while(flag[0]){
    flag[1] = false;
    Sleep(rand());		//delay
    flag[1] = true;
}
... ...					//critical section
flag[1] = false;
```

礼让方式，可以保证互斥。但是会导致活锁（等待时间恰好相同，都要进去的时候冲突，又开始礼让等待，有几率无止境等待）。

死锁：都要进临界区，都进不了

活锁：任意一个都能进临界区，都不进

###### Dekker算法：避免无原则的礼让

```c
flag[0] = true;			//自己想进入临界区
while(flag[1]){			//还有线程想访问则判断谁礼让谁坚持
    if(turn == 1){		//turn==1才礼让
        flag[0] = false;
        while(turn==1);	//do nothing
        flag[0] = true
    }
}
... ...					//critical section
turn = 1;
flag[0] = false;
```

逻辑复杂、正确性难证明、存在轮流问题、存在忙等待

###### Peterson算法

```c
flag[0] = true;
turn = 1;
while(flag[1]&&turn==1);	//do nothing
... ...					//critical section
flag[0] = false;
```

不存在轮流问题。

##### 硬件方法的尝试

###### 关中断

单CPU体系结构中进程访问临界资源时不能被中断。

使用开关中断指令即可。如x86的STI和CLI

缺点：

- 限制了处理器交替执行各个进程的能力
- 不能用于多核处理器或多处理器结构

###### 专用指令

原子指令，一个指令周期完成，不会被中断。如486以上的x86CPU的CMP和XCHG

- `TestSet`指令（TS）：将某位取反并将结果存入`ZF`寄存器，由此可进行加锁解锁
- `exchange`指令（XCHG）：交换一个寄存器和内存单元的内容

优点：

- 适用广
- 简单易证
- 可以使用多个变量支持多个临界区

缺点：

- 忙等待
- 可能饥饿
- 可能死锁

### 5.3 信号量semaphore

信号量机制由内核实现，进程通过信号合作，可以满足任何复杂的合作要求。信号量是由OS提供的用于进程并发控制的一种特殊的数据结构，含有一个整数变量和三个专门操作：初始化、P操作、V操作。

- 初始化：将信号量的值设置为可用资源数
- P操作：信号量的值减一。如果减后信号量为负数，执行P操作的进程将被阻塞
- V操作：信号量的值加一。如果加后信号量的值不是正数，则使一个因执行P操作被阻塞的进程唤醒。

除此之外，没有任何检查和修改信号量值的操作。

二元信号量：信号量的取值只能是0或1。因为值不会小于0，要用另外的方法判断等待队列是否为空。

##### 信号量的实际含义

- 信号量的初值：表示资源数目
- P操作：申请一个单位的资源。如果信号量小于0，表示资源分配完毕，故使进程阻塞
- V操作：释放一个单位的资源。如果信号量不大于0，表示有进程等待资源，故唤醒
- 信号量的值：若大于等于0，表示现在可用的资源数，若小于0，绝对值等于等待队列中的进程数

##### 基本实现

P和V操作必须是原子操作。软件方案可以考虑Dekker算法、Peterson算法，硬件方案可以考虑关中断或TS指令。

##### 优缺点

- 简单且表达能力强
- PV操作可以解决多种同步、互斥问题
- 不够安全，PV操作使用不当会产生死锁
- 遇到复杂同步互斥问题实现也复杂

#### 5.3.1 用信号量实现互斥与同步

多个进程访问临界区，将信号量初值设为1即可。这样，每个进程进入临界区执行P操作，离开执行V操作，可以保证最多只有一个进程进入临界区，从而实现了共享资源的互斥访问。

进程的同步：一些进程需要相互合作共同完成一项任务。一个进程到达某一点需要另一进程提供消息。未获得消息前则进入阻塞状态，获得消息才会被唤醒。

比如进程1访问写完共享资源后进程2才能读，进程2写完后进程3才能读。设置四个信号量`empty1`、`full1`、`empty2`、`full2`，分别初始化为1、0、1、0。三个进程的没描述如下：

```c
//p1
P(empty1);
//访问临界区（写）
V(full1);
```

```c
//p2
P(full1);
V(empty1);
//访问临界区（读、写）
P(empty2);
V(full2);
```

```c
//p3
P(full2);
//访问临界区（读）
V(empty2);
```

`empty`信号量表示是否能写入（不能连续写），`full`信号量表示是否能读出（写过才能读）。

#### 5.3.2 生产者/消费者问题

生产者不断写入数据进缓冲区，消费者不断读出，任一时刻只能有一个进程能访问缓冲区。

**为了表述简洁直观，我使用了类c的伪代码，但实际上信号量实现需要在汇编层面上进行**

##### 无限缓存

```c
int n = 0;			//表示缓冲区的产品数
int s = 1;			//实现互斥的信号量

void producer(){
    while(true){
    	produce();	//生产产品
        P(s);		//准备将产品放入缓冲区，需要互斥访问
        append();	//将产品放入缓冲区
        V(s);		
        V(n);		//缓冲区商品量增加
    }
}

void consumer(){
    while(true){
        P(n);
        P(s);		//P(n)P(s)次序颠倒会产生死锁。有产品才考虑访问缓冲区
        take();		//取出商品
        P(s);
        consume();	//消耗产品
    }
}
```

##### 有限缓存

```c
int buffer = N;		//缓冲区大小
int n = 0;			//产品数，控制能否继续取
int e = N;			//空闲数，控制能否继续存
int s = 1;			//实现互斥

void producer(){
    while(true){
    	produce();
        P(e);		//先判断能否继续存
        P(s);		//互斥访问
        append();
        V(s);		
        V(n);
    }
}

void consumer(){
    while(true){
        P(n);
        P(s);	
        take();		
        P(s);
        V(e);		//取走商品后，空闲数+1
        consume();	
    }
}
```

总结：一个信号量实现互斥，有几个需要同步的数据则定几个信号量。

### 5.4 管程monitor

同步机制与策略灵活但危险。集中的封装管理更加安全。

管程是一种封装同步机制与同步策略的**程序设计语言结构**。

#### 5.4.1 使用信号的管程

特点：

- 本地变量只能通过管程访问（封装）
- 进程通过调用管程来进入管程（调用）
- 每次只能一个进程执行相关管程的过程（互斥）

缺陷：

- 可能增加两次多余的进程切换
- 对进程调度要特殊要求（不允许插队）

#### 5.4.2 使用通知和广播的管程

- `cnotify`原语：将等待队列中的第一个进程变为就绪，自己继续执行。就绪的进程还要重新检查条件判断是否能访问临界区
- `cbroadcast`原语：通知所有等待队列中的进程

### 5.5 消息传递

通过`send`和`receive`操作。实现形式有多种。

#### 5.5.1 消息传递的同步

消息传递自然隐含了同步：只有发送方发送了消息，接受者才能收到消息。

`send`可以阻塞（阻塞到确定对方收到）或不阻塞，而`receive`一般是阻塞的。

#### 5.5.2 消息传递的寻址

- 直接寻址：发送方给出接收方的标识号，如进程ID
- 间接寻址
  - 共享信箱（共享内存地址）
  - 耦合方式：一对一、多对一、一对多、多对多
  - 进程与信箱的关联：
    - 静态方式：端口绑定
    - 动态方式：`connect`和`disconnect`的实现

#### 5.5.3/5.5.4 消息格式、排队原则

消息格式取决于运行环境（单机/分布式），可定长或变长，具体格式看协议

排队有FIFO原则与优先级原则。

#### 5.5.5 消息传递的互斥

使用无阻塞`send`和阻塞`receive`。信箱一开始有消息。要访问临界区先从信箱取消息，取到才能访问。访问后再将消息存入信箱。消息相当于使用临界区的令牌。

### 5.6 读者/写者问题

多个进程读写同一缓冲区。任意多的进程可以同时读，一次只有一个进程能写。写的时候不允许其他进程读。

#### 5.6.1 读者优先的信号量方案

```c
int readCount = 0;
int w = 1;			//控制写的信号量
int x = 1;			//对写readCount的互斥

void reader(){
 	while(true){
		P(x);
        readCount++;
        if(readCount == 1)P(w);	//只有当读者由0变1才禁止写入，其他n变n+1不重复禁止
        //如果改为readCount>=1，则后来的读者会被P(w)阻塞。
        V(x);
        read();
        P(x);
        readCount--;
        if(readCount == 0)V(w);	//只有没有读者才允许写
        V(x);
    }   
}

void writer(){
    while(true){
        P(w);
        write();
        V(w);　
	}
}
```

只有`readCount==0`才有`w == 1`。此时开始写，经过`writer`的`P(w)`，w变为0，此时如果有新的读者，则`readCount++`，此时`readCount==1`，需要`P(w)`，从而被阻塞。其他后来的读者会直接被开始的`P(x)`阻塞。

#### 5.6.1 写者优先的信号量方案

```c
int readCount = 0, writeCount =0;
int w = 1;			//控制写的信号量
int r = 1;			//控制读
int x = 1;			//对写readCount的互斥
int y = 1;			//对写writeCount的互斥
int z = 1;			//阻塞除去第一个以外的读者

void reader(){
	while(true){
        P(z);			//除了第一个读者，其他都在这里排队。如果只用一个r来阻塞读，那writer写的时候难以阻塞全部的读进程（可以看做占用全部的读资源，但读资源是无限的）
        P(r);
        P(x);
        readCount++;
        if(readCount==1)P(w);
        V(x);
        V(r);
        V(z);
        read();
        P(x);
        readCount--;
        if(readCount==0)V(w);
        V(x);
    }
}

void writer(){
    while(true){
        P(y);
        writeCount++;
        if(writeCount==1)P(r);
        V(y);
        P(w);
        write();
        V(w);
        P(y);
        writeCount--;
        if(writeCount==0)V(r);
        V(y);
    }
}
```

-----------------------------

## 6. 并发：死锁与饥饿（资源管理）

### 6.1 死锁原理

#### 6.1.1 死锁的概念

死锁是一个进程**集合**中每个进程都在等待只能由该集合的另一个进程才能引发的事件，导致全部都在等待。死锁是多个进程因为资源竞争且推进速度不合理形成的僵死现象。

##### 联合进程图

一种记录进程共享资源历史和分析死锁的工具。几个进程就有几维。

四种区域：

- 白色：安全区域
- 黑色：敏感区域（致命区域）

- 黑色：死锁区域
- 彩色：不可达区域

#### 6.1.2 资源

- 可重用资源：一次只能供一个进程使用，不会消耗资源
  - 特征：获得、使用、释放、重复上述步骤
  - 例子：处理器、I/O通道、存储器、信号量等

- 消耗性资源：可以生产也可以消耗
  - 特征：一个进程得到一个可消费资源，之后这个资源就不存在了
  - 例子：中断、信号、消息

#### 6.1.3 资源分配图

有向图描述进程的死锁模型。

表示法：

- 资源类：方框
- 资源实例：黑圆点。画在资源类里。
- 进程：圆圈中加进程名
- 分配边：**资源实例**指向进程的有向边
- 申请边：进程指向**资源类**的有向边

如果资源分配图没有环路则**一定**没有死锁。如果有环路则**可能**有死锁。如果每个资源类只有一个资源实例，则环路是死锁存在的充要条件。

#### 6.1.4 死锁的条件

必要条件：

- 互斥条件：
  - 进程对资源进行排他式使用，即同一时刻只有一个资源能占有该资源。
  - 要求却得不到资源的进程只能阻塞
- 占有等待条件：
  - 有资源的进程可以提出新的资源要求
  - 如果新资源已经被占有则进程阻塞，不释放已有资源
- 不可剥夺条件：资源只能在进程使用后自己主动释放

- 环路等待条件：资源分配图存在环路

### 6.2 死锁的预防prevention

通过破坏死锁条件来保证不会死锁。

鸵鸟算法：对死锁视而不见、完全不管。（其合理性在于管理死锁的高复杂性开销）

#### 6.2.1 破坏互斥条件

不直接操作资源或多个进程同时使用虚拟资源。比如：操作系统中有打印管理进程，直接调用打印资源。其他进程只能和打印管理进程交互，提交打印申请。

适用条件：

- 资源的故有特性运行多个进程使用（如文件运行同时读）
- 借助特殊技术允许同时使用（如打印机spooling技术）

缺点：不适用于绝大多数资源

#### 6.2.2 破坏占有且等待条件

禁止已经拥有资源的进程再申请其他资源，只能一次性申请全部资源。

简单安全、易于实现

进程延迟运行、资源严重浪费

#### 6.2.3 破坏不剥夺条件

申请新资源失败的进程必须释放已有的资源，之后需要再重新申请

适用条件：资源可以容易地保存和恢复

缺点：实现复杂、代价大、反复申请释放、开销大、降低吞吐量

#### 6.2.4 破坏环路等待条件

要求任何时刻一个进程只能占有一个资源（不现实）或对所有资源进行线性排队，申请资源必须严格按照序号递增顺序（按照1、2、3、4...的顺序依次申请，不需要的资源拒绝申请）

缺点：

- 排序方法与排序合理性难确定，限制了用户自主编程
- 资源浪费：不必要地拒绝资源访问
- 低效

### 6.3 死锁避免avoidance

不是预先破坏死锁条件，而是在资源动态分配过程中采用策略防止系统进入不安全状态。

不启用导致死锁的进程或不允许导致死锁的资源请求。

#### 6.3.1 进程启动拒绝

模型：

- n个进程和m种资源
- 系统资源总量向量`R=(R1,R2,R3,...,Rm)`，其中`Rj`为第j种资源的总个数
- 可用资源总量向量`V=(V1,V2,V3,...,Vm)`，其中`Vj`为第j种资源的剩余数
- 进程-资源需求矩阵C，其中`cij`为进程`i`对资源`j`的请求数
- 进程-资源分配矩阵A，其中`Aij`为当前已经分配给进程`i`的资源`j`的数量

正常情况下，有：

- 对`j=1~m`都有`Rj = Vj + (A1j+A2j+...+Anj)`
- 对`i=1~n,j=1~m`都有`cij <= Rj`
- 对`i=1~n,j=1~m`都有`cij >= Aij`

拒绝策略：若新加入的进程为n+1，若对`i=1~n,j=1~m`都有`Rj >= C(n+1)j +(c1j+c2j+...+cnj) `则运行启动进程（总需求小于总量），否则不启动。

本策略不能保证资源的最优使用率，但可以保证不会死锁。

#### 6.3.2 资源分配拒绝

安全状态：至少存在一个执行时序，使得当前所有进程都能运行到结束状态。

只要处于安全状态，则通过拒绝资源分配使得必定不会进入死锁状态。不安全状态不一定会死锁，但不能保证不会进入死锁状态。

#### 死锁避免优缺点

- 优点
  - 比死锁预防限制少
  - 无序死锁检测中的资源博多和进程重启
- 缺点
  - 必须声明进程需要的最大资源
  - 进程必须是无关的，执行顺序没有同步要求限制
  - 分配的资源数目必须固定
  - 占有资源的进程不会退出

### 6.4 死锁检测

没有任何预先措施，而是检测死锁并进行死锁恢复

#### 6.4.1 死锁检测时机与算法

- 检测时机
  - 资源申请时：算法简单但处理时间开销大
  - 周期检测或死锁“好像”发生时（如CPU使用率降低到某阈值）
- 检测方法（都很复杂）
  - 检查环路
  - 安全检查

#### 6.4.2 恢复

- 剥夺法：剥夺资源
- 回退：设置检查点与回滚（死锁可能重现）
- 杀死进程：
  - 杀死所有进程
  - 连续杀死死锁进程直至不再有死锁
  - 杀死一个非死锁进程

### 6.5 综合死锁策略

资源分类，各个类使用最合适的算法

### 6.6 哲学家就餐问题

饥饿：一组进程中，某个或某些进程无限等待其他进程所占用的资源

五个哲学家思考（和共享资源无关联的内容）和恰饭，一个人要两把叉子，总共只有五把。

#### 6.6.1 信号量

方案1（错误答案）：

```c
int fork[5] = {1,1,1,1,1};
int i;
void philosopher(int i){
	while(true){
        think();
        P(fork[i]);
        P(fork[(i+1)%5]);
        eat();
        V(fork[(i+1)%5]);
        V(fork[i]);
    }
}
//五个线程的i分别为0~4
```

方案1会产生死锁导致全部饥饿。

方案2：每次只允许四个人进入吃的状态

```c
int fork[5] = {1,1,1,1,1};
int i;
int room = 4;
void philosopher(int i){
	while(true){
        think();
        P(room);
        P(fork[i]);
        P(fork[(i+1)%5]);
        eat();
        V(fork[(i+1)%5]);
        V(fork[i]);
        V(room);
    }
}
```

#### 6.6.2 管程解决方案

略过

### 6.7~6.10 各种OS的机制

- Unix并发机制
  - 管道pipe与命名管道（FIFO）
  - 信号（模拟硬件的中断机制）
  - 信号量、套接字、共享内存、消息机制

- Linux内核并发机制
  - 原子操作
  - 自旋锁（忙等待）
  - 屏障：避免编译器和处理器为了优化而改变指令执行顺序所设置的内存屏障
  - 管道、消息、信号量、信号、共享内存、套接字

- Solaris线程同步机制
  - 互斥锁
  - 多读者/单写者锁：读者/写者问题的加锁实现
  - 条件变量：与互斥锁联合使用，实现管程功能
  - 管道、消息、信号、共享内存、套接字、信号量

- windows并发机制
  - 等待函数：用于执行体分派对象的同步
  - 同步对象
    - 互斥
    - 信号量
    - 通知/同步事件
    - 可等待计时器
  - 临界区
  - 轻量级读写锁和条件变量

---------------------------

## 7. 内存管理（物理内存）

存储体系：

- 高速缓存cache： KB~MB级，少量、高速、昂贵、易失
- 内存：GB级，中速、加个中等、易失
- SSD：GB~TB级、较高速、较昂贵、非易失
- 磁盘/外存：GB~TB级、低速、廉价、非易失

内存：

- 系统区：存放操作系统
- 用户区：存放用户程序和数据

存储管理的任务：将程序载入内存从而让CPU能够运行。需要将内存区域进行划分以容纳多个进程（多道程序设计）、有效分配内存以尽量容纳多的进程

### 7.1 存储管理的要求

#### 7.1.1 重定位

- 逻辑地址（相对地址）：与内存内容无关的内存位置（如偏移地址）

- 物理地址（绝对地址）：内存的实际地址

多道程序和共享内存技术要求程序使用相对地址以支持重定位。程序员不知道程序运行时在内存中的位置，处于内存某一块区域的代码在运行时可能被换出外存，之后又被换入内存的另一块区域。

重定位一般要求一定的硬件（CPU）支持。

#### 7.1.2 存储保护

多道程序和共享内存技术要求一个进程不能对其他进程进行非授权访问

程序的内存引用只能在运行时检查：

- 重定位导致无法在编译时检查绝对地址
- 多数程序设计语言允许地址的动态计算（数组下标、结构体指针等）
- 通常整合在重定位硬件机制中

#### 7.1.3 共享内存

支持不同进程访问内存的同一区域，包括同一程序的不同进程实例共享程序、合作进程共享数据

重定位机制也通常支持共享

#### 7.1.4 逻辑组织

物理上看，主存和辅存是一维线性结构。反应程序组织的逻辑性，采用某种模块化的形式组织用户程序与数据。模块化有利于编程、运行时的保护和共享。分段存储管理技术最符合用户（程序员）组织程序的观点。

#### 7.1.5 物理组织

主存和辅存信息交换能更好的实现系统目标。程序员关心物理地址是不切实际的，物理组织由操作系统的资源管理负责。

##### 覆盖技术（已经淘汰）和交换技术（仍在使用）

多道环境下扩充内存。共同点：

- 进程的程序和数据放在外层
- 当前执行的部分才放入内存
- 内外存进行信息交换

覆盖技术overlaying：将一个完整的程序划分成功能上相对独立的程序段，让不会同时执行的段共享一块内存区域。程序员要向系统提供覆盖结构，有操作系统完成段之间的覆盖。

交换技术swapping：内存紧张则某些进程暂时移到外存，再把需要的进程换入内存，占据前者的区域。交换技术实际是进程在内外存间的动态调度。

与覆盖技术比较，交换技术：

- 不要求用户给出程序段之间的逻辑覆盖结构
- 交换发生在不同的进程或作业之间，而覆盖发生在同一进程或作业内
- 覆盖只能覆盖那些与覆盖段无关的数据块，覆盖的范围有限

### 7.2 分区存储管理技术

分区partitioning包括固定分区和动态分区，现在只在一些特殊场合使用（如内核存储管理），在一些过时的OS中采用。

#### 7.2.1 固定分区

将内存划分成若干和固定大小的区域。可等长或不等长。一个进程只能占一个区

等长分区：若进程大于分区，只能部分载入，需要覆盖技术。小进程将产生内存碎片，导致内存的利用率降低。不等长分区一定程度生缓解了，但没有完全解决。

放置算法：

- 等长分区：进程放入任意分区都可以
- 不等长分区：
  - 多队列：每个分区单独设置一个队列，队列中的进程只能使用该分区（会造成浪费）
  - 单队列：所有分区共享一个队列，每个进程放入更大的最小分区

固定分区评价：

- 相对简单，开销小
- 分区数目预设限制了活动进程数
- 分区大小预设，小作业不能充分利用空间

#### 7.2.2 动态分区

分区的数目和大小都可变。最初分区为1，进程需要多少就分配多大分区。类似切蛋糕。

存在问题：外碎片：内存被划分得零零散散。造成碎片浪费

消除碎片：压缩：移动进程使相互紧靠（相当耗时且需要动态重定位）

防止算法：

- 首次适配：从前端开始扫描直到找到足够大的空闲区：简单、通常最好最快
- 下次适配：从上次结束的地方开始扫描：大块很快被分裂，经常要压缩
- 最佳适配：扫描整个内存，找出足够大的最小空闲区：产生大量小碎片，最差，更要经常压缩

#### 7.2.3 伙伴系统buddy system

固定和动态分区的折中方案。分区大小为2^k，收到内存请求时，如果超过分区一半则将整块给该进程，若小于一半，则将当前页对半分，成为两个等大的2^(k-1)大小的新分区，将其中一个分给进程。每块分区有大小的上下限。

#### 7.2.4 分区管理的重定位

简单重定位：在进程第一次载入时把其中所有的内存应用换成绝对地址（已过时。逻辑地址和物理地址不等长、不支持进程的换出换入）

动态重定位：基址寄存器（分区地址）+界限寄存器（偏移量）。需要安全检查。

### 7.3 页式存储管理

分页paging的出现是为了处理碎片问题。基本原理：

1. 将主存划分成许多等长的小帧（框、页框，frame）
2. 将进程分成若干页page，页和帧的大小相同
3. 进程加载时所有页面被载入可用帧（不要求连续），同时建立页表page table。

#### 7.3.1 页表

OS通过页表的建立与维护进行内存管理。

- OS为每个进程建立并维护一个页表，包含每个页在内存中对应的帧号、保护信息、共享信息等，页表以页号为索引。
- OS另外维护一个空闲帧的列表。

#### 7.3.2 简单分页的重定位

逻辑地址由页号和页内偏移组成。CPU有寄存器记录当前进程的页表起始的物理地址与页表长度。通过页号从表中查到帧号，再由偏移量得到最后的物理地址。

页和帧的大小必须为2的整数次幂，这样逻辑地址对程序员、编译器、汇编程序、链接程序都是透明的。

#### 7.3.3 简单分页的评价

与固定分区的区别：

- 分页中的帧非常小（碎片小）
- 分页的一个进程可以占用多个帧（不需要覆盖）
- 分页不要求一个进程占用的多个帧连续（充分利用空闲部分）

存在问题：

- 不易实现共享和保护（不反应程序的逻辑组织）

- 不便于动态链接（线性地址空间）
- 不易处理数据结构的动态增长（线性地址空间）

### 7.4 分段存储管理

将程序和数据划分成若干段segment，程序和数据不共段，不要求等长，但不能超过最大长度。进程加载时，所有段被载入内存可用区域，不要求连续，同时建立段表。

#### 7.4.1 段表

OS为每个进程建立并维护一个段表

- 段表包含每一段的起始物理地址、段长等，以段号为索引
- OS另外维护一个内存空闲块的表

#### 7.4.2 简单分段的重定位

逻辑地址由段号和段内偏移组成。进程段表地址被载入CPU专用寄存器。

1. 依据段号查到起始物理地址
2. 比较偏移与段长。若前者大则地址非法
3. 物理地址=段起始地址+偏移量

#### 7.4.3 页式管理和段式管理比较

- 分页出于系统管理的需要，分段出于用户应用的需要。一条指令或一个操作数可能跨越两个页的分界处，但不会跨越两个段的分界处。如何分段由用户自己定。编译器的对齐功能可以使得不跨页。
- 页大小固定，段大小不确定
- 逻辑地址表示
  - 分页是一维的，各个模块在链接时必须组成同一地址空间
  - 分段是二维的，各个模块链接时每段看做一个地址空间
- 通常段比页大，所以段表比页表短，查段表更快
- 分段对程序员可见，便于对程序和数据进行模块化组织
- 分段方便实现模块化共享和保护

- 都存在碎片但一般分段碎片化更严重。可以减少段长来减小浪费程度。分段存在外碎片（没有利用的未被分配的碎片），分页有小的内碎片（被分配未使用的碎片），分页内存利用率更高
- 分段克服了以上提及的分页存在的问题

--------------------------

## 8. 虚拟存储器

### 8.1 硬件和控制结构

虚拟存储的关键基础：

- 段式存储和页式存储的两大特点
  - 动态地址转换（重定位）：逻辑地址运行时动态转换成物理地址，实际上允许了进程的换出换入内存与内存位置的改变
  - 不连续分配：进程的物理空间不连续
- 部分加载：进程的全部页/段不必都在内存，只要当前执行部分在就行
  - OS把程序起始点的一个或几个块装入内存
  - 页表或段表中有制定位表示对应块是否在内存中，进程中驻留内存的部分称为驻留集
  - 如果逻辑地址访问不在内存中的块，会产生访问内存错误的中断
  - OS响应中断时进入阻塞态，并将相应的块读入内存：
    - 发出磁盘I/O请求
    - 执行I/O操作期间，分派其他进程运行
    - 磁盘I/O完成时产生中断，将OS把受影响进程放入就绪队列

部分加载使得内存中可以同时容纳更多的进程，同时进程可以比内存大，实现了虚拟内存。用户程序可以使用独立于物理内存的逻辑地址单元组成存储空间，逻辑地址空间可以比物理地址空间大。虚拟技术是由内存外存结合实现的。

虚拟存储的特征：

- 不连续性
- 部分交换
- 大空间

虚拟存储需要硬件辅助：MMU（内存管理单元），位于CPU内。CPU发虚地址给MMU，MMU发送物理地址给存储器。

#### 8.1.1 程序局部性与虚拟存储

局部性原理：一段时间内一个进程的运行往往呈现出高度的局部性，表现为执行某一段程序只访问某一块数据区：

- 空间局部性：一段时间内访问地址的集合聚集在某区域中
- 时间局部性：某些模块运行期间只在很短的时间内被调用

##### 虚拟存储的要求与抖动问题

要求：

- 每个进程只有一小块在内存
- 内存满时OS若要调入新的块，必须要把内存中的某一块换出去
- OS必须在新的块要使用前就换入它

抖动thrashing问题：交换操作过于频繁，有的块被反复换入换出，拖慢了速度

局部性原理保证了虚拟存储系统的可行性和效率性：

- 内存可容纳更多进程
- 使用可行的算法来优化交换效率，避免抖动

##### 虚拟存储必要的支持

- 硬件支持
  - 分页/分段所需的动态地址转换
  - 支持虚拟内存使用
- 软件支持
  - OS管理内外存的交换
  - 调页、放置、替换策略
  - 驻留集和工作集管理
  - 清除（回写）策略、加载（并发度）控制

#### 8.1.2 虚拟分页

页表项PTE（page table entry）控制位有：

- 存在位P（present）：记录本页是否在内存中
- 修改位M（modified）：记录本页内容是否被修改

- 保护位，1位或多位（rwe，读/写/执行）
- referenced：是否被访问
- cache：是否禁用缓存

页表长度不定，取决于进程大小。页表存放在内存，起始地址存在一个CPU的专用寄存器里。

缺页时产生缺页中断

##### 页表组织方法

页表可能非常大，从而占用内存非常大。对页表也进行分页，进程运行时它的部分页表必须在内存里，包括正在使用的页面对应的表项。

- 多级页表：对页表分页，可以有多级。
- 反向页表（倒排页表）：实际内存的每个页帧对应一个页表项而不是每个虚拟内存的页面有一个页表项。表项内容为进程号+虚拟页面号
  - 优点：物理内存小时能大量节省空间
  - 缺点：虚拟地址转换成物理地址变得困难。解决方法：TLB和散列表

转换后背缓冲区TLB（translation lookaside buffer查表缓冲区/转换缓冲区/缓冲页表/相联存储器）：对页表进行缓存的硬件，存储少量最近常用的页表表项，包含有效位、虚页号、修改位、保护码、帧号等。TLB在CPU里。

地址转换：先在TLB查（每一项是并行的），未命中则去内存查页表

TLB的细节：

- 关联映射：逻辑地址的虚页号与TLB表项匹配的检查由硬件实现，是并行的
- TLB表项的页号部分必须包含页号的所有域，整个页号匹配才算命中
- TLB会刷新：有清除TLB有效位的机器指令、TLB和专用寄存器包含进程标识符

##### 页面大小

小页有利于减少内碎片的总量，而大页有利于减小进程的页表容量和实现有效的磁盘数据块传送。

页很小则每个进程的内存页较多，通过调页适应局部性原理，缺页率低。页很大则进程使用的大部分地址空间都在内存，缺页率也低。**中等大小的页使得缺页率高。**

分配给进程的页框数可以小于进程需要的总数。数目越多，缺页率越低。但是有下限。

#### 8.1.3 虚拟段式存储管理

优点：

- 简化动态增长的数据结构的处理
- 支持模块的独立修改和重编译
- 更有效地进程共享和保护

虚拟段式存储管理组织：段表。
段式的原理基本和页式相同。

#### 8.1.4 虚拟段页式存储管理

结合分页和分段的优点，克服二者的缺点。

基本原理：

- 程序按照逻辑划分成若干段，每个段进一步划分成若干个页
- 内存花城许多小帧，每个帧与页大小相等
- OS为每个进程建立并维护一个段表，为每个段建立并维护一个页表

段表表项的段起始地址是该段的页表起始地址。Present位和Modified位只包含在页表表项中，保护和共享位通常在段表表项中。段页式可以理解为段式+虚拟页式。

逻辑地址包含段号、页号、页内偏移。段号对程序员可见，后两项的整体（段内偏移）也对程序员可见，但页号和页内偏移本身对程序员透明。

##### 共享和保护

共享：段表表项记录相同的段起始地址

保护：

- 越界保护（段基址和段长）
- 访问方式保护（权限）
- 环保护（模式和级别）

环保护ring protection：将访问模式用同心圆表示。中心为内核模式，从内到外的环依次为执行模式、管理模式、用户模式。程序可以访问同层或外层的数据、调用同层或内层的服务。相关指令：CHM改变模式、REI从异常或中断返回

### 8.2 操作系统软件

三个基本问题：

- 是否支持虚拟存储
- 支持页式/段式/段页式（取决于硬件平台）
- 采用的算法

 #### 8.2.1 调页策略

- 请求调页：只通过响应缺页中断调入需要的页面、只调入发生缺页时需要的页面。

- 预先调页：发生缺页时一次调入几个相邻的页。提高I/O效率却不能保证内存效率

 #### 8.2.2 放置策略

决定进程各部分驻留在内存的什么位置。对纯段式重要，纯页式和段页式系统不成问题

#### 8.2.3 替换策略

内存已满，考虑哪些页面要被替换。

- 最优替换算法OPT：淘汰“未来不再使用”或“很久之后才用”的页框。效果最佳但是不能预知。用于其他算法的性能评价。
- 最近最少使用算法LRU：淘汰使用频率最小的页框。性能接近最佳算法，局部性原理的合理近似但开销大。（使用频率小有模糊性：考虑访问次数/时间？考虑最久没有使用的？）
  - 链表实现：每次将访问的页框放到表头，表尾就是最少使用的
  - 硬件计数器：每执行一条指令计数器就+1，访问后计数器的值写入相应表项。最小的就是最久没用的

- 先进先出FIFO。性能差、有belady现象：调页时换入的页过多反而缺页率提高

- 钟算法CLOCK：开销小、性能好。使用环形链表，每页关联一位使用位R，被访问和装入的页框置R为1。有个指针指向其中一个表项。需要替换时，如果指的表项R为1则清0，指向下一个，如此往复直到遇到R为0的页框，进行替换。不需要替换时，指针也会依次向后移动，将R当前页的R清零。调页不需替换时指针一次移动一步，需要替换时指针移到能替换时为止。

#### 8.2.4 驻留集管理

给进程分配的物理页框的集合。驻留集小则内存可驻留的进程多，但缺页率高。

- 固定分配：驻留集大小固定，各个进程的驻留集大小在进程创建时决定，替换页面时只能局部替换
- 可变分配：驻留集大小可变。依据缺页率动态调整。需要OS评估进程行为，增加开销。

替换范围：

- 全局替换：可替换其他进程的页框，“损人利己”
- 局部替换：只能替换当前进程的驻留集中的页框

##### 工作集策略working set

用于调整驻留集大小。工作集是一个进程执行过程中某段时间内访问的页的集合。在等长时间段内，不同的时间的工作集不同。工作集中页数称为窗口大小。

记录工作集变化，删除驻留集不在工作集中的页，总让驻留集包含工作集（不能包含时增大驻留集）。

问题：

- 工作集过去的变化未必能反应未来
- 记录工作集开销大
- 工作集窗口大小最优值难以确定，且通常变化

##### 与工作集近似的策略

缺页率PFF：跟踪缺页率而不是工作集的变化，设定高低阈值来增减驻留集大小。在局部性阶段的过渡期间效果不好。

可变间隔采样工作集VSWS

#### 8.2.5 清除策略

何时将已经修改的页调出外存

- 请求清除：要替换时。调入缺少的页前还要先调出修改的页，等待时间长
- 预先清除：替换前调出，可成批调出。如果要多次修改则意义不大，造成不必要的开销

#### 8.2.6 负载控制策略

决定内存中同时存在的进程数，太少则可能都处于阻塞状态，浪费CPU时间，太多则驻留集小，容易缺页或抖动

- 基于工作集策略的算法，如缺页率等
- L=S判据策略：缺页的平均间隔时间==缺页处理时间，研究表明此时CPU利用率最大。都指真实时间。

- 50%判据：外存交换设备保持50%的利用率

- 加载控制策略：基于clock替换算法，如果指针转一圈越快说明缺页较少或较多不常使用的页，可以提高系统负载。反之减少。

OS不能完全控制进程创建，但可以通过进程挂起改变内存中的进程数量

### 8.3~8.4 OS内存管理实例

- linux
  - 虚拟内存：三级页表、伙伴系统、时钟算法
  - 内核内存分配：管理物理内存页框的分配和收回、小于一页的小块内存的slab分配方案

- windows：
  - 32位WinNT的虚地址空间4GB，其中2GB用于操作系统，进程的用户地址空间最大2GB
  - 进程分页，包括可用、保留、提交页
  - 可变分配+局部替换

---------------

## 9. 单处理器调度

### 9.1 处理器调度的类型

- 长程调度
  - 决定哪些新建进程可以进入系统准备执行
  - 控制多道程序系统的并发程度
  - 进程越多则各个进程对CPU使用的百分比越小
- 中程调度
  - 决定交换哪些主存-辅存进程
  - 基于多道程序设计的管理需要
- 短程调度
  - 决定下一个使用CPU的进程（分派程序）

**I/O调度不是处理器调度！**

#### 9.1.1 短程调度

##### 短程调度时机

- 当前进程正常或异常终止（通过中断实现）
- 时钟或I/O中断
- 系统调用（软中断）
- 信号量操作（软中断）

##### 短程调度模式

- 非剥夺式non-preemptive：让进程运行直到结束或阻塞
  - 容易实现
  - 适合专用系统，不适合通用系统
- 剥夺式preemptive：允许讲逻辑上可继续运行的进程在运行过程中暂停
  - 可防止单一进程长时间独占CPU
  - 开销大

##### 短程调度过程

1. 保存现场
2. 依据调度算法选择下一个要运行的进程（若没有则安排一个空闲进程idle）
3. 恢复现场

##### 短程调度目标

- 公平：各个进程获得合理CPU份额
- 效率：CPU与其他系统资源充分利用
- 响应时间短（从提交到开始输出结果，如鼠标操作）
- 周转时间短（从提交到结束）
- 吞吐量大
- 实时性：可以指定进程完成的最后期限

### 9.2 进程调度算法

- 先来先服务FCFS：
  - 非剥夺式
  - 短进程等待的时间可能很长
  - I/O密集进程必须等待CPU密集进程结束
- 最短进程优先SPN（next）
  - 选取**估计或统计时间**最短的进程
    - 指数平滑：依据之前的运行时间估算本次的$S_{n+1}=a*T_n+(1-a)*S_n$
  - 不可剥夺
  - 长进程可能饿死
- 最短剩余优先SRT（remaining time）
  - 剥夺式
  - 需要估计剩余时间
  - 长进程可能饿死
- 最高响应比优先HRRN（ratio next）
  - 非剥夺
  - 每次调度选取响应比R最大的进程：R=(w+s)/s，其中w为等待CPU时间，s为估计运行时间
  - 利于短进程尽快执行，长进程也不会饿死
- 时间片轮转RR（time slicing round robin）
  - 时间片太短则开销大
  - 时间片太长则响应时间边长
  - 利于CPU密集进程，不利于I/O密集进程
- 最高优先级优先HPF
  - 静态：创建时指定优先级且不变
  - 动态：优先级可以动态变化（依据运行时间、时间片后的操作等）
  - 不同优先级采用多个就绪队列
- 多级队列反馈MF/FB
  - 剥夺式、时间片
  - 关注已经执行的时间而不是剩余时间
  - 新进程优先级最高，被抢占则下降一个优先级
  - 相同优先级内FCFS，最低优先级时间片轮转



| 类别       | FCFS                      | RR             | SPN          | SRT            | HRRN         | MF/FB             |
| ---------- | ------------------------- | -------------- | ------------ | -------------- | ------------ | ----------------- |
| 实现函数   | max(w)                    | 常数           | min(s)       | min(s-e)       | max((w+s)/s) | e,优先级          |
| 决策模式   | 非抢占                    | 抢占（时间片） | 非抢占       | 抢占（到达时） | 非抢占       | 抢占（时间片）    |
| 吞吐量     | 不强调                    | 时间片太小则低 | 高           | 高             | 高           | 不强调            |
| 响应时间   | 可能大                    | 短进程小       | 短进程小     | 小             | 小           | 不强调            |
| 开销       | 最小                      | 最小           | 可能高       | 可能高         | 可能高       | 可能高            |
| 对进程影响 | 对短进程和I/O密集进程不利 | 公平           | 对长进程不利 | 对长进程不利   | 平衡         | 对I/O密集进程有利 |
| 饥饿       | 无                        | 无             | 可能         | 可能           | 无           | 可能              |

#### 9.2.5 公平共享调度

一个应用或作业可以由一个进程或线程集合组成，应该基于进程集合进行调度决策。同一用户组的调度不能影响其他用户组，即应基于用户组进行调度决策。

公平共享调度FSS：基于组调度，每个组公平共享处理器时间。每个用户被指定某种类型的权值，以定义其使用共享资源的份额。

优先级越高则数字越小。进程j在时间段i开始处的优先级$P_j(i)=Base_j+CPU(i)/2+GCPU_j(i)/4W_k$，其中$Base_j$为基础优先级，后面的变量分别是本进程已经使用的CPU时间和该组进程总的使用CPU的时间。$W_k$为该组的权值

### 9.3 传统Unix调度

- 分时交互
- 多级队列反馈，每个优先队列采用RR
- 优先级一秒更新一次，计算基于进程类型和执行历史

---------------

## 10. 多处理器和实时调度

不讲

------------

## 11. I/O管理和磁盘调度

 I/O特点：

- 经常成为性能瓶颈
- I/O设备种类繁多、结构各异、速度差异大
- 与操作系统的其他功能（特别是文件系统）密切相关

#### 11.1 I/O设备

分类：

- 人可读的human readable：与用户交互，如打印机、终端（键鼠、屏幕、手写笔等）
- 机器可读machine readable：与电子设备通信，如磁盘驱动器、固态硬盘、U盘、闪存盘、传感器、控制器、驱动器等
- 通信设备communication：与远程设备通信，如数字电路驱动器、调制调解器

I/O设备差异

- 数据量相差大、传送单位不同（如键盘传输字节，磁盘传送块）、数据表示不同
- 存储文件、存储虚拟内存、管理员终端等功能需要不同的软硬件支持
- 控制的复杂性
- 错误情况不同：不同设备以不同方式响应错误

##### 设备组成

- 机械部分：设备本身（物理装置）
- 电子部分：被称为设备控制器或适配器

OS与控制器而不是设备本身打交道，控制器完成设备与主机之间的连接和通讯。控制器要把串行的位流转换为字节块，进行必要的校验工作后送到内存。

#### 11.2 I/O功能的组织

控制设备和内存或CPU之间的数据传送方式：

- 程序控制（同步I/O）
  - 由用户进程直接控制（如发出启动命令）
  - I/O操作完成前CPU处于忙等待（不停检测是否完成）
- 中断方式驱动（异步I/O）
  - 操作系统将I/O命令（带参数）写入控制器寄存器中
  - CPU可以转去执行其他运算
  - I/O操作完成时控制器产生一个中断
- 直接内存访问DMA
  - 由DMA模块控制内存和I/O设备之间的数据交换
  - CPU仅在整个数据块的传送都完成时才被中断

I/O传送控制方式的发展：

1. CPU直接控制
2. 引入控制器或I/O模块，程序控制
3. 中断控制
4. I/O模块通过DMA直接控制内存
5. I/O模块有独立的处理器（I/O通道）
6. I/O模块逐步发展成专用I/O计算机

##### 中断读盘

1. 操作系统将带参数的I/O命令写入控制器寄存器
2. 控制器从磁盘驱动器串行地一位一位读一个块，知道整块信息放入控制器的内部缓冲区
3. 控制器做和校验运算，无误则产生一个中断
4. CPU响应中断，控制转交给操作系统
5. 操作系统从控制器缓冲区读入信息（一次一个字节或一次一个字）并送入内存

##### DMA读盘

1. CPU提供读取磁盘的地址、目的存储地址、要读的字节数
2. 控制器将数据读入缓冲区并校验
3. 控制器按照指定存储器地址将数据送入主存
4. 控制器产生中断通知OS操作完成

周期窃取技术：DMA控制器从CPU中夺取系统控制权，在总线空闲时在系统总线上与主存进行数据交换。

##### DMA配置方式

- 单总线，分离DMA：所有I/O模块共享一个系统总线、开销小、低效
- 单总线，I/O集成DMA：DMA与I/O数据交换脱离系统总线。DMA模块接口会多样
- I/O总线：数据交换脱离系统总线，DMA接口单一，便于扩展

### 11.3 操作系统设计问题

目标：I/O效率、通用性

#### 11.3.1 假脱机技术SPOOL（虚拟设备技术）

专门使用一个假脱机程序(SPOOLing程序)完成设备的I/O操作而不使用外围I/O处理机。设置两级缓冲区：内存缓冲区和快速外存上的缓冲池，后者可以暂存多批I/O操作的较多数据。应用程序进行I/O操作时只是和SPOOLing程序交换数据（虚拟I/O），实际上是对SPOOLing程序的缓冲池进行I/O操作。SPOOLing程序负责和外设进行数据交换（实际I/O）

优点：

- 高速虚拟I/O操作
- 实现对独享设备的共享

#### 11.3.2 逻辑I/O（设备无关的I/O软件）

大部分的I/O软件是与设备无关的，设备驱动程序与设备无关软件的确切界限依赖于具体系统。

设备无关I/O软件的常见功能：

- 设备驱动程序的统一接口：实现一般设备都需要的I/O功能，向用户层软件提供统一接口
- 设备命名：将命名映射到相应的设备驱动程序上
- 设备保护：防止无权限用户访问和存取设备
- 提供与设备无关的块大小，屏蔽不同设备基本单位可以不同这一事实，向高层软件同一块大小的抽象设备
- 缓冲：通过缓冲区协同设备读写与用户进程读写速度
- 分配和释放独占设备
- 错误报告

#### 11.3.3 设备I/O

逻辑设备与物理设备间的过度协调机构

用户命令到设备操作序列的转换、I/O缓冲

#### 11.3.4 调度和控制

物理设备控制实体，直接面对硬件设备的控制细节

####  总结

I/O软件的层次逻辑结构：硬件 -> 中断处理程序 -> 设备驱动程序 -> 设备无关软件 -> 用户进程（包括spooling）

### 11.4 I/O缓冲

进程要等待I/O操作，而I/O操作期间一些页面必须保留在主存。缓冲技术可以提高外设利用率，尽可能使得外设处于忙状态。

按传输方式划分缓冲设备：

- 面向块的设备：信息保存在固定大小的块中，传送时必须以块为单位，如磁盘、U盘
- 面向流的设备：信息始终以字节流的形式传送，如鼠标、终端、打印机等非辅存设备

按方向划分缓冲：

- 无缓冲：操作系统无缓冲

- 单方向缓冲
  - 单缓冲：操作系统有一个缓冲区
  - 双缓冲：操作系统中有两个缓冲区，OS清空或填充一个时，进程可以访问另一个
  - 环形缓冲：操作系统中有多个缓冲区，轮流访问
- 双方向缓冲

缓冲池：由多个缓冲区组成的队列，运作时分为空闲/输入/输出缓冲区

### 11.5 磁盘调度

磁盘的物理结构：若干个涂有铁屑的金属圆形金属或塑料片组合的盘组，每个圆盘含上下两个盘面。每个盘面有个读写磁头，通过存取臂在盘面移动。盘面以圆心为中心转动

读写一个磁盘块：

1. 移臂/寻道：将存取臂移动到相应柱面上（耗时最长）
2. 旋转：等待相应扇区旋转到磁头下
3. 实际传输（耗时最短）

重叠寻道：同时控制两个或多个存取臂驱动器同时进行寻道

如果有多个I/O请求，可以按一定的调度算法改变请求顺序以减少平均寻道时间，但也要尽量公平。常见磁盘调度算法：

- 先进先出FIFO：简单公平，一般效率不高，性能接近随机调度

- 优先级PRI（priority）：目的不在于优化磁盘效率而是其他需求
- 后进先出LIFO：有利于事务处理系统。可能饿死
- 最短服务时间优先SSTF：优先选择磁头移动最小的请求。不公平

- 电梯算法/扫描算法scan：
  - 无请求，磁头不动
  - 有请求，磁头往一个方向移动，移动过程中对遇到的访问请求进行服务，如果只有没有访问请求则改方向。克服了最短服务时间优先长期等待的缺点，但有偏向性

- 单向扫描算法C-SCAN（circular）：一个方向到头马上反向回到起点，再按之前的方向继续扫描。克服了SCAN的偏向性服务的特点，中、重负载时比纯scan好。

- N步扫描算法N step SCAN：将请求分队列，一次处理一个队列

### 11.6 RAID

独立/廉价磁盘冗余阵列RAID（redundant array of independent/inexpensive disks），分为0~6共7个级别/标准。把多个物理磁盘组织在一起，作为一个逻辑驱动器，提供磁盘跨越功能。数据分成多块分散在各个磁盘上，实现并行读写。提供冗余数据备份。

- RAID 0：整个逻辑盘的数据被分散到多个物理盘上，并行读写。没有冗余能力。
- RAID 1：把一个磁盘的数据镜像到另一个上，可以从任一磁盘读写，两个相同的磁盘同时更新。数据安全性最好但磁盘利用率最低

- RAID 2：并行读写、汉明码（一位纠错、两位检错）实现数据冗余。校验码存在特定的磁盘中。仅仅用于错误率高的环境中，不太实用
- RAID 3：只用一个荣誉磁盘存储校验数据。数据速率高但每次只能处理一个请求
- RAID 4：可处理多个I/O请求、校验基于数据块

- RAID 5：类似RAID4但校验数据不单独用特定磁盘存而是分散在各个盘上

- RAID 6：两种校验方法，双重冗余。可靠性高但性能损失严重

### 11.7 磁盘高速缓存Disk Cache

内存中的磁盘缓冲区，是磁盘中某些扇区的副本。数据在cache中则不用访问磁盘。

替换策略：

- 最近最少使用LRU
- 最不常用：LFU
- 基于频率的替换算法

### 11.8~11.10 各种操作系统的I/O

- Unix
  - 每个I/O设备关联一个特殊文件，用普通读写命令访问，分为字符设备和块设备
  - I/O：有缓冲I/O、无缓冲I/O
  - 维护自由列表、设备列表、驱动程序I/O队列
- Linux
  - 每个I/O设备关联一个特殊文件，分为字符设备、块设备和网络设备
  - 磁盘调度：电梯调度、最后期限调度、预期I/O调度
  - 页面缓存与脏页写回

- windows

## 12. 文件管理

### 12.1 文件系统

#### 12.1.1 文件系统的引入

存储和检索的需求。三个基本要求：

- 存储大量信息
- 长期保存信息
- 共享（并发存取）信息

解决方法：以文件形式存储在外部介质上。文件通过OS管理，即文件管理系统

#### 12.1.2 文件结构

相关术语

- 字段/域field：基本数据单元（数据类型、长度，如年龄、姓名）
- 记录record：一组相关的域（如一个人的信息）
- 文件file：相似记录的集合（如通过名字访问的实体）
- 数据库database：相关数据的集合，由若干类型的文件组成

文件是一种抽象机制，提供了把信息存储在介质上并便于访问存取的方法，用户不不关心实现细节

##### 文件

带标识的、逻辑上有完整意义的信息项序列。内容由创建者和使用者解释。

#### 12.1.3 文件管理系统

OS管理文件的模块，提供文件存储和访问功能。

- 方便文件的访问和控制：符号名称为标识
- 并发文件访问和控制
- 统一的用户接口
- 多种文件访问权限
- 性能优化：存储、检索、读写性能
- 差错恢复：检错与一定的差错恢复能力

文件管理功能（上层用户）：

- 命名
- 访问控制：并发访问与用户权限
- 结构管理：划分记录、顺序、索引
- 目录管理：用于文件访问和控制的信息，不包括文件内容
- 文件操作：创建、打开、读写、关闭
- 文件存取：修改、追加、搜索
- 限额：限制文件数、外存大小
- 审计：记录文件使用信息（如访问时间、访问用户），保存在日志中

文件管理功能（OS）：

- 文件分块存储
- I/O缓冲和调度
- 文件分配：文件与物理介质位置的映射
- 外存存储空间管理：分配和释放外存空间
- 外存设备的访问控制：设备驱动程序

### 12.2 文件逻辑组织与访问

- 字节序列：无结构，逻辑意义由用户程序解释

- 记录序列：有结构，如目录文件

堆、顺序、索引、散列...

##### 存取方式

- 顺序存取：类似链表，如老式磁带
- 随机（直接）存取：现代OS文件

### 12.3 B树

不讲。下学期学数据库再说

### 12.4 文件目录

文件由文件体（文件本身的信息）与文件说明组成。后者又称文件数据块FCB，是OS为了管理文件创造的数据结构。

#### 12.4.1 目录

所有FCB组织在一起，构成了文件目录，一个FCB为一个目录项。目录以文件的形式存储，即目录文件。目录主要是用于从文件名到文件内容的映射。

#### 12.4.2 目录内容

文件名、文件类型、文件结构、地址（位置和长度）、访问控制信息、使用信息（创建、访问时间）

#### 12.4.3 目录操作

打开、创建、删除、列出文件等

#### 12.4.4 目录结构

一级目录、二级目录、多级目录 

改进的多级目录：把FCB的文件说明分成两个部分：

- 符号目录项：文件名、标识号
- 基本目录项BFCB：其余文件说明信息

符号目录项为树状结构，基本目录项为线性结构，便于多级目录更快访问与并行访问